[{"body":" The blocks storage is an experimental Cortex storage engine based on Prometheus TSDB: it stores each tenant\u0026rsquo;s time series into their own TSDB which write out their series to a on-disk Block (defaults to 2h block range periods). Each Block is composed by chunk files - containing the timestamp-value pairs for multiple series - and an index, which indexes metric names and labels to time series in the chunk files.\nThe supported backends for the blocks storage are:\n Amazon S3 Google Cloud Storage Microsoft Azure Storage Local Filesystem (single node only) Internally, this storage engine is based on Thanos, but no Thanos knowledge is required in order to run it.\nThe rest of the document assumes you have read the Cortex architecture documentation.\nHow it works When the blocks storage is used, each ingester creates a per-tenant TSDB and ships the TSDB Blocks - which by default are cut every 2 hours - to the long-term storage.\nQueriers periodically iterate over the storage bucket to discover recently uploaded Blocks and - for each Block - download a subset of the block index - called \u0026ldquo;index header\u0026rdquo; - which is kept in memory and used to provide fast lookups.\nThe write path Ingesters receive incoming samples from the distributors. Each push request belongs to a tenant, and the ingester append the received samples to the specific per-tenant TSDB. The received samples are both kept in-memory and written to a write-ahead log (WAL) stored on the local disk and used to recover the in-memory series in case the ingester abruptly terminates. The per-tenant TSDB is lazily created in each ingester upon the first push request is received for that tenant.\nThe in-memory samples are periodically flushed to disk - and the WAL truncated - when a new TSDB Block is cut, which by default occurs every 2 hours. Each new Block cut is then uploaded to the long-term storage and kept in the ingester for some more time, in order to give queriers enough time to discover the new Block from the storage and download its index header.\nIn order to effectively use the WAL and being able to recover the in-memory series upon ingester abruptly termination, the WAL needs to be stored to a persistent local disk which can survive in the event of an ingester failure (ie. AWS EBS volume or GCP persistent disk when running in the cloud). For example, if you\u0026rsquo;re running the Cortex cluster in Kubernetes, you may use a StatefulSet with a persistent volume claim for the ingesters.\nThe read path Queriers - at startup - iterate over the entire storage bucket to discover all tenants Blocks and - for each of them - download the index header. During this initial synchronization phase, a querier is not ready to handle incoming queries yet and its /ready readiness probe endpoint will fail.\nQueriers also periodically re-iterate over the storage bucket to discover newly uploaded Blocks (by the ingesters) and find out Blocks deleted in the meanwhile, as effect of an optional retention policy.\nThe blocks chunks and the entire index is never fully downloaded by the queriers. In the read path, a querier lookups the series label names and values using the in-memory index header and then download the required segments of the index and chunks for the matching series directly from the long-term storage using byte-range requests.\nThe index header is also stored to the local disk, in order to avoid to re-download it on subsequent restarts of a querier. For this reason, it\u0026rsquo;s recommended - but not required - to run the querier with a persistent local disk. For example, if you\u0026rsquo;re running the Cortex cluster in Kubernetes, you may use a StatefulSet with a persistent volume claim for the queriers.\nSeries sharding and replication The series sharding and replication doesn\u0026rsquo;t change based on the storage engine, so the general overview provided by the \u0026ldquo;Cortex architecture\u0026rdquo; documentation applies to the blocks storage as well.\nIt\u0026rsquo;s important to note that - differently than the chunks storage - time series are effectively written N times to the long-term storage, where N is the replication factor (typically 3). This may lead to a storage utilization N times more than the chunks storage, but is actually mitigated by the compactor service (see \u0026ldquo;vertical compaction\u0026rdquo;).\nCompactor The compactor is an optional - but highly recommended - service which compacts multiple Blocks of a given tenant into a single optimized larger Block. The compactor has two main benefits:\n Vertically compact Blocks uploaded by all ingesters for the same time range Horizontally compact Blocks with small time ranges into a single larger Block The vertical compaction compacts all the Blocks of a tenant uploaded by any ingester for the same Block range period (defaults to 2 hours) into a single Block, de-duplicating samples that are originally written to N Blocks as effect of the replication.\nThe horizontal compaction triggers after the vertical compaction and compacts several Blocks belonging to adjacent small range periods (2 hours) into a single larger Block. Despite the total block chunks size doesn\u0026rsquo;t change after this compaction, it may have a significative impact on the reduction of the index size and its index header kept in memory by queriers.\nThe compactor is stateless.\nCompactor sharding The compactor optionally supports sharding. When sharding is enabled, multiple compactor instances can coordinate to split the workload and shard blocks by tenant. All the blocks of a tenant are processed by a single compactor instance at any given time, but compaction for different tenants may simultaneously run on different compactor instances.\nWhenever the pool of compactors increase or decrease (ie. following up a scale up/down), tenants are resharded across the available compactor instances without any manual intervention. Compactors coordinate via the Cortex hash ring.\nCompactor HTTP endpoints GET /compactor/ring\nDisplays the status of the compactors ring, including the tokens owned by each compactor and an option to remove (forget) instances from the ring. Index cache The querier supports a cache to speed up postings and series lookups from TSDB blocks indexes. Two backends are supported:\n inmemory memcached In-memory index cache The inmemory index cache is enabled by default and its max size can be configured through the flag -experimental.tsdb.bucket-store.index-cache.inmemory.max-size-bytes (or config file). The trade-off of using the in-memory index cache is:\n Pros: zero latency Cons: increased querier memory usage, not shared across multiple querier replicas Memcached index cache The memcached index cache allows to use Memcached as cache backend. This cache backend is configured using -experimental.tsdb.bucket-store.index-cache.backend=memcached and requires the Memcached server(s) addresses via -experimental.tsdb.bucket-store.index-cache.memcached.addresses (or config file). The addresses are resolved using the DNS service provider.\nThe trade-off of using the Memcached index cache is:\n Pros: can scale beyond a single node memory (Memcached cluster), shared across multiple querier instances Cons: higher latency in the cache round trip compared to the in-memory one The Memcached client uses a jump hash algorithm to shard cached entries across a cluster of Memcached servers. For this reason, you should make sure memcached servers are not behind any kind of load balancer and their address is configured so that servers are added/removed to the end of the list whenever a scale up/down occurs.\nFor example, if you\u0026rsquo;re running Memcached in Kubernetes, you may:\n Deploy your Memcached cluster using a StatefulSet Create an headless service for Memcached StatefulSet Configure the Cortex\u0026rsquo;s Memcached client address using the dnssrvnoa+ service discovery Configuration The general configuration documentation also applied to a Cortex cluster running the blocks storage, with few differences:\n storage_config tsdb_config store_gateway_config compactor_config storage_config The storage_config configures the storage engine.\nstorage:# The storage engine to use. Use \u0026#34;tsdb\u0026#34; for the blocks storage.# CLI flag: -store.engineengine:tsdb tsdb_config The tsdb_config configures the experimental blocks storage.\ntsdb:# Local directory to store TSDBs in the ingesters.# CLI flag: -experimental.tsdb.dir[dir:\u0026lt;string\u0026gt;|default=\u0026#34;tsdb\u0026#34;]# TSDB blocks range period.# CLI flag: -experimental.tsdb.block-ranges-period[block_ranges_period:\u0026lt;listofduration\u0026gt;|default=2h0m0s]# TSDB blocks retention in the ingester before a block is removed. This should# be larger than the block_ranges_period and large enough to give queriers# enough time to discover newly uploaded blocks.# CLI flag: -experimental.tsdb.retention-period[retention_period:\u0026lt;duration\u0026gt;|default=6h]# How frequently the TSDB blocks are scanned and new ones are shipped to the# storage. 0 means shipping is disabled.# CLI flag: -experimental.tsdb.ship-interval[ship_interval:\u0026lt;duration\u0026gt;|default=1m]# Maximum number of tenants concurrently shipping blocks to the storage.# CLI flag: -experimental.tsdb.ship-concurrency[ship_concurrency:\u0026lt;int\u0026gt;|default=10]# Backend storage to use. Supported backends are: s3, gcs, azure, filesystem.# CLI flag: -experimental.tsdb.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;s3\u0026#34;]bucket_store:# Directory to store synchronized TSDB index headers.# CLI flag: -experimental.tsdb.bucket-store.sync-dir[sync_dir:\u0026lt;string\u0026gt;|default=\u0026#34;tsdb-sync\u0026#34;]# How frequently scan the bucket to look for changes (new blocks shipped by# ingesters and blocks removed by retention or compaction). 0 disables it.# CLI flag: -experimental.tsdb.bucket-store.sync-interval[sync_interval:\u0026lt;duration\u0026gt;|default=5m]# Max size - in bytes - of a per-tenant chunk pool, used to reduce memory# allocations.# CLI flag: -experimental.tsdb.bucket-store.max-chunk-pool-bytes[max_chunk_pool_bytes:\u0026lt;int\u0026gt;|default=2147483648]# Max number of samples per query when loading series from the long-term# storage. 0 disables the limit.# CLI flag: -experimental.tsdb.bucket-store.max-sample-count[max_sample_count:\u0026lt;int\u0026gt;|default=0]# Max number of concurrent queries to execute against the long-term storage# on a per-tenant basis.# CLI flag: -experimental.tsdb.bucket-store.max-concurrent[max_concurrent:\u0026lt;int\u0026gt;|default=20]# Maximum number of concurrent tenants synching blocks.# CLI flag: -experimental.tsdb.bucket-store.tenant-sync-concurrency[tenant_sync_concurrency:\u0026lt;int\u0026gt;|default=10]# Maximum number of concurrent blocks synching per tenant.# CLI flag: -experimental.tsdb.bucket-store.block-sync-concurrency[block_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Number of Go routines to use when syncing block meta files from object# storage per tenant.# CLI flag: -experimental.tsdb.bucket-store.meta-sync-concurrency[meta_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Whether the bucket store should use the binary index header. If false, it# uses the JSON index header.# CLI flag: -experimental.tsdb.bucket-store.binary-index-header-enabled[binary_index_header_enabled:\u0026lt;boolean\u0026gt;|default=true]# Minimum age of a block before it\u0026#39;s being read. Set it to safe value (e.g# 30m) if your object storage is eventually consistent. GCS and S3 are# (roughly) strongly consistent.# CLI flag: -experimental.tsdb.bucket-store.consistency-delay[consistency_delay:\u0026lt;duration\u0026gt;|default=0s]index_cache:# The index cache backend type. Supported values: inmemory, memcached.# CLI flag: -experimental.tsdb.bucket-store.index-cache.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;inmemory\u0026#34;]inmemory:# Maximum size in bytes of in-memory index cache used to speed up blocks# index lookups (shared between all tenants).# CLI flag: -experimental.tsdb.bucket-store.index-cache.inmemory.max-size-bytes[max_size_bytes:\u0026lt;int\u0026gt;|default=1073741824]memcached:# Comma separated list of memcached addresses. Supported prefixes are:# dns+ (looked up as an A/AAAA query), dnssrv+ (looked up as a SRV# query, dnssrvnoa+ (looked up as a SRV query, with no A/AAAA lookup# made after that).# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The socket read/write timeout.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# The maximum number of idle connections that will be maintained per# address.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.max-idle-connections[max_idle_connections:\u0026lt;int\u0026gt;|default=16]# The maximum number of concurrent asynchronous operations can occur.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.max-async-concurrency[max_async_concurrency:\u0026lt;int\u0026gt;|default=50]# The maximum number of enqueued asynchronous operations allowed.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.max-async-buffer-size[max_async_buffer_size:\u0026lt;int\u0026gt;|default=10000]# The maximum number of concurrent connections running get operations.# If set to 0, concurrency is unlimited.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.max-get-multi-concurrency[max_get_multi_concurrency:\u0026lt;int\u0026gt;|default=100]# The maximum number of keys a single underlying get operation should# run. If more keys are specified, internally keys are splitted into# multiple batches and fetched concurrently, honoring the max# concurrency. If set to 0, the max batch size is unlimited.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.max-get-multi-batch-size[max_get_multi_batch_size:\u0026lt;int\u0026gt;|default=0]# The maximum size of an item stored in memcached. Bigger items are not# stored. If set to 0, no maximum size is enforced.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.max-item-size[max_item_size:\u0026lt;int\u0026gt;|default=1048576]# Compress postings before storing them to postings cache.# CLI flag: -experimental.tsdb.bucket-store.index-cache.postings-compression-enabled[postings_compression_enabled:\u0026lt;boolean\u0026gt;|default=false]# Duration after which the blocks marked for deletion will be filtered out# while fetching blocks. The idea of ignore-deletion-marks-delay is to# ignore blocks that are marked for deletion with some delay. This ensures# store can still serve blocks that are meant to be deleted but do not have# a replacement yet.Default is 6h, half of the default value for# -compactor.deletion-delay.# CLI flag: -experimental.tsdb.bucket-store.ignore-deletion-marks-delay[ignore_deletion_mark_delay:\u0026lt;duration\u0026gt;|default=6h]# How frequently does Cortex try to compact TSDB head. Block is only created# if data covers smallest block range. Must be greater than 0 and max 5# minutes.# CLI flag: -experimental.tsdb.head-compaction-interval[head_compaction_interval:\u0026lt;duration\u0026gt;|default=1m]# Maximum number of tenants concurrently compacting TSDB head into a new block# CLI flag: -experimental.tsdb.head-compaction-concurrency[head_compaction_concurrency:\u0026lt;int\u0026gt;|default=5]# The number of shards of series to use in TSDB (must be a power of 2).# Reducing this will decrease memory footprint, but can negatively impact# performance.# CLI flag: -experimental.tsdb.stripe-size[stripe_size:\u0026lt;int\u0026gt;|default=16384]# True if the Cortex cluster is running the store-gateway service and the# querier should query the bucket store via the store-gateway.# CLI flag: -experimental.tsdb.store-gateway-enabled[store_gateway_enabled:\u0026lt;boolean\u0026gt;|default=false]# limit the number of concurrently opening TSDB\u0026#39;s on startup# CLI flag: -experimental.tsdb.max-tsdb-opening-concurrency-on-startup[max_tsdb_opening_concurrency_on_startup:\u0026lt;int\u0026gt;|default=10]s3:# S3 endpoint without schema# CLI flag: -experimental.tsdb.s3.endpoint[endpoint:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 bucket name# CLI flag: -experimental.tsdb.s3.bucket-name[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 secret access key# CLI flag: -experimental.tsdb.s3.secret-access-key[secret_access_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 access key ID# CLI flag: -experimental.tsdb.s3.access-key-id[access_key_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# If enabled, use http:// for the S3 endpoint instead of https://. This# could be useful in local dev/test environments while using an# S3-compatible backend storage, like Minio.# CLI flag: -experimental.tsdb.s3.insecure[insecure:\u0026lt;boolean\u0026gt;|default=false]gcs:# GCS bucket name# CLI flag: -experimental.tsdb.gcs.bucket-name[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# JSON representing either a Google Developers Console# client_credentials.json file or a Google Developers service account key# file. If empty, fallback to Google default logic.# CLI flag: -experimental.tsdb.gcs.service-account[service_account:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]azure:# Azure storage account name# CLI flag: -experimental.tsdb.azure.account-name[account_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage account key# CLI flag: -experimental.tsdb.azure.account-key[account_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage container name# CLI flag: -experimental.tsdb.azure.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage endpoint suffix without schema. The account name will be# prefixed to this value to create the FQDN# CLI flag: -experimental.tsdb.azure.endpoint-suffix[endpoint_suffix:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Number of retries for recoverable errors# CLI flag: -experimental.tsdb.azure.max-retries[max_retries:\u0026lt;int\u0026gt;|default=20]filesystem:# Local filesystem storage directory.# CLI flag: -experimental.tsdb.filesystem.dir[dir:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;] store_gateway_config The store_gateway_config configures the store-gateway service used by the experimental blocks storage.\nstore_gateway:# Shard blocks across multiple store gateway instances. This option needs be# set both on the store-gateway and querier when running in microservices# mode.# CLI flag: -experimental.store-gateway.sharding-enabled[sharding_enabled:\u0026lt;boolean\u0026gt;|default=false]# The hash ring configuration. This option is required only if blocks sharding# is enabled.sharding_ring:# The key-value store used to share the hash ring across multiple instances.# This option needs be set both on the store-gateway and querier when# running in microservices mode.kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, multi, memberlist (experimental).# CLI flag: -experimental.store-gateway.sharding-ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -experimental.store-gateway.sharding-ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;collectors/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is:# experimental.store-gateway.sharding-ring[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is:# experimental.store-gateway.sharding-ring[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -experimental.store-gateway.sharding-ring.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -experimental.store-gateway.sharding-ring.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -experimental.store-gateway.sharding-ring.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -experimental.store-gateway.sharding-ring.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# Period at which to heartbeat to the ring.# CLI flag: -experimental.store-gateway.sharding-ring.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=15s]# The heartbeat timeout after which store gateways are considered unhealthy# within the ring. This option needs be set both on the store-gateway and# querier when running in microservices mode.# CLI flag: -experimental.store-gateway.sharding-ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m]# The replication factor to use when sharding blocks. This option needs be# set both on the store-gateway and querier when running in microservices# mode.# CLI flag: -experimental.store-gateway.replication-factor[replication_factor:\u0026lt;int\u0026gt;|default=3]# File path where tokens are stored. If empty, tokens are not stored at# shutdown and restored at startup.# CLI flag: -experimental.store-gateway.tokens-file-path[tokens_file_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;] compactor_config The compactor_config configures the compactor for the experimental blocks storage.\ncompactor:# List of compaction time ranges.# CLI flag: -compactor.block-ranges[block_ranges:\u0026lt;listofduration\u0026gt;|default=2h0m0s,12h0m0s,24h0m0s]# Number of Go routines to use when syncing block index and chunks files from# the long term storage.# CLI flag: -compactor.block-sync-concurrency[block_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Number of Go routines to use when syncing block meta files from the long# term storage.# CLI flag: -compactor.meta-sync-concurrency[meta_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Minimum age of fresh (non-compacted) blocks before they are being processed.# Malformed blocks older than the maximum of consistency-delay and 48h0m0s# will be removed.# CLI flag: -compactor.consistency-delay[consistency_delay:\u0026lt;duration\u0026gt;|default=30m]# Data directory in which to cache blocks and process compactions# CLI flag: -compactor.data-dir[data_dir:\u0026lt;string\u0026gt;|default=\u0026#34;./data\u0026#34;]# The frequency at which the compaction runs# CLI flag: -compactor.compaction-interval[compaction_interval:\u0026lt;duration\u0026gt;|default=1h]# How many times to retry a failed compaction during a single compaction# interval# CLI flag: -compactor.compaction-retries[compaction_retries:\u0026lt;int\u0026gt;|default=3]# Time before a block marked for deletion is deleted from bucket. If not 0,# blocks will be marked for deletion and compactor component will delete# blocks marked for deletion from the bucket. If delete-delay is 0, blocks# will be deleted straight away. Note that deleting blocks immediately can# cause query failures, if store gateway still has the block loaded, or# compactor is ignoring the deletion because it\u0026#39;s compacting the block at the# same time.# CLI flag: -compactor.deletion-delay[deletion_delay:\u0026lt;duration\u0026gt;|default=12h]# Shard tenants across multiple compactor instances. Sharding is required if# you run multiple compactor instances, in order to coordinate compactions and# avoid race conditions leading to the same tenant blocks simultaneously# compacted by different instances.# CLI flag: -compactor.sharding-enabled[sharding_enabled:\u0026lt;boolean\u0026gt;|default=false]sharding_ring:kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, multi, memberlist (experimental).# CLI flag: -compactor.ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -compactor.ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;collectors/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is: compactor.ring[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is: compactor.ring[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -compactor.ring.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -compactor.ring.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -compactor.ring.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -compactor.ring.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# Period at which to heartbeat to the ring.# CLI flag: -compactor.ring.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=5s]# The heartbeat timeout after which compactors are considered unhealthy# within the ring.# CLI flag: -compactor.ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m] Known issues Can\u0026rsquo;t ingest samples older than 1h compared to the latest received sample of a tenant The blocks storage opens a TSDB for each tenant in each ingester receiving samples for that tenant. The received series are kept in the TSDB head (in-memory + Write Ahead Log) and then persisted to the storage whenever a new block is cut from the head.\nA new block is cut from the head when the head (in-memory series) covers more than 1.5x of the block range period. For 2 hours block range (default), it means that the head needs to have 3h of data to cut a block. Block \u0026ldquo;start time\u0026rdquo; is always the minimum sample timestamp in the head, while block \u0026ldquo;end time\u0026rdquo; is aligned on block range boundary. The data stored into a block is then removed from the head. That means that after cutting the block, the head will already have at least 1h of data.\nGiven TSDB doesn\u0026rsquo;t allow to append samples out of head bounds, the Cortex blocks storage can\u0026rsquo;t ingest samples older than the minimum timestamp in the head or (maximum timestamp - 1h), whatever is higher. Under normal conditions, the limit is about 1h before the latest received sample of a tenant.\nThe typical case where this issue triggers is after a long outage. Let\u0026rsquo;s consider this scenario:\n Multiple Prometheus servers remote writing to the same Cortex tenant Some Prometheus servers stop remote writing to Cortex (ie. networking issue) and they fall behind more than 1h When the failing Prometheus servers will be back online, Cortex blocks storage will discard any sample whose timestamp is older than 1h because the max timestamp in the TSDB head is close to \u0026ldquo;now\u0026rdquo; (due to the working Prometheus servers which never stopped to write samples) while the failing ones are trying to catch up writing samples older than 1h Migrating from the chunks to the blocks storage Currently, no smooth migration path is provided to migrate from chunks to blocks storage. For this reason, the blocks storage can only be enabled in new Cortex clusters.\n","excerpt":"The blocks storage is an experimental Cortex storage engine based on Prometheus TSDB: it stores each …","ref":"/docs/operations/blocks-storage/","title":"Blocks storage (experimental)"},{"body":" Author: Marco Pracucci Date: March 2020 Status: accepted Problem In Cortex, when using the experimental blocks storage, each querier internally runs the Thanos BucketStore. This means that each querier has a full view over all blocks in the long-term storage and all blocks index headers are loaded in each querier memory. The querier memory usage linearly increase with number and size of all blocks in the storage, imposing a scalability limit to the blocks storage.\nIn this proposal we want to solve this. In particular, we want to:\n Shard blocks (index headers) across a pool of nodes Do not compromise HA on the read path (if a node fails, queries should continue to work) Do not compromise correctness (either the query result is correct or it fails) Proposed solution The idea is to introduce a new Cortex service - store-gateway - internally running the Thanos BucketStore. At query time, a querier will run a query fetching the matching series both from ingesters and the subset of gateways holding the related blocks (based on the query time range). Blocks are replicated across the gateways in order to guarantee query results consistency and HA even in the case of a gateway instance failure.\nRing-based sharding and replication In order to build blocks sharding and replication, the store-gateway instances form a ring. Each gateway instance uses a custom MetaFetcherFilter to filter blocks loaded on the instance itself, keeping only blocks whose hash(block-id) is within the tokens range assigned to the gateway instance within the ring.\nWithin a gateway, the blocks synchronization is triggered in two cases:\n Periodically\nto discover new blocks uploaded by ingesters or compactor, and delete old blocks removed due to retention or by the compactor On-demand when the ring topology changes (the tokens ranges assigned to the gateway instance have changed) It\u0026rsquo;s important to outline that the sync takes time (typically will have to re-scan the bucket and download new blocks index headers) and Cortex needs to guarantee query results consistency at any given time (see below).\nQuery execution When a querier executes a query, it will need to fetch series both from ingesters and the store-gateway instances.\nFor a given query, the number of blocks to query is expected to be low, especially if the Cortex cluster is running the query-frontend with a 24h query split interval. In this scenario, whatever is the client\u0026rsquo;s query time range, the query-frontend will split the client\u0026rsquo;s query into partitioned queries each with up to 24h time range and the querier will likely hit not more than 1 block per partitioned query (except for the last 24h for which blocks may have not been compacted yet).\nGiven this assumption, we want to avoid sending every query to every store-gateway instance. The querier should be able to take an informed decision about the minimum subset of store-gateway instances which needs to query given a time range.\nThe idea is to run the MetaFetcher also within the querier, but without any sharding filter (contrary to the store-gateway). At any given point in time, the querier knows the entire list of blocks in the storage. When the querier executes the Select() (or SelectSorted()) it does:\n Compute the list of blocks by the query time range Compute the minimum list of store-gateway instances containing the required blocks (using the information from the ring) Fetch series from ingesters and the matching store-gateway instances Merge and deduplicate received series Optimization: can be skipped if the querier hits only 1 store-gateway Query results consistency When a querier executes a query, it should guarantee that either all blocks matching the time range are queried or the query fails.\nHowever, due to the (intentional) lack of a strong coordination between queriers and store-gateways, and the ring topology which can change any time, there\u0026rsquo;s no guarantee that the blocks assigned to a store-gateway shard are effectively loaded on the store-gateway itself at any given point in time.\nThe idea is introduce a consistency check in the querier. When a store-gateway receives a request from the querier, the store-gateway includes in the response the list of block IDs currently loaded on the store-gateway itself. The querier can then merge the list of block IDs received from all store-gateway hit, and match it against the list of block IDs computed at the beginning of the query execution.\nThere are three possible scenarios:\n The list match: all good All the blocks known by the querier are within the list of blocks returned by store-gateway, but the store-gateway also included blocks unknown to the querier: all good (it means the store-gateways have discovered and loaded new blocks before the querier discovered them) Some blocks known by the querier are not within the list of blocks returned by store-gateway: potential consistency issue We want to protect from a partial results response which may occur in the case #3. However, there are some legit cases which, if not handled, would lead to frequent false positives. Given the querier and store-gateway instances independently scan the bucket at a regular interval (to find new blocks or deleted blocks), we may be in one of the following cases:\na. The querier has discovered new blocks before the store-gateway successfully discovered and loaded them b. The store-gateway has offloaded blocks \u0026ldquo;marked for deletion\u0026rdquo; before the querier\nTo protect from case (a), we can exclude the blocks which have been uploaded in the last X time from the consistency check (same technique already used in other Thanos components). This X delay time is used to give the store-gateway enough time to discover and load new blocks, before the querier consider them for the consistency check. This value X should be greater than the -experimental.tsdb.bucket-store.consistency-delay, because we do expect the querier to consider a block for consistency check once it\u0026rsquo;s reasonably safe to assume that its store-gateway already loaded it.\nTo protect from case (b) we need to understand how blocks are offloaded. The BucketStore (running within the store-gateway) offloads a block as soon as it\u0026rsquo;s not returned by the MetaFetcher. This means we can configure the MetaFetcher with a IgnoreDeletionMarkFilter with a delay of X (could be the same value used for case (a)) and in the querier exclude the blocks which have been marked for deletion more than X time ago from the consistency check.\nTrade-offs The proposed solution comes with the following trade-offs:\n A querier is not ready until it has completed an initial full scan of the bucket, downloading the meta.json file of every block A store-gateway is not ready until it has completed an initial full scan of the bucket, downloading the meta.json and index header of each block matching its shard If a querier hits 2+ store-gateways it may receive duplicated series if the 2+ store-gateways share some blocks due to the replication factor ","excerpt":"Author: Marco Pracucci Date: March 2020 Status: accepted Problem In Cortex, when using the …","ref":"/docs/proposals/blocks-storage-sharding/","title":"Blocks storage sharding"},{"body":" Cortex can be run as a single binary or as multiple independent microservices. The single-binary mode is easier to deploy and is aimed mainly at users wanting to try out Cortex or develop on it. The microservices mode is intended for production usage, as it allows you to independently scale different services and isolate failures. This document will focus on single-process Cortex. See the architecture doc For more information about the microservices.\nSeparately from single process vs microservices decision, Cortex can be configured to use local storage or cloud storage (DynamoDB, Bigtable, Cassandra, S3, GCS etc). This document will focus on using local storage. Local storage is explicitly not production ready at this time. Cortex can also make use of external memcacheds for caching and although these are not mandatory, they should be used in production.\nSingle instance, single process For simplicity and to get started, we\u0026rsquo;ll run it as a single process with no dependencies:\n$ go build ./cmd/cortex $ ./cortex -config.file=./docs/configuration/single-process-config.yaml This starts a single Cortex node storing chunks and index to your local filesystem in /tmp/cortex. It is not intended for production use.\nClone and build prometheus\n$ git clone https://github.com/prometheus/prometheus $ cd prometheus $ go build ./cmd/prometheus Add the following to your Prometheus config (documentation/examples/prometheus.yml in Prometheus repo):\nremote_write:-url:http://localhost:9009/api/prom/push And start Prometheus with that config file:\n$ ./prometheus --config.file=./documentation/examples/prometheus.yml Your Prometheus instance will now start pushing data to Cortex. To query that data, start a Grafana instance:\n$ docker run --rm -d --name=grafana -p 3000:3000 grafana/grafana In the Grafana UI (username/password admin/admin), add a Prometheus datasource for Cortex (http://host.docker.internal:9009/api/prom).\nTo clean up: press CTRL-C in both terminals (for Cortex and Promrtheus).\nHorizontally scale out Next we\u0026rsquo;re going to show how you can run a scale out Cortex cluster using Docker. We\u0026rsquo;ll need:\n A built Cortex image. A Docker network to put these containers on so they can resolve each other by name. A single node Consul instance to coordinate the Cortex cluster.\n$ make ./cmd/cortex/.uptodate $ docker network create cortex $ docker run -d --name=consul --network=cortex -e CONSUL_BIND_INTERFACE=eth0 consul Next we\u0026rsquo;ll run a couple of Cortex instances pointed at that Consul. You\u0026rsquo;ll note the Cortex configuration can be specified in either a config file or overridden on the command line. See the arguments documentation for more information about Cortex configuration options.\n$ docker run -d --name=cortex1 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config.yaml:/etc/single-process-config.yaml \\ -p 9001:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 $ docker run -d --name=cortex2 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config.yaml:/etc/single-process-config.yaml \\ -p 9002:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 If you go to http://localhost:9001/ring (or http://localhost:9002/ring) you should see both Cortex nodes join the ring.\nTo demonstrate the correct operation of Cortex clustering, we\u0026rsquo;ll send samples to one of the instances and queries to another. In production, you\u0026rsquo;d want to load balance both pushes and queries evenly among all the nodes.\nPoint Prometheus at the first:\nremote_write:-url:http://localhost:9001/api/prom/push$ ./prometheus --config.file=./documentation/examples/prometheus.yml And Grafana at the second:\n$ docker run -d --name=grafana --network=cortex -p 3000:3000 grafana/grafana In the Grafana UI (username/password admin/admin), add a Prometheus datasource for Cortex (http://cortex2:9009/api/prom).\nTo clean up: CTRL-C the Prometheus process and run:\n$ docker rm -f cortex1 cortex2 consul grafana $ docker network remove cortex High availability with replication In this last demo we\u0026rsquo;ll show how Cortex can replicate data among three nodes, and demonstrate Cortex can tolerate a node failure without affecting reads and writes.\nFirst, create a network and run a new Consul and Grafana:\n$ docker network create cortex $ docker run -d --name=consul --network=cortex -e CONSUL_BIND_INTERFACE=eth0 consul $ docker run -d --name=grafana --network=cortex -p 3000:3000 grafana/grafana Then, launch 3 Cortex nodes with replication factor 3:\n$ docker run -d --name=cortex1 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config.yaml:/etc/single-process-config.yaml \\ -p 9001:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 \\ -distributor.replication-factor=3 $ docker run -d --name=cortex2 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config.yaml:/etc/single-process-config.yaml \\ -p 9002:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 \\ -distributor.replication-factor=3 $ docker run -d --name=cortex3 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config.yaml:/etc/single-process-config.yaml \\ -p 9003:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 \\ -distributor.replication-factor=3 Configure Prometheus to send data to the first replica:\nremote_write:-url:http://localhost:9001/api/prom/push$ ./prometheus --config.file=./documentation/examples/prometheus.yml In Grafana, add a datasource for the 3rd Cortex replica (http://cortex3:9009/api/prom) and verify the same data appears in both Prometheus and Cortex.\nTo show that Cortex can tolerate a node failure, hard kill one of the Cortex replicas:\n$ docker rm -f cortex2 You should see writes and queries continue to work without error.\nTo clean up: CTRL-C the Prometheus process and run:\n$ docker rm -f cortex1 cortex2 cortex3 consul grafana $ docker network remove cortex ","excerpt":"Cortex can be run as a single binary or as multiple independent microservices. The single-binary …","ref":"/docs/getting-started/getting-started-chunks-storage/","title":"Getting Started with Chunks Storage"},{"body":" Cortex can be configured using a YAML file - specified using the -config.file flag - or CLI flags. In case you combine both, CLI flags take precedence over the YAML config file.\nThe current configuration of any Cortex component can be seen by visiting the /config HTTP path. Passwords are filtered out of this endpoint.\nReference To specify which configuration file to load, pass the -config.file flag at the command line. The file is written in YAML format, defined by the scheme below. Brackets indicate that a parameter is optional.\nGeneric placeholders \u0026lt;boolean\u0026gt;: a boolean that can take the values true or false \u0026lt;int\u0026gt;: any integer matching the regular expression [1-9]+[0-9]* \u0026lt;duration\u0026gt;: a duration matching the regular expression [0-9]+(ns|us|µs|ms|s|m|h|d|w|y) where y = 365 days. \u0026lt;string\u0026gt;: a regular string \u0026lt;url\u0026gt;: an URL \u0026lt;prefix\u0026gt;: a CLI flag prefix based on the context (look at the parent configuration block to see which CLI flags prefix should be used) Use environment variables in the configuration You can use environment variable references in the config file to set values that need to be configurable during deployment by using the -config.expand-env flag. To do this, use:\n${VAR} Where VAR is the name of the environment variable.\nEach variable reference is replaced at startup by the value of the environment variable. The replacement is case-sensitive and occurs before the YAML file is parsed. References to undefined variables are replaced by empty strings unless you specify a default value or custom error text.\nTo specify a default value, use:\n${VAR:default_value} Where default_value is the value to use if the environment variable is undefined.\nSupported contents and default values of the config file # The Cortex service to run. Supported values are: all, distributor, ingester,# querier, query-frontend, table-manager, ruler, alertmanager, configs.# CLI flag: -target[target:\u0026lt;string\u0026gt;|default=\u0026#34;all\u0026#34;]# Set to false to disable auth.# CLI flag: -auth.enabled[auth_enabled:\u0026lt;boolean\u0026gt;|default=true]# HTTP path prefix for Cortex API.# CLI flag: -http.prefix[http_prefix:\u0026lt;string\u0026gt;|default=\u0026#34;/api/prom\u0026#34;]api:# HTTP URL path under which the Alertmanager ui and api will be served.# CLI flag: -http.alertmanager-http-prefix[alertmanager_http_prefix:\u0026lt;string\u0026gt;|default=\u0026#34;/alertmanager\u0026#34;]# HTTP URL path under which the Prometheus api will be served.# CLI flag: -http.prometheus-http-prefix[prometheus_http_prefix:\u0026lt;string\u0026gt;|default=\u0026#34;/prometheus\u0026#34;]# The server_config configures the HTTP and gRPC server of the launched# service(s).[server:\u0026lt;server_config\u0026gt;]# The distributor_config configures the Cortex distributor.[distributor:\u0026lt;distributor_config\u0026gt;]# The querier_config configures the Cortex querier.[querier:\u0026lt;querier_config\u0026gt;]# The ingester_client_config configures how the Cortex distributors connect to# the ingesters.[ingester_client:\u0026lt;ingester_client_config\u0026gt;]# The ingester_config configures the Cortex ingester.[ingester:\u0026lt;ingester_config\u0026gt;]# The flusher_config configures the WAL flusher target, used to manually run# one-time flushes when scaling down ingesters.[flusher:\u0026lt;flusher_config\u0026gt;]# The storage_config configures where Cortex stores the data (chunks storage# engine).[storage:\u0026lt;storage_config\u0026gt;]# The chunk_store_config configures how Cortex stores the data (chunks storage# engine).[chunk_store:\u0026lt;chunk_store_config\u0026gt;]# The limits_config configures default and per-tenant limits imposed by Cortex# services (ie. distributor, ingester, ...).[limits:\u0026lt;limits_config\u0026gt;]# The frontend_worker_config configures the worker - running within the Cortex# querier - picking up and executing queries enqueued by the query-frontend.[frontend_worker:\u0026lt;frontend_worker_config\u0026gt;]# The query_frontend_config configures the Cortex query-frontend.[frontend:\u0026lt;query_frontend_config\u0026gt;]# The queryrange_config configures the query splitting and caching in the Cortex# query-frontend.[query_range:\u0026lt;queryrange_config\u0026gt;]# The table_manager_config configures the Cortex table-manager.[table_manager:\u0026lt;table_manager_config\u0026gt;]# The tsdb_config configures the experimental blocks storage.[tsdb:\u0026lt;tsdb_config\u0026gt;]# The compactor_config configures the compactor for the experimental blocks# storage.[compactor:\u0026lt;compactor_config\u0026gt;]# The store_gateway_config configures the store-gateway service used by the# experimental blocks storage.[store_gateway:\u0026lt;store_gateway_config\u0026gt;]# The purger_config configures the purger which takes care of delete requests[purger:\u0026lt;purger_config\u0026gt;]# The ruler_config configures the Cortex ruler.[ruler:\u0026lt;ruler_config\u0026gt;]# The configs_config configures the Cortex Configs DB and API.[configs:\u0026lt;configs_config\u0026gt;]# The alertmanager_config configures the Cortex alertmanager.[alertmanager:\u0026lt;alertmanager_config\u0026gt;]runtime_config:# How often to check runtime config file.# CLI flag: -runtime-config.reload-period[period:\u0026lt;duration\u0026gt;|default=10s]# File with the configuration that can be updated in runtime.# CLI flag: -runtime-config.file[file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The memberlist_config configures the Gossip memberlist.[memberlist:\u0026lt;memberlist_config\u0026gt;] server_config The server_config configures the HTTP and gRPC server of the launched service(s).\n# HTTP server listen address.# CLI flag: -server.http-listen-address[http_listen_address:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# HTTP server listen port.# CLI flag: -server.http-listen-port[http_listen_port:\u0026lt;int\u0026gt;|default=80]# Maximum number of simultaneous http connections, \u0026lt;=0 to disable# CLI flag: -server.http-conn-limit[http_listen_conn_limit:\u0026lt;int\u0026gt;|default=0]# gRPC server listen address.# CLI flag: -server.grpc-listen-address[grpc_listen_address:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# gRPC server listen port.# CLI flag: -server.grpc-listen-port[grpc_listen_port:\u0026lt;int\u0026gt;|default=9095]# Maximum number of simultaneous grpc connections, \u0026lt;=0 to disable# CLI flag: -server.grpc-conn-limit[grpc_listen_conn_limit:\u0026lt;int\u0026gt;|default=0]http_tls_config:# HTTP server cert path.# CLI flag: -server.http-tls-cert-path[cert_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# HTTP server key path.# CLI flag: -server.http-tls-key-path[key_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# HTTP TLS Client Auth type.# CLI flag: -server.http-tls-client-auth[client_auth_type:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# HTTP TLS Client CA path.# CLI flag: -server.http-tls-ca-path[client_ca_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]grpc_tls_config:# GRPC TLS server cert path.# CLI flag: -server.grpc-tls-cert-path[cert_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# GRPC TLS server key path.# CLI flag: -server.grpc-tls-key-path[key_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# GRPC TLS Client Auth type.# CLI flag: -server.grpc-tls-client-auth[client_auth_type:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# GRPC TLS Client CA path.# CLI flag: -server.grpc-tls-ca-path[client_ca_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Register the intrumentation handlers (/metrics etc).# CLI flag: -server.register-instrumentation[register_instrumentation:\u0026lt;boolean\u0026gt;|default=true]# Timeout for graceful shutdowns# CLI flag: -server.graceful-shutdown-timeout[graceful_shutdown_timeout:\u0026lt;duration\u0026gt;|default=30s]# Read timeout for HTTP server# CLI flag: -server.http-read-timeout[http_server_read_timeout:\u0026lt;duration\u0026gt;|default=30s]# Write timeout for HTTP server# CLI flag: -server.http-write-timeout[http_server_write_timeout:\u0026lt;duration\u0026gt;|default=30s]# Idle timeout for HTTP server# CLI flag: -server.http-idle-timeout[http_server_idle_timeout:\u0026lt;duration\u0026gt;|default=2m]# Limit on the size of a gRPC message this server can receive (bytes).# CLI flag: -server.grpc-max-recv-msg-size-bytes[grpc_server_max_recv_msg_size:\u0026lt;int\u0026gt;|default=4194304]# Limit on the size of a gRPC message this server can send (bytes).# CLI flag: -server.grpc-max-send-msg-size-bytes[grpc_server_max_send_msg_size:\u0026lt;int\u0026gt;|default=4194304]# Limit on the number of concurrent streams for gRPC calls (0 = unlimited)# CLI flag: -server.grpc-max-concurrent-streams[grpc_server_max_concurrent_streams:\u0026lt;int\u0026gt;|default=100]# The duration after which an idle connection should be closed. Default:# infinity# CLI flag: -server.grpc.keepalive.max-connection-idle[grpc_server_max_connection_idle:\u0026lt;duration\u0026gt;|default=2562047h47m16.854775807s]# The duration for the maximum amount of time a connection may exist before it# will be closed. Default: infinity# CLI flag: -server.grpc.keepalive.max-connection-age[grpc_server_max_connection_age:\u0026lt;duration\u0026gt;|default=2562047h47m16.854775807s]# An additive period after max-connection-age after which the connection will be# forcibly closed. Default: infinity# CLI flag: -server.grpc.keepalive.max-connection-age-grace[grpc_server_max_connection_age_grace:\u0026lt;duration\u0026gt;|default=2562047h47m16.854775807s]# Duration after which a keepalive probe is sent in case of no activity over the# connection., Default: 2h# CLI flag: -server.grpc.keepalive.time[grpc_server_keepalive_time:\u0026lt;duration\u0026gt;|default=2h]# After having pinged for keepalive check, the duration after which an idle# connection should be closed, Default: 20s# CLI flag: -server.grpc.keepalive.timeout[grpc_server_keepalive_timeout:\u0026lt;duration\u0026gt;|default=20s]# Only log messages with the given severity or above. Valid levels: [debug,# info, warn, error]# CLI flag: -log.level[log_level:\u0026lt;string\u0026gt;|default=\u0026#34;info\u0026#34;]# Base path to serve all API routes from (e.g. /v1/)# CLI flag: -server.path-prefix[http_path_prefix:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;] distributor_config The distributor_config configures the Cortex distributor.\npool:# How frequently to clean up clients for ingesters that have gone away.# CLI flag: -distributor.client-cleanup-period[client_cleanup_period:\u0026lt;duration\u0026gt;|default=15s]# Run a health check on each ingester client during periodic cleanup.# CLI flag: -distributor.health-check-ingesters[health_check_ingesters:\u0026lt;boolean\u0026gt;|default=true]ha_tracker:# Enable the distributors HA tracker so that it can accept samples from# Prometheus HA replicas gracefully (requires labels).# CLI flag: -distributor.ha-tracker.enable[enable_ha_tracker:\u0026lt;boolean\u0026gt;|default=false]# Update the timestamp in the KV store for a given cluster/replica only after# this amount of time has passed since the current stored timestamp.# CLI flag: -distributor.ha-tracker.update-timeout[ha_tracker_update_timeout:\u0026lt;duration\u0026gt;|default=15s]# Maximum jitter applied to the update timeout, in order to spread the HA# heartbeats over time.# CLI flag: -distributor.ha-tracker.update-timeout-jitter-max[ha_tracker_update_timeout_jitter_max:\u0026lt;duration\u0026gt;|default=5s]# If we don\u0026#39;t receive any samples from the accepted replica for a cluster in# this amount of time we will failover to the next replica we receive a sample# from. This value must be greater than the update timeout# CLI flag: -distributor.ha-tracker.failover-timeout[ha_tracker_failover_timeout:\u0026lt;duration\u0026gt;|default=30s]kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, multi, memberlist (experimental).# CLI flag: -distributor.ha-tracker.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -distributor.ha-tracker.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;ha-tracker/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is: distributor.ha-tracker[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is: distributor.ha-tracker[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -distributor.ha-tracker.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -distributor.ha-tracker.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -distributor.ha-tracker.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -distributor.ha-tracker.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# remote_write API max receive message size (bytes).# CLI flag: -distributor.max-recv-msg-size[max_recv_msg_size:\u0026lt;int\u0026gt;|default=104857600]# Timeout for downstream ingesters.# CLI flag: -distributor.remote-timeout[remote_timeout:\u0026lt;duration\u0026gt;|default=2s]# Time to wait before sending more than the minimum successful query requests.# CLI flag: -distributor.extra-query-delay[extra_queue_delay:\u0026lt;duration\u0026gt;|default=0s]# Distribute samples based on all labels, as opposed to solely by user and# metric name.# CLI flag: -distributor.shard-by-all-labels[shard_by_all_labels:\u0026lt;boolean\u0026gt;|default=false]ring:kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, multi, memberlist (experimental).# CLI flag: -distributor.ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -distributor.ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;collectors/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is: distributor.ring[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is: distributor.ring[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -distributor.ring.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -distributor.ring.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -distributor.ring.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -distributor.ring.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# Period at which to heartbeat to the ring.# CLI flag: -distributor.ring.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=5s]# The heartbeat timeout after which distributors are considered unhealthy# within the ring.# CLI flag: -distributor.ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m] ingester_config The ingester_config configures the Cortex ingester.\nwalconfig:# Enable writing of ingested data into WAL.# CLI flag: -ingester.wal-enabled[wal_enabled:\u0026lt;boolean\u0026gt;|default=false]# Enable checkpointing of in-memory chunks. It should always be true when# using normally. Set it to false iff you are doing some small tests as there# is no mechanism to delete the old WAL yet if checkpoint is disabled.# CLI flag: -ingester.checkpoint-enabled[checkpoint_enabled:\u0026lt;boolean\u0026gt;|default=true]# Recover data from existing WAL irrespective of WAL enabled/disabled.# CLI flag: -ingester.recover-from-wal[recover_from_wal:\u0026lt;boolean\u0026gt;|default=false]# Directory to store the WAL and/or recover from WAL.# CLI flag: -ingester.wal-dir[wal_dir:\u0026lt;string\u0026gt;|default=\u0026#34;wal\u0026#34;]# Interval at which checkpoints should be created.# CLI flag: -ingester.checkpoint-duration[checkpoint_duration:\u0026lt;duration\u0026gt;|default=30m]lifecycler:ring:kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, multi, memberlist (experimental).# CLI flag: -ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;collectors/\u0026#34;]# The consul_config configures the consul client.[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# The heartbeat timeout after which ingesters are skipped for reads/writes.# CLI flag: -ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m]# The number of ingesters to write to and read from.# CLI flag: -distributor.replication-factor[replication_factor:\u0026lt;int\u0026gt;|default=3]# Number of tokens for each ingester.# CLI flag: -ingester.num-tokens[num_tokens:\u0026lt;int\u0026gt;|default=128]# Period at which to heartbeat to consul.# CLI flag: -ingester.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=5s]# Observe tokens after generating to resolve collisions. Useful when using# gossiping ring.# CLI flag: -ingester.observe-period[observe_period:\u0026lt;duration\u0026gt;|default=0s]# Period to wait for a claim from another member; will join automatically# after this.# CLI flag: -ingester.join-after[join_after:\u0026lt;duration\u0026gt;|default=0s]# Minimum duration to wait before becoming ready. This is to work around race# conditions with ingesters exiting and updating the ring.# CLI flag: -ingester.min-ready-duration[min_ready_duration:\u0026lt;duration\u0026gt;|default=1m]# Name of network interface to read address from.# CLI flag: -ingester.lifecycler.interface[interface_names:\u0026lt;listofstring\u0026gt;|default=[eth0en0]]# Duration to sleep for before exiting, to ensure metrics are scraped.# CLI flag: -ingester.final-sleep[final_sleep:\u0026lt;duration\u0026gt;|default=30s]# File path where tokens are stored. If empty, tokens are not stored at# shutdown and restored at startup.# CLI flag: -ingester.tokens-file-path[tokens_file_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The availability zone of the host, this instance is running on. Default is# an empty string, which disables zone awareness for writes.# CLI flag: -ingester.availability-zone[availability_zone:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Number of times to try and transfer chunks before falling back to flushing.# Negative value or zero disables hand-over.# CLI flag: -ingester.max-transfer-retries[max_transfer_retries:\u0026lt;int\u0026gt;|default=10]# Period with which to attempt to flush chunks.# CLI flag: -ingester.flush-period[flush_period:\u0026lt;duration\u0026gt;|default=1m]# Period chunks will remain in memory after flushing.# CLI flag: -ingester.retain-period[retain_period:\u0026lt;duration\u0026gt;|default=5m]# Maximum chunk idle time before flushing.# CLI flag: -ingester.max-chunk-idle[max_chunk_idle_time:\u0026lt;duration\u0026gt;|default=5m]# Maximum chunk idle time for chunks terminating in stale markers before# flushing. 0 disables it and a stale series is not flushed until the# max-chunk-idle timeout is reached.# CLI flag: -ingester.max-stale-chunk-idle[max_stale_chunk_idle_time:\u0026lt;duration\u0026gt;|default=2m]# Timeout for individual flush operations.# CLI flag: -ingester.flush-op-timeout[flush_op_timeout:\u0026lt;duration\u0026gt;|default=1m]# Maximum chunk age before flushing.# CLI flag: -ingester.max-chunk-age[max_chunk_age:\u0026lt;duration\u0026gt;|default=12h]# Range of time to subtract from -ingester.max-chunk-age to spread out flushes# CLI flag: -ingester.chunk-age-jitter[chunk_age_jitter:\u0026lt;duration\u0026gt;|default=0s]# Number of concurrent goroutines flushing to dynamodb.# CLI flag: -ingester.concurrent-flushes[concurrent_flushes:\u0026lt;int\u0026gt;|default=50]# If true, spread series flushes across the whole period of# -ingester.max-chunk-age.# CLI flag: -ingester.spread-flushes[spread_flushes:\u0026lt;boolean\u0026gt;|default=true]# Period at which metadata we have not seen will remain in memory before being# deleted.# CLI flag: -ingester.metadata-retain-period[metadata_retain_period:\u0026lt;duration\u0026gt;|default=10m]# Period with which to update the per-user ingestion rates.# CLI flag: -ingester.rate-update-period[rate_update_period:\u0026lt;duration\u0026gt;|default=15s] querier_config The querier_config configures the Cortex querier.\n# The maximum number of concurrent queries.# CLI flag: -querier.max-concurrent[max_concurrent:\u0026lt;int\u0026gt;|default=20]# The timeout for a query.# CLI flag: -querier.timeout[timeout:\u0026lt;duration\u0026gt;|default=2m]# Use iterators to execute query, as opposed to fully materialising the series# in memory.# CLI flag: -querier.iterators[iterators:\u0026lt;boolean\u0026gt;|default=false]# Use batch iterators to execute query, as opposed to fully materialising the# series in memory. Takes precedent over the -querier.iterators flag.# CLI flag: -querier.batch-iterators[batch_iterators:\u0026lt;boolean\u0026gt;|default=true]# Use streaming RPCs to query ingester.# CLI flag: -querier.ingester-streaming[ingester_streaming:\u0026lt;boolean\u0026gt;|default=true]# Maximum number of samples a single query can load into memory.# CLI flag: -querier.max-samples[max_samples:\u0026lt;int\u0026gt;|default=50000000]# Maximum lookback beyond which queries are not sent to ingester. 0 means all# queries are sent to ingester.# CLI flag: -querier.query-ingesters-within[query_ingesters_within:\u0026lt;duration\u0026gt;|default=0s]# The time after which a metric should only be queried from storage and not just# ingesters. 0 means all queries are sent to store.# CLI flag: -querier.query-store-after[query_store_after:\u0026lt;duration\u0026gt;|default=0s]# Maximum duration into the future you can query. 0 to disable.# CLI flag: -querier.max-query-into-future[max_query_into_future:\u0026lt;duration\u0026gt;|default=10m]# The default evaluation interval or step size for subqueries.# CLI flag: -querier.default-evaluation-interval[default_evaluation_interval:\u0026lt;duration\u0026gt;|default=1m]# Active query tracker monitors active queries, and writes them to the file in# given directory. If Cortex discovers any queries in this log during startup,# it will log them to the log file. Setting to empty value disables active query# tracker, which also disables -querier.max-concurrent option.# CLI flag: -querier.active-query-tracker-dir[active_query_tracker_dir:\u0026lt;string\u0026gt;|default=\u0026#34;./active-query-tracker\u0026#34;]# Comma separated list of store-gateway addresses in DNS Service Discovery# format. This option should be set when using the experimental blocks storage# and the store-gateway sharding is disabled (when enabled, the store-gateway# instances form a ring and addresses are picked from the ring).# CLI flag: -experimental.querier.store-gateway-addresses[store_gateway_addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;] query_frontend_config The query_frontend_config configures the Cortex query-frontend.\n# Maximum number of outstanding requests per tenant per frontend; requests# beyond this error with HTTP 429.# CLI flag: -querier.max-outstanding-requests-per-tenant[max_outstanding_per_tenant:\u0026lt;int\u0026gt;|default=100]# Compress HTTP responses.# CLI flag: -querier.compress-http-responses[compress_responses:\u0026lt;boolean\u0026gt;|default=false]# URL of downstream Prometheus.# CLI flag: -frontend.downstream-url[downstream_url:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Log queries that are slower than the specified duration. 0 to disable.# CLI flag: -frontend.log-queries-longer-than[log_queries_longer_than:\u0026lt;duration\u0026gt;|default=0s] queryrange_config The queryrange_config configures the query splitting and caching in the Cortex query-frontend.\n# Split queries by an interval and execute in parallel, 0 disables it. You# should use an a multiple of 24 hours (same as the storage bucketing scheme),# to avoid queriers downloading and processing the same chunks. This also# determines how cache keys are chosen when result caching is enabled# CLI flag: -querier.split-queries-by-interval[split_queries_by_interval:\u0026lt;duration\u0026gt;|default=0s]# Deprecated: Split queries by day and execute in parallel.# CLI flag: -querier.split-queries-by-day[split_queries_by_day:\u0026lt;boolean\u0026gt;|default=false]# Mutate incoming queries to align their start and end with their step.# CLI flag: -querier.align-querier-with-step[align_queries_with_step:\u0026lt;boolean\u0026gt;|default=false]results_cache:cache:# Enable in-memory cache.# CLI flag: -frontend.cache.enable-fifocache[enable_fifocache:\u0026lt;boolean\u0026gt;|default=false]# The default validity of entries for caches unless overridden.# CLI flag: -frontend.default-validity[default_validity:\u0026lt;duration\u0026gt;|default=0s]background:# At what concurrency to write back to cache.# CLI flag: -frontend.background.write-back-concurrency[writeback_goroutines:\u0026lt;int\u0026gt;|default=10]# How many key batches to buffer for background write-back.# CLI flag: -frontend.background.write-back-buffer[writeback_buffer:\u0026lt;int\u0026gt;|default=10000]# The memcached_config block configures how data is stored in Memcached (ie.# expiration).# The CLI flags prefix for this block config is: frontend[memcached:\u0026lt;memcached_config\u0026gt;]# The memcached_client_config configures the client used to connect to# Memcached.# The CLI flags prefix for this block config is: frontend[memcached_client:\u0026lt;memcached_client_config\u0026gt;]# The redis_config configures the Redis backend cache.# The CLI flags prefix for this block config is: frontend[redis:\u0026lt;redis_config\u0026gt;]# The fifo_cache_config configures the local in-memory cache.# The CLI flags prefix for this block config is: frontend[fifocache:\u0026lt;fifo_cache_config\u0026gt;]# Most recent allowed cacheable result, to prevent caching very recent results# that might still be in flux.# CLI flag: -frontend.max-cache-freshness[max_freshness:\u0026lt;duration\u0026gt;|default=1m]# Cache query results.# CLI flag: -querier.cache-results[cache_results:\u0026lt;boolean\u0026gt;|default=false]# Maximum number of retries for a single request; beyond this, the downstream# error is returned.# CLI flag: -querier.max-retries-per-request[max_retries:\u0026lt;int\u0026gt;|default=5]# Perform query parallelisations based on storage sharding configuration and# query ASTs. This feature is supported only by the chunks storage engine.# CLI flag: -querier.parallelise-shardable-queries[parallelise_shardable_queries:\u0026lt;boolean\u0026gt;|default=false] ruler_config The ruler_config configures the Cortex ruler.\n# URL of alerts return path.# CLI flag: -ruler.external.url[external_url:\u0026lt;url\u0026gt;|default=]# How frequently to evaluate rules# CLI flag: -ruler.evaluation-interval[evaluation_interval:\u0026lt;duration\u0026gt;|default=1m]# Duration to delay the evaluation of rules to ensure they underlying metrics# have been pushed to cortex.# CLI flag: -ruler.evaluation-delay-duration[evaluation_delay_duration:\u0026lt;duration\u0026gt;|default=0s]# How frequently to poll for rule changes# CLI flag: -ruler.poll-interval[poll_interval:\u0026lt;duration\u0026gt;|default=1m]storage:# Method to use for backend rule storage (configdb, azure, gcs, s3)# CLI flag: -ruler.storage.type[type:\u0026lt;string\u0026gt;|default=\u0026#34;configdb\u0026#34;]# The configstore_config configures the config database storing rules and# alerts, and is used by the Cortex alertmanager.# The CLI flags prefix for this block config is: ruler[configdb:\u0026lt;configstore_config\u0026gt;]azure:# Name of the blob container used to store chunks. Defaults to `cortex`.# This container must be created before running cortex.# CLI flag: -ruler.storage.azure.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;cortex\u0026#34;]# The Microsoft Azure account name to be used# CLI flag: -ruler.storage.azure.account-name[account_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The Microsoft Azure account key to use.# CLI flag: -ruler.storage.azure.account-key[account_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Preallocated buffer size for downloads (default is 512KB)# CLI flag: -ruler.storage.azure.download-buffer-size[download_buffer_size:\u0026lt;int\u0026gt;|default=512000]# Preallocated buffer size for up;oads (default is 256KB)# CLI flag: -ruler.storage.azure.upload-buffer-size[upload_buffer_size:\u0026lt;int\u0026gt;|default=256000]# Number of buffers used to used to upload a chunk. (defaults to 1)# CLI flag: -ruler.storage.azure.download-buffer-count[upload_buffer_count:\u0026lt;int\u0026gt;|default=1]# Timeout for requests made against azure blob storage. Defaults to 30# seconds.# CLI flag: -ruler.storage.azure.request-timeout[request_timeout:\u0026lt;duration\u0026gt;|default=30s]# Number of retries for a request which times out.# CLI flag: -ruler.storage.azure.max-retries[max_retries:\u0026lt;int\u0026gt;|default=5]# Minimum time to wait before retrying a request.# CLI flag: -ruler.storage.azure.min-retry-delay[min_retry_delay:\u0026lt;duration\u0026gt;|default=10ms]# Maximum time to wait before retrying a request.# CLI flag: -ruler.storage.azure.max-retry-delay[max_retry_delay:\u0026lt;duration\u0026gt;|default=500ms]gcs:# Name of GCS bucket to put chunks in.# CLI flag: -ruler.storage.gcs.bucketname[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The size of the buffer that GCS client for each PUT request. 0 to disable# buffering.# CLI flag: -ruler.storage.gcs.chunk-buffer-size[chunk_buffer_size:\u0026lt;int\u0026gt;|default=0]# The duration after which the requests to GCS should be timed out.# CLI flag: -ruler.storage.gcs.request-timeout[request_timeout:\u0026lt;duration\u0026gt;|default=0s]s3:# S3 endpoint URL with escaped Key and Secret encoded. If only region is# specified as a host, proper endpoint will be deduced. Use# inmemory:///\u0026lt;bucket-name\u0026gt; to use a mock in-memory implementation.# CLI flag: -ruler.storage.s3.url[s3:\u0026lt;url\u0026gt;|default=]# Comma separated list of bucket names to evenly distribute chunks over.# Overrides any buckets specified in s3.url flag# CLI flag: -ruler.storage.s3.buckets[bucketnames:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Set this to `true` to force the request to use path-style addressing.# CLI flag: -ruler.storage.s3.force-path-style[s3forcepathstyle:\u0026lt;boolean\u0026gt;|default=false]swift:# Openstack authentication URL.# CLI flag: -ruler.storage.swift.auth-url[auth_url:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack username for the api.# CLI flag: -ruler.storage.swift.username[username:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain name.# CLI flag: -ruler.storage.swift.user-domain-name[user_domain_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain id.# CLI flag: -ruler.storage.swift.user-domain-id[user_domain_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack userid for the api.# CLI flag: -ruler.storage.swift.user-id[user_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack api key.# CLI flag: -ruler.storage.swift.password[password:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain id.# CLI flag: -ruler.storage.swift.domain-id[domain_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain name.# CLI flag: -ruler.storage.swift.domain-name[domain_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack project id (v2,v3 auth only).# CLI flag: -ruler.storage.swift.project-id[project_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack project name (v2,v3 auth only).# CLI flag: -ruler.storage.swift.project-name[project_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Id of the project\u0026#39;s domain (v3 auth only), only needed if it differs the# from user domain.# CLI flag: -ruler.storage.swift.project-domain-id[project_domain_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Name of the project\u0026#39;s domain (v3 auth only), only needed if it differs# from the user domain.# CLI flag: -ruler.storage.swift.project-domain-name[project_domain_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack Region to use eg LON, ORD - default is use first region (v2,v3# auth only)# CLI flag: -ruler.storage.swift.region-name[region_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Name of the Swift container to put chunks in.# CLI flag: -ruler.storage.swift.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;cortex\u0026#34;]# file path to store temporary rule files for the prometheus rule managers# CLI flag: -ruler.rule-path[rule_path:\u0026lt;string\u0026gt;|default=\u0026#34;/rules\u0026#34;]# URL of the Alertmanager to send notifications to.# CLI flag: -ruler.alertmanager-url[alertmanager_url:\u0026lt;url\u0026gt;|default=]# Use DNS SRV records to discover alertmanager hosts.# CLI flag: -ruler.alertmanager-discovery[enable_alertmanager_discovery:\u0026lt;boolean\u0026gt;|default=false]# How long to wait between refreshing alertmanager hosts.# CLI flag: -ruler.alertmanager-refresh-interval[alertmanager_refresh_interval:\u0026lt;duration\u0026gt;|default=1m]# If enabled requests to alertmanager will utilize the V2 API.# CLI flag: -ruler.alertmanager-use-v2[enable_alertmanager_v2:\u0026lt;boolean\u0026gt;|default=false]# Capacity of the queue for notifications to be sent to the Alertmanager.# CLI flag: -ruler.notification-queue-capacity[notification_queue_capacity:\u0026lt;int\u0026gt;|default=10000]# HTTP timeout duration when sending notifications to the Alertmanager.# CLI flag: -ruler.notification-timeout[notification_timeout:\u0026lt;duration\u0026gt;|default=10s]# Distribute rule evaluation using ring backend# CLI flag: -ruler.enable-sharding[enable_sharding:\u0026lt;boolean\u0026gt;|default=false]# Time to spend searching for a pending ruler when shutting down.# CLI flag: -ruler.search-pending-for[search_pending_for:\u0026lt;duration\u0026gt;|default=5m]ring:kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, multi, memberlist (experimental).# CLI flag: -ruler.ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -ruler.ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;rulers/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is: ruler.ring[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is: ruler.ring[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -ruler.ring.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -ruler.ring.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -ruler.ring.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -ruler.ring.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# Period at which to heartbeat to the ring.# CLI flag: -ruler.ring.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=5s]# The heartbeat timeout after which rulers are considered unhealthy within the# ring.# CLI flag: -ruler.ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m]# Number of tokens for each ingester.# CLI flag: -ruler.ring.num-tokens[num_tokens:\u0026lt;int\u0026gt;|default=128]# Period with which to attempt to flush rule groups.# CLI flag: -ruler.flush-period[flush_period:\u0026lt;duration\u0026gt;|default=1m]# Enable the ruler api# CLI flag: -experimental.ruler.enable-api[enable_api:\u0026lt;boolean\u0026gt;|default=false] alertmanager_config The alertmanager_config configures the Cortex alertmanager.\n# Base path for data storage.# CLI flag: -alertmanager.storage.path[data_dir:\u0026lt;string\u0026gt;|default=\u0026#34;data/\u0026#34;]# How long to keep data for.# CLI flag: -alertmanager.storage.retention[retention:\u0026lt;duration\u0026gt;|default=120h]# The URL under which Alertmanager is externally reachable (for example, if# Alertmanager is served via a reverse proxy). Used for generating relative and# absolute links back to Alertmanager itself. If the URL has a path portion, it# will be used to prefix all HTTP endpoints served by Alertmanager. If omitted,# relevant URL components will be derived automatically.# CLI flag: -alertmanager.web.external-url[external_url:\u0026lt;url\u0026gt;|default=]# How frequently to poll Cortex configs# CLI flag: -alertmanager.configs.poll-interval[poll_interval:\u0026lt;duration\u0026gt;|default=15s]# Listen address for cluster.# CLI flag: -cluster.listen-address[cluster_bind_address:\u0026lt;string\u0026gt;|default=\u0026#34;0.0.0.0:9094\u0026#34;]# Explicit address to advertise in cluster.# CLI flag: -cluster.advertise-address[cluster_advertise_address:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Initial peers (may be repeated).# CLI flag: -cluster.peer[peers:\u0026lt;listofstring\u0026gt;|default=]# Time to wait between peers to send notifications.# CLI flag: -cluster.peer-timeout[peer_timeout:\u0026lt;duration\u0026gt;|default=15s]# Filename of fallback config to use if none specified for instance.# CLI flag: -alertmanager.configs.fallback[fallback_config_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Root of URL to generate if config is http://internal.monitor# CLI flag: -alertmanager.configs.auto-webhook-root[auto_webhook_root:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]storage:# Type of backend to use to store alertmanager configs. Supported values are:# \u0026#34;configdb\u0026#34;, \u0026#34;local\u0026#34;.# CLI flag: -alertmanager.storage.type[type:\u0026lt;string\u0026gt;|default=\u0026#34;configdb\u0026#34;]# The configstore_config configures the config database storing rules and# alerts, and is used by the Cortex alertmanager.# The CLI flags prefix for this block config is: alertmanager[configdb:\u0026lt;configstore_config\u0026gt;]local:# Path at which alertmanager configurations are stored.# CLI flag: -alertmanager.storage.local.path[path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;] table_manager_config The table_manager_config configures the Cortex table-manager.\n# If true, disable all changes to DB capacity# CLI flag: -table-manager.throughput-updates-disabled[throughput_updates_disabled:\u0026lt;boolean\u0026gt;|default=false]# If true, enables retention deletes of DB tables# CLI flag: -table-manager.retention-deletes-enabled[retention_deletes_enabled:\u0026lt;boolean\u0026gt;|default=false]# Tables older than this retention period are deleted. Note: This setting is# destructive to data!(default: 0, which disables deletion)# CLI flag: -table-manager.retention-period[retention_period:\u0026lt;duration\u0026gt;|default=0s]# How frequently to poll backend to learn our capacity.# CLI flag: -table-manager.poll-interval[poll_interval:\u0026lt;duration\u0026gt;|default=2m]# Periodic tables grace period (duration which table will be created/deleted# before/after it\u0026#39;s needed).# CLI flag: -table-manager.periodic-table.grace-period[creation_grace_period:\u0026lt;duration\u0026gt;|default=10m]index_tables_provisioning:# Enables on demand throughput provisioning for the storage provider (if# supported). Applies only to tables which are not autoscaled. Supported by# DynamoDB# CLI flag: -table-manager.index-table.enable-ondemand-throughput-mode[enable_ondemand_throughput_mode:\u0026lt;boolean\u0026gt;|default=false]# Table default write throughput. Supported by DynamoDB# CLI flag: -table-manager.index-table.write-throughput[provisioned_write_throughput:\u0026lt;int\u0026gt;|default=1000]# Table default read throughput. Supported by DynamoDB# CLI flag: -table-manager.index-table.read-throughput[provisioned_read_throughput:\u0026lt;int\u0026gt;|default=300]# Enables on demand throughput provisioning for the storage provider (if# supported). Applies only to tables which are not autoscaled. Supported by# DynamoDB# CLI flag: -table-manager.index-table.inactive-enable-ondemand-throughput-mode[enable_inactive_throughput_on_demand_mode:\u0026lt;boolean\u0026gt;|default=false]# Table write throughput for inactive tables. Supported by DynamoDB# CLI flag: -table-manager.index-table.inactive-write-throughput[inactive_write_throughput:\u0026lt;int\u0026gt;|default=1]# Table read throughput for inactive tables. Supported by DynamoDB# CLI flag: -table-manager.index-table.inactive-read-throughput[inactive_read_throughput:\u0026lt;int\u0026gt;|default=300]write_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.index-table.write-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.index-table.write-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.index-table.write-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.index-table.write-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.index-table.write-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.index-table.write-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.index-table.write-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]inactive_write_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]# Number of last inactive tables to enable write autoscale.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale-last-n[inactive_write_scale_lastn:\u0026lt;int\u0026gt;|default=4]read_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.index-table.read-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.index-table.read-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.index-table.read-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.index-table.read-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.index-table.read-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.index-table.read-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.index-table.read-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]inactive_read_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]# Number of last inactive tables to enable read autoscale.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale-last-n[inactive_read_scale_lastn:\u0026lt;int\u0026gt;|default=4]chunk_tables_provisioning:# Enables on demand throughput provisioning for the storage provider (if# supported). Applies only to tables which are not autoscaled. Supported by# DynamoDB# CLI flag: -table-manager.chunk-table.enable-ondemand-throughput-mode[enable_ondemand_throughput_mode:\u0026lt;boolean\u0026gt;|default=false]# Table default write throughput. Supported by DynamoDB# CLI flag: -table-manager.chunk-table.write-throughput[provisioned_write_throughput:\u0026lt;int\u0026gt;|default=1000]# Table default read throughput. Supported by DynamoDB# CLI flag: -table-manager.chunk-table.read-throughput[provisioned_read_throughput:\u0026lt;int\u0026gt;|default=300]# Enables on demand throughput provisioning for the storage provider (if# supported). Applies only to tables which are not autoscaled. Supported by# DynamoDB# CLI flag: -table-manager.chunk-table.inactive-enable-ondemand-throughput-mode[enable_inactive_throughput_on_demand_mode:\u0026lt;boolean\u0026gt;|default=false]# Table write throughput for inactive tables. Supported by DynamoDB# CLI flag: -table-manager.chunk-table.inactive-write-throughput[inactive_write_throughput:\u0026lt;int\u0026gt;|default=1]# Table read throughput for inactive tables. Supported by DynamoDB# CLI flag: -table-manager.chunk-table.inactive-read-throughput[inactive_read_throughput:\u0026lt;int\u0026gt;|default=300]write_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.chunk-table.write-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.chunk-table.write-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.chunk-table.write-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.chunk-table.write-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.chunk-table.write-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.chunk-table.write-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.chunk-table.write-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]inactive_write_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]# Number of last inactive tables to enable write autoscale.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale-last-n[inactive_write_scale_lastn:\u0026lt;int\u0026gt;|default=4]read_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.chunk-table.read-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.chunk-table.read-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.chunk-table.read-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.chunk-table.read-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.chunk-table.read-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.chunk-table.read-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.chunk-table.read-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]inactive_read_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]# Number of last inactive tables to enable read autoscale.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale-last-n[inactive_read_scale_lastn:\u0026lt;int\u0026gt;|default=4] storage_config The storage_config configures where Cortex stores the data (chunks storage engine).\n# The storage engine to use: chunks or tsdb. Be aware tsdb is experimental and# shouldn\u0026#39;t be used in production.# CLI flag: -store.engine[engine:\u0026lt;string\u0026gt;|default=\u0026#34;chunks\u0026#34;]aws:dynamodb:# DynamoDB endpoint URL with escaped Key and Secret encoded. If only region# is specified as a host, proper endpoint will be deduced. Use# inmemory:///\u0026lt;table-name\u0026gt; to use a mock in-memory implementation.# CLI flag: -dynamodb.url[dynamodb_url:\u0026lt;url\u0026gt;|default=]# DynamoDB table management requests per second limit.# CLI flag: -dynamodb.api-limit[api_limit:\u0026lt;float\u0026gt;|default=2]# DynamoDB rate cap to back off when throttled.# CLI flag: -dynamodb.throttle-limit[throttle_limit:\u0026lt;float\u0026gt;|default=10]metrics:# Use metrics-based autoscaling, via this query URL# CLI flag: -metrics.url[url:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Queue length above which we will scale up capacity# CLI flag: -metrics.target-queue-length[target_queue_length:\u0026lt;int\u0026gt;|default=100000]# Scale up capacity by this multiple# CLI flag: -metrics.scale-up-factor[scale_up_factor:\u0026lt;float\u0026gt;|default=1.3]# Ignore throttling below this level (rate per second)# CLI flag: -metrics.ignore-throttle-below[ignore_throttle_below:\u0026lt;float\u0026gt;|default=1]# query to fetch ingester queue length# CLI flag: -metrics.queue-length-query[queue_length_query:\u0026lt;string\u0026gt;|default=\u0026#34;sum(avg_over_time(cortex_ingester_flush_queue_length{job=\\\u0026#34;cortex/ingester\\\u0026#34;}[2m]))\u0026#34;]# query to fetch throttle rates per table# CLI flag: -metrics.write-throttle-query[write_throttle_query:\u0026lt;string\u0026gt;|default=\u0026#34;sum(rate(cortex_dynamo_throttled_total{operation=\\\u0026#34;DynamoDB.BatchWriteItem\\\u0026#34;}[1m])) by (table) \u0026gt; 0\u0026#34;]# query to fetch write capacity usage per table# CLI flag: -metrics.usage-query[write_usage_query:\u0026lt;string\u0026gt;|default=\u0026#34;sum(rate(cortex_dynamo_consumed_capacity_total{operation=\\\u0026#34;DynamoDB.BatchWriteItem\\\u0026#34;}[15m])) by (table) \u0026gt; 0\u0026#34;]# query to fetch read capacity usage per table# CLI flag: -metrics.read-usage-query[read_usage_query:\u0026lt;string\u0026gt;|default=\u0026#34;sum(rate(cortex_dynamo_consumed_capacity_total{operation=\\\u0026#34;DynamoDB.QueryPages\\\u0026#34;}[1h])) by (table) \u0026gt; 0\u0026#34;]# query to fetch read errors per table# CLI flag: -metrics.read-error-query[read_error_query:\u0026lt;string\u0026gt;|default=\u0026#34;sum(increase(cortex_dynamo_failures_total{operation=\\\u0026#34;DynamoDB.QueryPages\\\u0026#34;,error=\\\u0026#34;ProvisionedThroughputExceededException\\\u0026#34;}[1m])) by (table) \u0026gt; 0\u0026#34;]# Number of chunks to group together to parallelise fetches (zero to# disable)# CLI flag: -dynamodb.chunk-gang-size[chunk_gang_size:\u0026lt;int\u0026gt;|default=10]# Max number of chunk-get operations to start in parallel# CLI flag: -dynamodb.chunk.get-max-parallelism[chunk_get_max_parallelism:\u0026lt;int\u0026gt;|default=32]# S3 endpoint URL with escaped Key and Secret encoded. If only region is# specified as a host, proper endpoint will be deduced. Use# inmemory:///\u0026lt;bucket-name\u0026gt; to use a mock in-memory implementation.# CLI flag: -s3.url[s3:\u0026lt;url\u0026gt;|default=]# Comma separated list of bucket names to evenly distribute chunks over.# Overrides any buckets specified in s3.url flag# CLI flag: -s3.buckets[bucketnames:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Set this to `true` to force the request to use path-style addressing.# CLI flag: -s3.force-path-style[s3forcepathstyle:\u0026lt;boolean\u0026gt;|default=false]azure:# Name of the blob container used to store chunks. Defaults to `cortex`. This# container must be created before running cortex.# CLI flag: -azure.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;cortex\u0026#34;]# The Microsoft Azure account name to be used# CLI flag: -azure.account-name[account_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The Microsoft Azure account key to use.# CLI flag: -azure.account-key[account_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Preallocated buffer size for downloads (default is 512KB)# CLI flag: -azure.download-buffer-size[download_buffer_size:\u0026lt;int\u0026gt;|default=512000]# Preallocated buffer size for up;oads (default is 256KB)# CLI flag: -azure.upload-buffer-size[upload_buffer_size:\u0026lt;int\u0026gt;|default=256000]# Number of buffers used to used to upload a chunk. (defaults to 1)# CLI flag: -azure.download-buffer-count[upload_buffer_count:\u0026lt;int\u0026gt;|default=1]# Timeout for requests made against azure blob storage. Defaults to 30# seconds.# CLI flag: -azure.request-timeout[request_timeout:\u0026lt;duration\u0026gt;|default=30s]# Number of retries for a request which times out.# CLI flag: -azure.max-retries[max_retries:\u0026lt;int\u0026gt;|default=5]# Minimum time to wait before retrying a request.# CLI flag: -azure.min-retry-delay[min_retry_delay:\u0026lt;duration\u0026gt;|default=10ms]# Maximum time to wait before retrying a request.# CLI flag: -azure.max-retry-delay[max_retry_delay:\u0026lt;duration\u0026gt;|default=500ms]bigtable:# Bigtable project ID.# CLI flag: -bigtable.project[project:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Bigtable instance ID.# CLI flag: -bigtable.instance[instance:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]grpc_client_config:# gRPC client max receive message size (bytes).# CLI flag: -bigtable.grpc-max-recv-msg-size[max_recv_msg_size:\u0026lt;int\u0026gt;|default=104857600]# gRPC client max send message size (bytes).# CLI flag: -bigtable.grpc-max-send-msg-size[max_send_msg_size:\u0026lt;int\u0026gt;|default=16777216]# Use compression when sending messages.# CLI flag: -bigtable.grpc-use-gzip-compression[use_gzip_compression:\u0026lt;boolean\u0026gt;|default=false]# Rate limit for gRPC client; 0 means disabled.# CLI flag: -bigtable.grpc-client-rate-limit[rate_limit:\u0026lt;float\u0026gt;|default=0]# Rate limit burst for gRPC client.# CLI flag: -bigtable.grpc-client-rate-limit-burst[rate_limit_burst:\u0026lt;int\u0026gt;|default=0]# Enable backoff and retry when we hit ratelimits.# CLI flag: -bigtable.backoff-on-ratelimits[backoff_on_ratelimits:\u0026lt;boolean\u0026gt;|default=false]backoff_config:# Minimum delay when backing off.# CLI flag: -bigtable.backoff-min-period[min_period:\u0026lt;duration\u0026gt;|default=100ms]# Maximum delay when backing off.# CLI flag: -bigtable.backoff-max-period[max_period:\u0026lt;duration\u0026gt;|default=10s]# Number of times to backoff and retry before failing.# CLI flag: -bigtable.backoff-retries[max_retries:\u0026lt;int\u0026gt;|default=10]# If enabled, once a tables info is fetched, it is cached.# CLI flag: -bigtable.table-cache.enabled[table_cache_enabled:\u0026lt;boolean\u0026gt;|default=true]# Duration to cache tables before checking again.# CLI flag: -bigtable.table-cache.expiration[table_cache_expiration:\u0026lt;duration\u0026gt;|default=30m]gcs:# Name of GCS bucket to put chunks in.# CLI flag: -gcs.bucketname[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The size of the buffer that GCS client for each PUT request. 0 to disable# buffering.# CLI flag: -gcs.chunk-buffer-size[chunk_buffer_size:\u0026lt;int\u0026gt;|default=0]# The duration after which the requests to GCS should be timed out.# CLI flag: -gcs.request-timeout[request_timeout:\u0026lt;duration\u0026gt;|default=0s]cassandra:# Comma-separated hostnames or IPs of Cassandra instances.# CLI flag: -cassandra.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Port that Cassandra is running on# CLI flag: -cassandra.port[port:\u0026lt;int\u0026gt;|default=9042]# Keyspace to use in Cassandra.# CLI flag: -cassandra.keyspace[keyspace:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Consistency level for Cassandra.# CLI flag: -cassandra.consistency[consistency:\u0026lt;string\u0026gt;|default=\u0026#34;QUORUM\u0026#34;]# Replication factor to use in Cassandra.# CLI flag: -cassandra.replication-factor[replication_factor:\u0026lt;int\u0026gt;|default=1]# Instruct the cassandra driver to not attempt to get host info from the# system.peers table.# CLI flag: -cassandra.disable-initial-host-lookup[disable_initial_host_lookup:\u0026lt;boolean\u0026gt;|default=false]# Use SSL when connecting to cassandra instances.# CLI flag: -cassandra.ssl[SSL:\u0026lt;boolean\u0026gt;|default=false]# Require SSL certificate validation.# CLI flag: -cassandra.host-verification[host_verification:\u0026lt;boolean\u0026gt;|default=true]# Path to certificate file to verify the peer.# CLI flag: -cassandra.ca-path[CA_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Enable password authentication when connecting to cassandra.# CLI flag: -cassandra.auth[auth:\u0026lt;boolean\u0026gt;|default=false]# Username to use when connecting to cassandra.# CLI flag: -cassandra.username[username:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Password to use when connecting to cassandra.# CLI flag: -cassandra.password[password:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# File containing password to use when connecting to cassandra.# CLI flag: -cassandra.password-file[password_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# If set, when authenticating with cassandra a custom authenticator will be# expected during the handshake. This flag can be set multiple times.# CLI flag: -cassandra.custom-authenticator[custom_authenticators:\u0026lt;listofstring\u0026gt;|default=]# Timeout when connecting to cassandra.# CLI flag: -cassandra.timeout[timeout:\u0026lt;duration\u0026gt;|default=2s]# Initial connection timeout, used during initial dial to server.# CLI flag: -cassandra.connect-timeout[connect_timeout:\u0026lt;duration\u0026gt;|default=5s]# Number of retries to perform on a request. (Default is 0: no retries)# CLI flag: -cassandra.max-retries[max_retries:\u0026lt;int\u0026gt;|default=0]# Maximum time to wait before retrying a failed request. (Default = 10s)# CLI flag: -cassandra.retry-max-backoff[retry_max_backoff:\u0026lt;duration\u0026gt;|default=10s]# Minimum time to wait before retrying a failed request. (Default = 100ms)# CLI flag: -cassandra.retry-min-backoff[retry_min_backoff:\u0026lt;duration\u0026gt;|default=100ms]# Limit number of concurrent queries to Cassandra. (Default is 0: no limit)# CLI flag: -cassandra.query-concurrency[query_concurrency:\u0026lt;int\u0026gt;|default=0]boltdb:# Location of BoltDB index files.# CLI flag: -boltdb.dir[directory:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]filesystem:# Directory to store chunks in.# CLI flag: -local.chunk-directory[directory:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]swift:# Openstack authentication URL.# CLI flag: -swift.auth-url[auth_url:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack username for the api.# CLI flag: -swift.username[username:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain name.# CLI flag: -swift.user-domain-name[user_domain_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain id.# CLI flag: -swift.user-domain-id[user_domain_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack userid for the api.# CLI flag: -swift.user-id[user_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack api key.# CLI flag: -swift.password[password:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain id.# CLI flag: -swift.domain-id[domain_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain name.# CLI flag: -swift.domain-name[domain_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack project id (v2,v3 auth only).# CLI flag: -swift.project-id[project_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack project name (v2,v3 auth only).# CLI flag: -swift.project-name[project_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Id of the project\u0026#39;s domain (v3 auth only), only needed if it differs the# from user domain.# CLI flag: -swift.project-domain-id[project_domain_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Name of the project\u0026#39;s domain (v3 auth only), only needed if it differs from# the user domain.# CLI flag: -swift.project-domain-name[project_domain_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack Region to use eg LON, ORD - default is use first region (v2,v3# auth only)# CLI flag: -swift.region-name[region_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Name of the Swift container to put chunks in.# CLI flag: -swift.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;cortex\u0026#34;]# Cache validity for active index entries. Should be no higher than# -ingester.max-chunk-idle.# CLI flag: -store.index-cache-validity[index_cache_validity:\u0026lt;duration\u0026gt;|default=5m]index_queries_cache_config:# Cache config for index entry reading. Enable in-memory cache.# CLI flag: -store.index-cache-read.cache.enable-fifocache[enable_fifocache:\u0026lt;boolean\u0026gt;|default=false]# Cache config for index entry reading. The default validity of entries for# caches unless overridden.# CLI flag: -store.index-cache-read.default-validity[default_validity:\u0026lt;duration\u0026gt;|default=0s]background:# Cache config for index entry reading. At what concurrency to write back to# cache.# CLI flag: -store.index-cache-read.background.write-back-concurrency[writeback_goroutines:\u0026lt;int\u0026gt;|default=10]# Cache config for index entry reading. How many key batches to buffer for# background write-back.# CLI flag: -store.index-cache-read.background.write-back-buffer[writeback_buffer:\u0026lt;int\u0026gt;|default=10000]# The memcached_config block configures how data is stored in Memcached (ie.# expiration).# The CLI flags prefix for this block config is: store.index-cache-read[memcached:\u0026lt;memcached_config\u0026gt;]# The memcached_client_config configures the client used to connect to# Memcached.# The CLI flags prefix for this block config is: store.index-cache-read[memcached_client:\u0026lt;memcached_client_config\u0026gt;]# The redis_config configures the Redis backend cache.# The CLI flags prefix for this block config is: store.index-cache-read[redis:\u0026lt;redis_config\u0026gt;]# The fifo_cache_config configures the local in-memory cache.# The CLI flags prefix for this block config is: store.index-cache-read[fifocache:\u0026lt;fifo_cache_config\u0026gt;]delete_store:# Store for keeping delete request# CLI flag: -deletes.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Name of the table which stores delete requests# CLI flag: -deletes.requests-table-name[requests_table_name:\u0026lt;string\u0026gt;|default=\u0026#34;delete_requests\u0026#34;] flusher_config The flusher_config configures the WAL flusher target, used to manually run one-time flushes when scaling down ingesters.\n# Directory to read WAL from.# CLI flag: -flusher.wal-dir[wal_dir:\u0026lt;string\u0026gt;|default=\u0026#34;wal\u0026#34;]# Number of concurrent goroutines flushing to dynamodb.# CLI flag: -flusher.concurrent-flushes[concurrent_flushes:\u0026lt;int\u0026gt;|default=50]# Timeout for individual flush operations.# CLI flag: -flusher.flush-op-timeout[flush_op_timeout:\u0026lt;duration\u0026gt;|default=2m] chunk_store_config The chunk_store_config configures how Cortex stores the data (chunks storage engine).\nchunk_cache_config:# Cache config for chunks. Enable in-memory cache.# CLI flag: -store.chunks-cache.cache.enable-fifocache[enable_fifocache:\u0026lt;boolean\u0026gt;|default=false]# Cache config for chunks. The default validity of entries for caches unless# overridden.# CLI flag: -store.chunks-cache.default-validity[default_validity:\u0026lt;duration\u0026gt;|default=0s]background:# Cache config for chunks. At what concurrency to write back to cache.# CLI flag: -store.chunks-cache.background.write-back-concurrency[writeback_goroutines:\u0026lt;int\u0026gt;|default=10]# Cache config for chunks. How many key batches to buffer for background# write-back.# CLI flag: -store.chunks-cache.background.write-back-buffer[writeback_buffer:\u0026lt;int\u0026gt;|default=10000]# The memcached_config block configures how data is stored in Memcached (ie.# expiration).# The CLI flags prefix for this block config is: store.chunks-cache[memcached:\u0026lt;memcached_config\u0026gt;]# The memcached_client_config configures the client used to connect to# Memcached.# The CLI flags prefix for this block config is: store.chunks-cache[memcached_client:\u0026lt;memcached_client_config\u0026gt;]# The redis_config configures the Redis backend cache.# The CLI flags prefix for this block config is: store.chunks-cache[redis:\u0026lt;redis_config\u0026gt;]# The fifo_cache_config configures the local in-memory cache.# The CLI flags prefix for this block config is: store.chunks-cache[fifocache:\u0026lt;fifo_cache_config\u0026gt;]write_dedupe_cache_config:# Cache config for index entry writing. Enable in-memory cache.# CLI flag: -store.index-cache-write.cache.enable-fifocache[enable_fifocache:\u0026lt;boolean\u0026gt;|default=false]# Cache config for index entry writing. The default validity of entries for# caches unless overridden.# CLI flag: -store.index-cache-write.default-validity[default_validity:\u0026lt;duration\u0026gt;|default=0s]background:# Cache config for index entry writing. At what concurrency to write back to# cache.# CLI flag: -store.index-cache-write.background.write-back-concurrency[writeback_goroutines:\u0026lt;int\u0026gt;|default=10]# Cache config for index entry writing. How many key batches to buffer for# background write-back.# CLI flag: -store.index-cache-write.background.write-back-buffer[writeback_buffer:\u0026lt;int\u0026gt;|default=10000]# The memcached_config block configures how data is stored in Memcached (ie.# expiration).# The CLI flags prefix for this block config is: store.index-cache-write[memcached:\u0026lt;memcached_config\u0026gt;]# The memcached_client_config configures the client used to connect to# Memcached.# The CLI flags prefix for this block config is: store.index-cache-write[memcached_client:\u0026lt;memcached_client_config\u0026gt;]# The redis_config configures the Redis backend cache.# The CLI flags prefix for this block config is: store.index-cache-write[redis:\u0026lt;redis_config\u0026gt;]# The fifo_cache_config configures the local in-memory cache.# The CLI flags prefix for this block config is: store.index-cache-write[fifocache:\u0026lt;fifo_cache_config\u0026gt;]# Cache index entries older than this period. 0 to disable.# CLI flag: -store.cache-lookups-older-than[cache_lookups_older_than:\u0026lt;duration\u0026gt;|default=0s]# Limit how long back data can be queried# CLI flag: -store.max-look-back-period[max_look_back_period:\u0026lt;duration\u0026gt;|default=0s] ingester_client_config The ingester_client_config configures how the Cortex distributors connect to the ingesters.\ngrpc_client_config:# gRPC client max receive message size (bytes).# CLI flag: -ingester.client.grpc-max-recv-msg-size[max_recv_msg_size:\u0026lt;int\u0026gt;|default=104857600]# gRPC client max send message size (bytes).# CLI flag: -ingester.client.grpc-max-send-msg-size[max_send_msg_size:\u0026lt;int\u0026gt;|default=16777216]# Use compression when sending messages.# CLI flag: -ingester.client.grpc-use-gzip-compression[use_gzip_compression:\u0026lt;boolean\u0026gt;|default=false]# Rate limit for gRPC client; 0 means disabled.# CLI flag: -ingester.client.grpc-client-rate-limit[rate_limit:\u0026lt;float\u0026gt;|default=0]# Rate limit burst for gRPC client.# CLI flag: -ingester.client.grpc-client-rate-limit-burst[rate_limit_burst:\u0026lt;int\u0026gt;|default=0]# Enable backoff and retry when we hit ratelimits.# CLI flag: -ingester.client.backoff-on-ratelimits[backoff_on_ratelimits:\u0026lt;boolean\u0026gt;|default=false]backoff_config:# Minimum delay when backing off.# CLI flag: -ingester.client.backoff-min-period[min_period:\u0026lt;duration\u0026gt;|default=100ms]# Maximum delay when backing off.# CLI flag: -ingester.client.backoff-max-period[max_period:\u0026lt;duration\u0026gt;|default=10s]# Number of times to backoff and retry before failing.# CLI flag: -ingester.client.backoff-retries[max_retries:\u0026lt;int\u0026gt;|default=10] frontend_worker_config The frontend_worker_config configures the worker - running within the Cortex querier - picking up and executing queries enqueued by the query-frontend.\n# Address of query frontend service, in host:port format.# CLI flag: -querier.frontend-address[frontend_address:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Number of simultaneous queries to process per query frontend.# CLI flag: -querier.worker-parallelism[parallelism:\u0026lt;int\u0026gt;|default=10]# Force worker concurrency to match the -querier.max-concurrent option.# Overrides querier.worker-parallelism.# CLI flag: -querier.worker-match-max-concurrent[match_max_concurrent:\u0026lt;boolean\u0026gt;|default=false]# How often to query DNS.# CLI flag: -querier.dns-lookup-period[dns_lookup_duration:\u0026lt;duration\u0026gt;|default=10s]grpc_client_config:# gRPC client max receive message size (bytes).# CLI flag: -querier.frontend-client.grpc-max-recv-msg-size[max_recv_msg_size:\u0026lt;int\u0026gt;|default=104857600]# gRPC client max send message size (bytes).# CLI flag: -querier.frontend-client.grpc-max-send-msg-size[max_send_msg_size:\u0026lt;int\u0026gt;|default=16777216]# Use compression when sending messages.# CLI flag: -querier.frontend-client.grpc-use-gzip-compression[use_gzip_compression:\u0026lt;boolean\u0026gt;|default=false]# Rate limit for gRPC client; 0 means disabled.# CLI flag: -querier.frontend-client.grpc-client-rate-limit[rate_limit:\u0026lt;float\u0026gt;|default=0]# Rate limit burst for gRPC client.# CLI flag: -querier.frontend-client.grpc-client-rate-limit-burst[rate_limit_burst:\u0026lt;int\u0026gt;|default=0]# Enable backoff and retry when we hit ratelimits.# CLI flag: -querier.frontend-client.backoff-on-ratelimits[backoff_on_ratelimits:\u0026lt;boolean\u0026gt;|default=false]backoff_config:# Minimum delay when backing off.# CLI flag: -querier.frontend-client.backoff-min-period[min_period:\u0026lt;duration\u0026gt;|default=100ms]# Maximum delay when backing off.# CLI flag: -querier.frontend-client.backoff-max-period[max_period:\u0026lt;duration\u0026gt;|default=10s]# Number of times to backoff and retry before failing.# CLI flag: -querier.frontend-client.backoff-retries[max_retries:\u0026lt;int\u0026gt;|default=10] etcd_config The etcd_config configures the etcd client. The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n no prefix compactor.ring distributor.ha-tracker distributor.ring experimental.store-gateway.sharding-ring ruler.ring \u0026nbsp;\n# The etcd endpoints to connect to.# CLI flag: -\u0026lt;prefix\u0026gt;.etcd.endpoints[endpoints:\u0026lt;listofstring\u0026gt;|default=[]]# The dial timeout for the etcd connection.# CLI flag: -\u0026lt;prefix\u0026gt;.etcd.dial-timeout[dial_timeout:\u0026lt;duration\u0026gt;|default=10s]# The maximum number of retries to do for failed ops.# CLI flag: -\u0026lt;prefix\u0026gt;.etcd.max-retries[max_retries:\u0026lt;int\u0026gt;|default=10] consul_config The consul_config configures the consul client. The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n no prefix compactor.ring distributor.ha-tracker distributor.ring experimental.store-gateway.sharding-ring ruler.ring \u0026nbsp;\n# Hostname and port of Consul.# CLI flag: -\u0026lt;prefix\u0026gt;.consul.hostname[host:\u0026lt;string\u0026gt;|default=\u0026#34;localhost:8500\u0026#34;]# ACL Token used to interact with Consul.# CLI flag: -\u0026lt;prefix\u0026gt;.consul.acl-token[acl_token:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# HTTP timeout when talking to Consul# CLI flag: -\u0026lt;prefix\u0026gt;.consul.client-timeout[http_client_timeout:\u0026lt;duration\u0026gt;|default=20s]# Enable consistent reads to Consul.# CLI flag: -\u0026lt;prefix\u0026gt;.consul.consistent-reads[consistent_reads:\u0026lt;boolean\u0026gt;|default=false]# Rate limit when watching key or prefix in Consul, in requests per second. 0# disables the rate limit.# CLI flag: -\u0026lt;prefix\u0026gt;.consul.watch-rate-limit[watch_rate_limit:\u0026lt;float\u0026gt;|default=1]# Burst size used in rate limit. Values less than 1 are treated as 1.# CLI flag: -\u0026lt;prefix\u0026gt;.consul.watch-burst-size[watch_burst_size:\u0026lt;int\u0026gt;|default=1] memberlist_config The memberlist_config configures the Gossip memberlist.\n# Name of the node in memberlist cluster. Defaults to hostname.# CLI flag: -memberlist.nodename[node_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The timeout for establishing a connection with a remote node, and for# read/write operations. Uses memberlist LAN defaults if 0.# CLI flag: -memberlist.stream-timeout[stream_timeout:\u0026lt;duration\u0026gt;|default=0s]# Multiplication factor used when sending out messages (factor * log(N+1)).# CLI flag: -memberlist.retransmit-factor[retransmit_factor:\u0026lt;int\u0026gt;|default=0]# How often to use pull/push sync. Uses memberlist LAN defaults if 0.# CLI flag: -memberlist.pullpush-interval[pull_push_interval:\u0026lt;duration\u0026gt;|default=0s]# How often to gossip. Uses memberlist LAN defaults if 0.# CLI flag: -memberlist.gossip-interval[gossip_interval:\u0026lt;duration\u0026gt;|default=0s]# How many nodes to gossip to. Uses memberlist LAN defaults if 0.# CLI flag: -memberlist.gossip-nodes[gossip_nodes:\u0026lt;int\u0026gt;|default=0]# How long to keep gossiping to dead nodes, to give them chance to refute their# death. Uses memberlist LAN defaults if 0.# CLI flag: -memberlist.gossip-to-dead-nodes-time[gossip_to_dead_nodes_time:\u0026lt;duration\u0026gt;|default=0s]# How soon can dead node\u0026#39;s name be reclaimed with new address. Defaults to 0,# which is disabled.# CLI flag: -memberlist.dead-node-reclaim-time[dead_node_reclaim_time:\u0026lt;duration\u0026gt;|default=0s]# Other cluster members to join. Can be specified multiple times. Memberlist# store is EXPERIMENTAL.# CLI flag: -memberlist.join[join_members:\u0026lt;listofstring\u0026gt;|default=]# If this node fails to join memberlist cluster, abort.# CLI flag: -memberlist.abort-if-join-fails[abort_if_cluster_join_fails:\u0026lt;boolean\u0026gt;|default=true]# How long to keep LEFT ingesters in the ring.# CLI flag: -memberlist.left-ingesters-timeout[left_ingesters_timeout:\u0026lt;duration\u0026gt;|default=5m]# Timeout for leaving memberlist cluster.# CLI flag: -memberlist.leave-timeout[leave_timeout:\u0026lt;duration\u0026gt;|default=5s]# IP address to listen on for gossip messages. Multiple addresses may be# specified. Defaults to 0.0.0.0# CLI flag: -memberlist.bind-addr[bind_addr:\u0026lt;listofstring\u0026gt;|default=]# Port to listen on for gossip messages.# CLI flag: -memberlist.bind-port[bind_port:\u0026lt;int\u0026gt;|default=7946]# Timeout used when connecting to other nodes to send packet.# CLI flag: -memberlist.packet-dial-timeout[packet_dial_timeout:\u0026lt;duration\u0026gt;|default=5s]# Timeout for writing \u0026#39;packet\u0026#39; data.# CLI flag: -memberlist.packet-write-timeout[packet_write_timeout:\u0026lt;duration\u0026gt;|default=5s] limits_config The limits_config configures default and per-tenant limits imposed by Cortex services (ie. distributor, ingester, \u0026hellip;).\n# Per-user ingestion rate limit in samples per second.# CLI flag: -distributor.ingestion-rate-limit[ingestion_rate:\u0026lt;float\u0026gt;|default=25000]# Whether the ingestion rate limit should be applied individually to each# distributor instance (local), or evenly shared across the cluster (global).# CLI flag: -distributor.ingestion-rate-limit-strategy[ingestion_rate_strategy:\u0026lt;string\u0026gt;|default=\u0026#34;local\u0026#34;]# Per-user allowed ingestion burst size (in number of samples).# CLI flag: -distributor.ingestion-burst-size[ingestion_burst_size:\u0026lt;int\u0026gt;|default=50000]# Flag to enable, for all users, handling of samples with external labels# identifying replicas in an HA Prometheus setup.# CLI flag: -distributor.ha-tracker.enable-for-all-users[accept_ha_samples:\u0026lt;boolean\u0026gt;|default=false]# Prometheus label to look for in samples to identify a Prometheus HA cluster.# CLI flag: -distributor.ha-tracker.cluster[ha_cluster_label:\u0026lt;string\u0026gt;|default=\u0026#34;cluster\u0026#34;]# Prometheus label to look for in samples to identify a Prometheus HA replica.# CLI flag: -distributor.ha-tracker.replica[ha_replica_label:\u0026lt;string\u0026gt;|default=\u0026#34;__replica__\u0026#34;]# This flag can be used to specify label names that to drop during sample# ingestion within the distributor and can be repeated in order to drop multiple# labels.# CLI flag: -distributor.drop-label[drop_labels:\u0026lt;listofstring\u0026gt;|default=]# Maximum length accepted for label names# CLI flag: -validation.max-length-label-name[max_label_name_length:\u0026lt;int\u0026gt;|default=1024]# Maximum length accepted for label value. This setting also applies to the# metric name# CLI flag: -validation.max-length-label-value[max_label_value_length:\u0026lt;int\u0026gt;|default=2048]# Maximum number of label names per series.# CLI flag: -validation.max-label-names-per-series[max_label_names_per_series:\u0026lt;int\u0026gt;|default=30]# Maximum length accepted for metric metadata. Metadata refers to Metric Name,# HELP and UNIT.# CLI flag: -validation.max-metadata-length[max_metadata_length:\u0026lt;int\u0026gt;|default=1024]# Reject old samples.# CLI flag: -validation.reject-old-samples[reject_old_samples:\u0026lt;boolean\u0026gt;|default=false]# Maximum accepted sample age before rejecting.# CLI flag: -validation.reject-old-samples.max-age[reject_old_samples_max_age:\u0026lt;duration\u0026gt;|default=336h]# Duration which table will be created/deleted before/after it\u0026#39;s needed; we# won\u0026#39;t accept sample from before this time.# CLI flag: -validation.create-grace-period[creation_grace_period:\u0026lt;duration\u0026gt;|default=10m]# Enforce every metadata has a metric name.# CLI flag: -validation.enforce-metadata-metric-name[enforce_metadata_metric_name:\u0026lt;boolean\u0026gt;|default=true]# Enforce every sample has a metric name.# CLI flag: -validation.enforce-metric-name[enforce_metric_name:\u0026lt;boolean\u0026gt;|default=true]# Per-user subring to shard metrics to ingesters. 0 is disabled.# CLI flag: -experimental.distributor.user-subring-size[user_subring_size:\u0026lt;int\u0026gt;|default=0]# The maximum number of series that a query can return.# CLI flag: -ingester.max-series-per-query[max_series_per_query:\u0026lt;int\u0026gt;|default=100000]# The maximum number of samples that a query can return.# CLI flag: -ingester.max-samples-per-query[max_samples_per_query:\u0026lt;int\u0026gt;|default=1000000]# The maximum number of active series per user, per ingester. 0 to disable.# CLI flag: -ingester.max-series-per-user[max_series_per_user:\u0026lt;int\u0026gt;|default=5000000]# The maximum number of active series per metric name, per ingester. 0 to# disable.# CLI flag: -ingester.max-series-per-metric[max_series_per_metric:\u0026lt;int\u0026gt;|default=50000]# The maximum number of active series per user, across the cluster. 0 to# disable. Supported only if -distributor.shard-by-all-labels is true.# CLI flag: -ingester.max-global-series-per-user[max_global_series_per_user:\u0026lt;int\u0026gt;|default=0]# The maximum number of active series per metric name, across the cluster. 0 to# disable.# CLI flag: -ingester.max-global-series-per-metric[max_global_series_per_metric:\u0026lt;int\u0026gt;|default=0]# Minimum number of samples in an idle chunk to flush it to the store. Use with# care, if chunks are less than this size they will be discarded.# CLI flag: -ingester.min-chunk-length[min_chunk_length:\u0026lt;int\u0026gt;|default=0]# The maximum number of active metrics with metadata per user, per ingester. 0# to disable.# CLI flag: -ingester.max-metadata-per-user[max_metadata_per_user:\u0026lt;int\u0026gt;|default=8000]# The maximum number of metadata per metric, per ingester. 0 to disable.# CLI flag: -ingester.max-metadata-per-metric[max_metadata_per_metric:\u0026lt;int\u0026gt;|default=10]# The maximum number of active metrics with metadata per user, across the# cluster. 0 to disable. Supported only if -distributor.shard-by-all-labels is# true.# CLI flag: -ingester.max-global-metadata-per-user[max_global_metadata_per_user:\u0026lt;int\u0026gt;|default=0]# The maximum number of metadata per metric, across the cluster. 0 to disable.# CLI flag: -ingester.max-global-metadata-per-metric[max_global_metadata_per_metric:\u0026lt;int\u0026gt;|default=0]# Maximum number of chunks that can be fetched in a single query.# CLI flag: -store.query-chunk-limit[max_chunks_per_query:\u0026lt;int\u0026gt;|default=2000000]# Limit to length of chunk store queries, 0 to disable.# CLI flag: -store.max-query-length[max_query_length:\u0026lt;duration\u0026gt;|default=0s]# Maximum number of queries will be scheduled in parallel by the frontend.# CLI flag: -querier.max-query-parallelism[max_query_parallelism:\u0026lt;int\u0026gt;|default=14]# Cardinality limit for index queries.# CLI flag: -store.cardinality-limit[cardinality_limit:\u0026lt;int\u0026gt;|default=100000]# File name of per-user overrides. [deprecated, use -runtime-config.file# instead]# CLI flag: -limits.per-user-override-config[per_tenant_override_config:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Period with which to reload the overrides. [deprecated, use# -runtime-config.reload-period instead]# CLI flag: -limits.per-user-override-period[per_tenant_override_period:\u0026lt;duration\u0026gt;|default=10s] redis_config The redis_config configures the Redis backend cache. The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n frontend store.chunks-cache store.index-cache-read store.index-cache-write \u0026nbsp;\n# Redis service endpoint to use when caching chunks. If empty, no redis will be# used.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.endpoint[endpoint:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Maximum time to wait before giving up on redis requests.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# How long keys stay in the redis.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.expiration[expiration:\u0026lt;duration\u0026gt;|default=0s]# Maximum number of idle connections in pool.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.max-idle-conns[max_idle_conns:\u0026lt;int\u0026gt;|default=80]# Maximum number of active connections in pool.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.max-active-conns[max_active_conns:\u0026lt;int\u0026gt;|default=0]# Password to use when connecting to redis.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.password[password:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Enables connecting to redis with TLS.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.enable-tls[enable_tls:\u0026lt;boolean\u0026gt;|default=false]# Close connections after remaining idle for this duration. If the value is# zero, then idle connections are not closed.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.idle-timeout[idle_timeout:\u0026lt;duration\u0026gt;|default=0s]# Enables waiting if there are no idle connections. If the value is false and# the pool is at the max_active_conns limit, the pool will return a connection# with ErrPoolExhausted error and not wait for idle connections.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.wait-on-pool-exhaustion[wait_on_pool_exhaustion:\u0026lt;boolean\u0026gt;|default=false]# Close connections older than this duration. If the value is zero, then the# pool does not close connections based on age.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.max-conn-lifetime[max_conn_lifetime:\u0026lt;duration\u0026gt;|default=0s] memcached_config The memcached_config block configures how data is stored in Memcached (ie. expiration). The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n frontend store.chunks-cache store.index-cache-read store.index-cache-write \u0026nbsp;\n# How long keys stay in the memcache.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.expiration[expiration:\u0026lt;duration\u0026gt;|default=0s]# How many keys to fetch in each batch.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.batchsize[batch_size:\u0026lt;int\u0026gt;|default=1024]# Maximum active requests to memcache.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.parallelism[parallelism:\u0026lt;int\u0026gt;|default=100] memcached_client_config The memcached_client_config configures the client used to connect to Memcached. The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n frontend store.chunks-cache store.index-cache-read store.index-cache-write \u0026nbsp;\n# Hostname for memcached service to use. If empty and if addresses is unset, no# memcached will be used.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.hostname[host:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# SRV service used to discover memcache servers.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.service[service:\u0026lt;string\u0026gt;|default=\u0026#34;memcached\u0026#34;]# EXPERIMENTAL: Comma separated addresses list in DNS Service Discovery format:# https://cortexmetrics.io/docs/configuration/arguments/#dns-service-discovery# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Maximum time to wait before giving up on memcached requests.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# Maximum number of idle connections in pool.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.max-idle-conns[max_idle_conns:\u0026lt;int\u0026gt;|default=16]# Period with which to poll DNS for memcache servers.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.update-interval[update_interval:\u0026lt;duration\u0026gt;|default=1m]# Use consistent hashing to distribute to memcache servers.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.consistent-hash[consistent_hash:\u0026lt;boolean\u0026gt;|default=true] fifo_cache_config The fifo_cache_config configures the local in-memory cache. The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n frontend store.chunks-cache store.index-cache-read store.index-cache-write \u0026nbsp;\n# Maximum memory size of the cache in bytes. A unit suffix (KB, MB, GB) may be# applied.# CLI flag: -\u0026lt;prefix\u0026gt;.fifocache.max-size-bytes[max_size_bytes:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Maximum number of entries in the cache.# CLI flag: -\u0026lt;prefix\u0026gt;.fifocache.max-size-items[max_size_items:\u0026lt;int\u0026gt;|default=0]# The expiry duration for the cache.# CLI flag: -\u0026lt;prefix\u0026gt;.fifocache.duration[validity:\u0026lt;duration\u0026gt;|default=0s]# Deprecated (use max-size-items or max-size-bytes instead): The number of# entries to cache.# CLI flag: -\u0026lt;prefix\u0026gt;.fifocache.size[size:\u0026lt;int\u0026gt;|default=0] configs_config The configs_config configures the Cortex Configs DB and API.\ndatabase:# URI where the database can be found (for dev you can use memory://)# CLI flag: -configs.database.uri[uri:\u0026lt;string\u0026gt;|default=\u0026#34;postgres://postgres@configs-db.weave.local/configs?sslmode=disable\u0026#34;]# Path where the database migration files can be found# CLI flag: -configs.database.migrations-dir[migrations_dir:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# File containing password (username goes in URI)# CLI flag: -configs.database.password-file[password_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]api:notifications:# Disable Email notifications for Alertmanager.# CLI flag: -configs.notifications.disable-email[disable_email:\u0026lt;boolean\u0026gt;|default=false]# Disable WebHook notifications for Alertmanager.# CLI flag: -configs.notifications.disable-webhook[disable_webhook:\u0026lt;boolean\u0026gt;|default=false] configstore_config The configstore_config configures the config database storing rules and alerts, and is used by the Cortex alertmanager. The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n alertmanager ruler \u0026nbsp;\n# URL of configs API server.# CLI flag: -\u0026lt;prefix\u0026gt;.configs.url[configs_api_url:\u0026lt;url\u0026gt;|default=]# Timeout for requests to Weave Cloud configs service.# CLI flag: -\u0026lt;prefix\u0026gt;.configs.client-timeout[client_timeout:\u0026lt;duration\u0026gt;|default=5s] tsdb_config The tsdb_config configures the experimental blocks storage.\n# Local directory to store TSDBs in the ingesters.# CLI flag: -experimental.tsdb.dir[dir:\u0026lt;string\u0026gt;|default=\u0026#34;tsdb\u0026#34;]# TSDB blocks range period.# CLI flag: -experimental.tsdb.block-ranges-period[block_ranges_period:\u0026lt;listofduration\u0026gt;|default=2h0m0s]# TSDB blocks retention in the ingester before a block is removed. This should# be larger than the block_ranges_period and large enough to give queriers# enough time to discover newly uploaded blocks.# CLI flag: -experimental.tsdb.retention-period[retention_period:\u0026lt;duration\u0026gt;|default=6h]# How frequently the TSDB blocks are scanned and new ones are shipped to the# storage. 0 means shipping is disabled.# CLI flag: -experimental.tsdb.ship-interval[ship_interval:\u0026lt;duration\u0026gt;|default=1m]# Maximum number of tenants concurrently shipping blocks to the storage.# CLI flag: -experimental.tsdb.ship-concurrency[ship_concurrency:\u0026lt;int\u0026gt;|default=10]# Backend storage to use. Supported backends are: s3, gcs, azure, filesystem.# CLI flag: -experimental.tsdb.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;s3\u0026#34;]bucket_store:# Directory to store synchronized TSDB index headers.# CLI flag: -experimental.tsdb.bucket-store.sync-dir[sync_dir:\u0026lt;string\u0026gt;|default=\u0026#34;tsdb-sync\u0026#34;]# How frequently scan the bucket to look for changes (new blocks shipped by# ingesters and blocks removed by retention or compaction). 0 disables it.# CLI flag: -experimental.tsdb.bucket-store.sync-interval[sync_interval:\u0026lt;duration\u0026gt;|default=5m]# Max size - in bytes - of a per-tenant chunk pool, used to reduce memory# allocations.# CLI flag: -experimental.tsdb.bucket-store.max-chunk-pool-bytes[max_chunk_pool_bytes:\u0026lt;int\u0026gt;|default=2147483648]# Max number of samples per query when loading series from the long-term# storage. 0 disables the limit.# CLI flag: -experimental.tsdb.bucket-store.max-sample-count[max_sample_count:\u0026lt;int\u0026gt;|default=0]# Max number of concurrent queries to execute against the long-term storage on# a per-tenant basis.# CLI flag: -experimental.tsdb.bucket-store.max-concurrent[max_concurrent:\u0026lt;int\u0026gt;|default=20]# Maximum number of concurrent tenants synching blocks.# CLI flag: -experimental.tsdb.bucket-store.tenant-sync-concurrency[tenant_sync_concurrency:\u0026lt;int\u0026gt;|default=10]# Maximum number of concurrent blocks synching per tenant.# CLI flag: -experimental.tsdb.bucket-store.block-sync-concurrency[block_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Number of Go routines to use when syncing block meta files from object# storage per tenant.# CLI flag: -experimental.tsdb.bucket-store.meta-sync-concurrency[meta_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Whether the bucket store should use the binary index header. If false, it# uses the JSON index header.# CLI flag: -experimental.tsdb.bucket-store.binary-index-header-enabled[binary_index_header_enabled:\u0026lt;boolean\u0026gt;|default=true]# Minimum age of a block before it\u0026#39;s being read. Set it to safe value (e.g# 30m) if your object storage is eventually consistent. GCS and S3 are# (roughly) strongly consistent.# CLI flag: -experimental.tsdb.bucket-store.consistency-delay[consistency_delay:\u0026lt;duration\u0026gt;|default=0s]index_cache:# The index cache backend type. Supported values: inmemory, memcached.# CLI flag: -experimental.tsdb.bucket-store.index-cache.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;inmemory\u0026#34;]inmemory:# Maximum size in bytes of in-memory index cache used to speed up blocks# index lookups (shared between all tenants).# CLI flag: -experimental.tsdb.bucket-store.index-cache.inmemory.max-size-bytes[max_size_bytes:\u0026lt;int\u0026gt;|default=1073741824]memcached:# Comma separated list of memcached addresses. Supported prefixes are:# dns+ (looked up as an A/AAAA query), dnssrv+ (looked up as a SRV query,# dnssrvnoa+ (looked up as a SRV query, with no A/AAAA lookup made after# that).# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The socket read/write timeout.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# The maximum number of idle connections that will be maintained per# address.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.max-idle-connections[max_idle_connections:\u0026lt;int\u0026gt;|default=16]# The maximum number of concurrent asynchronous operations can occur.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.max-async-concurrency[max_async_concurrency:\u0026lt;int\u0026gt;|default=50]# The maximum number of enqueued asynchronous operations allowed.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.max-async-buffer-size[max_async_buffer_size:\u0026lt;int\u0026gt;|default=10000]# The maximum number of concurrent connections running get operations. If# set to 0, concurrency is unlimited.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.max-get-multi-concurrency[max_get_multi_concurrency:\u0026lt;int\u0026gt;|default=100]# The maximum number of keys a single underlying get operation should run.# If more keys are specified, internally keys are splitted into multiple# batches and fetched concurrently, honoring the max concurrency. If set# to 0, the max batch size is unlimited.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.max-get-multi-batch-size[max_get_multi_batch_size:\u0026lt;int\u0026gt;|default=0]# The maximum size of an item stored in memcached. Bigger items are not# stored. If set to 0, no maximum size is enforced.# CLI flag: -experimental.tsdb.bucket-store.index-cache.memcached.max-item-size[max_item_size:\u0026lt;int\u0026gt;|default=1048576]# Compress postings before storing them to postings cache.# CLI flag: -experimental.tsdb.bucket-store.index-cache.postings-compression-enabled[postings_compression_enabled:\u0026lt;boolean\u0026gt;|default=false]# Duration after which the blocks marked for deletion will be filtered out# while fetching blocks. The idea of ignore-deletion-marks-delay is to ignore# blocks that are marked for deletion with some delay. This ensures store can# still serve blocks that are meant to be deleted but do not have a# replacement yet.Default is 6h, half of the default value for# -compactor.deletion-delay.# CLI flag: -experimental.tsdb.bucket-store.ignore-deletion-marks-delay[ignore_deletion_mark_delay:\u0026lt;duration\u0026gt;|default=6h]# How frequently does Cortex try to compact TSDB head. Block is only created if# data covers smallest block range. Must be greater than 0 and max 5 minutes.# CLI flag: -experimental.tsdb.head-compaction-interval[head_compaction_interval:\u0026lt;duration\u0026gt;|default=1m]# Maximum number of tenants concurrently compacting TSDB head into a new block# CLI flag: -experimental.tsdb.head-compaction-concurrency[head_compaction_concurrency:\u0026lt;int\u0026gt;|default=5]# The number of shards of series to use in TSDB (must be a power of 2). Reducing# this will decrease memory footprint, but can negatively impact performance.# CLI flag: -experimental.tsdb.stripe-size[stripe_size:\u0026lt;int\u0026gt;|default=16384]# True if the Cortex cluster is running the store-gateway service and the# querier should query the bucket store via the store-gateway.# CLI flag: -experimental.tsdb.store-gateway-enabled[store_gateway_enabled:\u0026lt;boolean\u0026gt;|default=false]# limit the number of concurrently opening TSDB\u0026#39;s on startup# CLI flag: -experimental.tsdb.max-tsdb-opening-concurrency-on-startup[max_tsdb_opening_concurrency_on_startup:\u0026lt;int\u0026gt;|default=10]s3:# S3 endpoint without schema# CLI flag: -experimental.tsdb.s3.endpoint[endpoint:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 bucket name# CLI flag: -experimental.tsdb.s3.bucket-name[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 secret access key# CLI flag: -experimental.tsdb.s3.secret-access-key[secret_access_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 access key ID# CLI flag: -experimental.tsdb.s3.access-key-id[access_key_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# If enabled, use http:// for the S3 endpoint instead of https://. This could# be useful in local dev/test environments while using an S3-compatible# backend storage, like Minio.# CLI flag: -experimental.tsdb.s3.insecure[insecure:\u0026lt;boolean\u0026gt;|default=false]gcs:# GCS bucket name# CLI flag: -experimental.tsdb.gcs.bucket-name[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# JSON representing either a Google Developers Console client_credentials.json# file or a Google Developers service account key file. If empty, fallback to# Google default logic.# CLI flag: -experimental.tsdb.gcs.service-account[service_account:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]azure:# Azure storage account name# CLI flag: -experimental.tsdb.azure.account-name[account_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage account key# CLI flag: -experimental.tsdb.azure.account-key[account_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage container name# CLI flag: -experimental.tsdb.azure.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage endpoint suffix without schema. The account name will be# prefixed to this value to create the FQDN# CLI flag: -experimental.tsdb.azure.endpoint-suffix[endpoint_suffix:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Number of retries for recoverable errors# CLI flag: -experimental.tsdb.azure.max-retries[max_retries:\u0026lt;int\u0026gt;|default=20]filesystem:# Local filesystem storage directory.# CLI flag: -experimental.tsdb.filesystem.dir[dir:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;] compactor_config The compactor_config configures the compactor for the experimental blocks storage.\n# List of compaction time ranges.# CLI flag: -compactor.block-ranges[block_ranges:\u0026lt;listofduration\u0026gt;|default=2h0m0s,12h0m0s,24h0m0s]# Number of Go routines to use when syncing block index and chunks files from# the long term storage.# CLI flag: -compactor.block-sync-concurrency[block_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Number of Go routines to use when syncing block meta files from the long term# storage.# CLI flag: -compactor.meta-sync-concurrency[meta_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Minimum age of fresh (non-compacted) blocks before they are being processed.# Malformed blocks older than the maximum of consistency-delay and 48h0m0s will# be removed.# CLI flag: -compactor.consistency-delay[consistency_delay:\u0026lt;duration\u0026gt;|default=30m]# Data directory in which to cache blocks and process compactions# CLI flag: -compactor.data-dir[data_dir:\u0026lt;string\u0026gt;|default=\u0026#34;./data\u0026#34;]# The frequency at which the compaction runs# CLI flag: -compactor.compaction-interval[compaction_interval:\u0026lt;duration\u0026gt;|default=1h]# How many times to retry a failed compaction during a single compaction# interval# CLI flag: -compactor.compaction-retries[compaction_retries:\u0026lt;int\u0026gt;|default=3]# Time before a block marked for deletion is deleted from bucket. If not 0,# blocks will be marked for deletion and compactor component will delete blocks# marked for deletion from the bucket. If delete-delay is 0, blocks will be# deleted straight away. Note that deleting blocks immediately can cause query# failures, if store gateway still has the block loaded, or compactor is# ignoring the deletion because it\u0026#39;s compacting the block at the same time.# CLI flag: -compactor.deletion-delay[deletion_delay:\u0026lt;duration\u0026gt;|default=12h]# Shard tenants across multiple compactor instances. Sharding is required if you# run multiple compactor instances, in order to coordinate compactions and avoid# race conditions leading to the same tenant blocks simultaneously compacted by# different instances.# CLI flag: -compactor.sharding-enabled[sharding_enabled:\u0026lt;boolean\u0026gt;|default=false]sharding_ring:kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, multi, memberlist (experimental).# CLI flag: -compactor.ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -compactor.ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;collectors/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is: compactor.ring[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is: compactor.ring[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -compactor.ring.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -compactor.ring.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -compactor.ring.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -compactor.ring.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# Period at which to heartbeat to the ring.# CLI flag: -compactor.ring.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=5s]# The heartbeat timeout after which compactors are considered unhealthy within# the ring.# CLI flag: -compactor.ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m] store_gateway_config The store_gateway_config configures the store-gateway service used by the experimental blocks storage.\n# Shard blocks across multiple store gateway instances. This option needs be set# both on the store-gateway and querier when running in microservices mode.# CLI flag: -experimental.store-gateway.sharding-enabled[sharding_enabled:\u0026lt;boolean\u0026gt;|default=false]# The hash ring configuration. This option is required only if blocks sharding# is enabled.sharding_ring:# The key-value store used to share the hash ring across multiple instances.# This option needs be set both on the store-gateway and querier when running# in microservices mode.kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, multi, memberlist (experimental).# CLI flag: -experimental.store-gateway.sharding-ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -experimental.store-gateway.sharding-ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;collectors/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is:# experimental.store-gateway.sharding-ring[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is:# experimental.store-gateway.sharding-ring[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -experimental.store-gateway.sharding-ring.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -experimental.store-gateway.sharding-ring.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -experimental.store-gateway.sharding-ring.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -experimental.store-gateway.sharding-ring.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# Period at which to heartbeat to the ring.# CLI flag: -experimental.store-gateway.sharding-ring.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=15s]# The heartbeat timeout after which store gateways are considered unhealthy# within the ring. This option needs be set both on the store-gateway and# querier when running in microservices mode.# CLI flag: -experimental.store-gateway.sharding-ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m]# The replication factor to use when sharding blocks. This option needs be set# both on the store-gateway and querier when running in microservices mode.# CLI flag: -experimental.store-gateway.replication-factor[replication_factor:\u0026lt;int\u0026gt;|default=3]# File path where tokens are stored. If empty, tokens are not stored at# shutdown and restored at startup.# CLI flag: -experimental.store-gateway.tokens-file-path[tokens_file_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;] purger_config The purger_config configures the purger which takes care of delete requests\n# Enable purger to allow deletion of series. Be aware that Delete series feature# is still experimental# CLI flag: -purger.enable[enable:\u0026lt;boolean\u0026gt;|default=false]# Number of workers executing delete plans in parallel# CLI flag: -purger.num-workers[num_workers:\u0026lt;int\u0026gt;|default=2]# Name of the object store to use for storing delete plans# CLI flag: -purger.object-store-type[object_store_type:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]","excerpt":"Cortex can be configured using a YAML file - specified using the -config.file flag - or CLI flags. …","ref":"/docs/configuration/configuration-file/","title":"Configuration file"},{"body":" \nCortex provides horizontally scalable, highly available, multi-tenant, long term storage for Prometheus.\n Horizontally scalable: Cortex can run across multiple machines in a cluster, exceeding the throughput and storage of a single machine. This enables you to send the metrics from multiple Prometheus servers to a single Cortex cluster and run \u0026ldquo;globally aggregated\u0026rdquo; queries across all data in a single place. Highly available: When run in a cluster, Cortex can replicate data between machines. This allows you to survive machine failure without gaps in your graphs. Multi-tenant: Cortex can isolate data and queries from multiple different independent Prometheus sources in a single cluster, allowing untrusted parties to share the same cluster. Long term storage: Cortex supports Amazon DynamoDB, Google Bigtable, Cassandra, S3 and GCS for long term storage of metric data. This allows you to durably store data for longer than the lifetime of any single machine, and use this data for long term capacity planning. Cortex is a CNCF sandbox project used in several production systems including Weave Cloud and Grafana Cloud. Cortex is primarily used as a remote write destination for Prometheus, exposing a Prometheus-compatible query API.\nDocumentation Read the getting started guide if you\u0026rsquo;re new to the project. Before deploying Cortex with a permanent storage backend you should read:\n An overview of Cortex\u0026rsquo;s architecture A guide to running Cortex Information regarding configuring Cortex For a guide to contributing to Cortex, see the contributor guidelines.\nFurther reading To learn more about Cortex, consult the following documents \u0026amp; talks:\n May 2019 KubeCon talks; \u0026ldquo;Cortex: Intro\u0026rdquo; (video, slides, blog post) and \u0026ldquo;Cortex: Deep Dive\u0026rdquo; (video, slides) Feb 2019 blog post \u0026amp; podcast; \u0026ldquo;Prometheus Scalability with Bryan Boreham\u0026rdquo; (podcast) Feb 2019 blog post; \u0026ldquo;How Aspen Mesh Runs Cortex in Production\u0026ldquo; Dec 2018 KubeCon talk; \u0026ldquo;Cortex: Infinitely Scalable Prometheus\u0026rdquo; (video, slides) Dec 2018 CNCF blog post; \u0026ldquo;Cortex: a multi-tenant, horizontally scalable Prometheus-as-a-Service\u0026ldquo; Nov 2018 CloudNative London meetup talk; \u0026ldquo;Cortex: Horizontally Scalable, Highly Available Prometheus\u0026rdquo; (slides) Nov 2018 CNCF TOC Presentation; \u0026ldquo;Horizontally Scalable, Multi-tenant Prometheus\u0026rdquo; (slides) Sept 2018 blog post; \u0026ldquo;What is Cortex?\u0026ldquo; Aug 2018 PromCon panel; \u0026ldquo;Prometheus Long-Term Storage Approaches\u0026rdquo; (video) Jul 2018 design doc; \u0026ldquo;Cortex Query Optimisations\u0026ldquo; Aug 2017 PromCon talk; \u0026ldquo;Cortex: Prometheus as a Service, One Year On\u0026rdquo; (videos, slides, write up part 1, part 2, part 3) Jun 2017 Prometheus London meetup talk; \u0026ldquo;Cortex: open-source, horizontally-scalable, distributed Prometheus\u0026rdquo; (video) Dec 2016 KubeCon talk; \u0026ldquo;Weave Cortex: Multi-tenant, horizontally scalable Prometheus as a Service\u0026rdquo; (video, slides) Aug 2016 PromCon talk; \u0026ldquo;Project Frankenstein: Multitenant, Scale-Out Prometheus\u0026rdquo;: (video, slides) Jun 2016 design document; \u0026ldquo;Project Frankenstein: A Multi Tenant, Scale Out Prometheus\u0026ldquo; Getting Help If you have any questions about Cortex:\n Ask a question on the Cortex Slack channel. To invite yourself to the CNCF Slack, visit http://slack.cncf.io/. File an issue. Send an email to cortex-users@lists.cncf.io Your feedback is always welcome.\nHosted Cortex (Prometheus as a service) There are several commercial services where you can use Cortex on-demand:\nWeave Cloud Weave Cloud from Weaveworks lets you deploy, manage, and monitor container-based applications. Sign up at https://cloud.weave.works and follow the instructions there. Additional help can also be found in the Weave Cloud documentation.\nInstrumenting Your App: Best Practices\nGrafana Cloud To use Cortex as part of Grafana Cloud, sign up for Grafana Cloud by clicking \u0026ldquo;Log In\u0026rdquo; in the top right and then \u0026ldquo;Sign Up Now\u0026rdquo;. Cortex is included as part of the Starter and Basic Hosted Grafana plans.\n","excerpt":"Cortex provides horizontally scalable, highly available, multi-tenant, long term storage for …","ref":"/docs/","title":"Documentation"},{"body":" Author: Jay Batra Date: March 2020 Status: proposal Problem In Cortex, currently, we are missing versioning of documentation. The idea is to have version documentation just like Prometheus.Prometheus. Documentation is the main source of information for current contributors and first-timers. A properly versioned documentation will help everyone to have a proper place to look for answers before flagging it in the community.\nIn this proposal, we want to solve this. In particular, we want to:\n Version specific pages of the documentation Include links to change version (the version must be in the URL) Include the master version and last 3 minor releases. Documentation defaults to the last minor release. Proposed solution Currently, the documentation is residing under the docs/ folder of cortexproject/cortex. It is built by Hugo using the theme docsy. It will have a proper drop-down menu which will enable proper versioning. It has a section params.version in config.toml which will allow us to map URLs with proper versions. We will have to change all the occurrences of older doc links with new links. We will keep master version with 3 latest release versions. Each release is a minor version expressed as 1.x. The document would default to latest minor version.\nFrom the current doc, the following paths (and all their subpages) should be versioned for now:\n https://cortexmetrics.io/docs/apis/ https://cortexmetrics.io/docs/configuration/ (moving v1.x Guarantees outside of the tree, because these shouldn\u0026rsquo;t be versioned) The above should be versioned under a single URL path (/docs/running-cortex/ in the following example, but final prefix is still to be decided).\nExample: For master version we would be able to use the above links via the following path\n/docs/running-cortex/master/configuration/ /docs/running-cortex/master/api/ And for a minor version like 1.x:\n/docs/running-cortex/1.0/configuration/ /docs/running-cortex/1.0/apis/ we\u0026rsquo;ll have versioned documentation only under the /docs/running-cortex/ prefix and, as a starting point, all versioned pages should go there.\n","excerpt":"Author: Jay Batra Date: March 2020 Status: proposal Problem In Cortex, currently, we are missing …","ref":"/docs/proposals/documentation-versioning/","title":"Documentation Versioning"},{"body":" Author: @annanay25 Reviewers: @jtlisi, @pstibrany, @cyriltovena, @pracucci Date: April 2020 Status: Accepted Overview Cortex uses modules to start and operate services with dependencies. Inter-service dependencies are specified in a map and passed to a module manager which ensures that they are initialised in the right order of dependencies. While this works really well, the implementation is tied in specifically to the Cortex struct and is not flexible for use with other projects like Loki, which also require similar forms of dependency management.\nWe would like to extend modules in cortex to a generic dependency management framework, that can be used by any project with no ties to cortex.\nSpecific goals Framework should allow for reusing cortex modules and allow us to: Add new modules Overwrite the implementation of a current module Manage dependencies Framework should allow for building an application from scratch using the modules package, with no dependencies on Cortex. For ex: Remove code from Loki that was copied from pkg/cortex/cortex.go. Proposed Design Modules package To make the modules package extensible, we need to abstract away any Cortex specific details from the module manager. The proposed design is to:\n Make a new component Manager, which is envisioned to be a central manager for all modules of the application. It stores modules \u0026amp; dependencies, and will be housed under a new package pkg/util/modules. Manager has the following methods for interaction:\nfunc (m *Manager) RegisterModule(name string, initFn func() (Service, error)) func (m *Manager) AddDependency(name string, dependsOn... string) error func (m *Manager) InitModuleServices(target string) (map[string]services.Service, error) Modules can be created by the application and registered with modules.Manager using RegisterModule. The parameters are:\n name: Name of the module initFn: A function that will be used to start the module. If it returns nil, and other modules depend on it, InitModuleServices will return an error. Dependencies between modules can be added using AddDependency. The parameters to the function are:\n name: Name of the module dependsOn: A variadic list of modules that the module depends on. These need to be added before the call to InitModuleServices.\n The application can be initialized by running initFn\u0026rsquo;s of all the modules in the right order of dependencies by invoking InitModuleServices with the target module name. Changes to pkg/cortex: WrappedService present in the current module design will be deprecated. All initFn\u0026rsquo;s will be wrapped into WrappedService by default.\n While the process of loading modules into modules.Manager should be remain as part of the Cortex.New() function, InitModuleServices should be part of Cortex.Run() and to enable this, modules.Manager would be made a member of the Cortex struct.\n Usage Following these changes, the Modules package will be a generic dependency management framework that can be used by any project.\nTo use the modules framework: Import the pkg/util/modules package, and initialize a new instance of the Manager using modules.NewManager() Create components in the system that implement the services interface (present in pkg/util/services). Register each of these components as a module using Manager.RegisterModule() by passing name of the module and initFn for the module. To add dependencies between modules, use Manager.AddDependency() Once all modules are added into modules.Manager, initialize the application by calling Manager.InitModuleServices() which initializes modules in the right order of dependencies. Future work Extend the module manager to allow specifying multiple targets as opposed to a single target name supported currently. Factor out Run() method to make it independent of Cortex. This will help reduce replicated code in the Loki project as well as help manage modules.Manager outside of the Cortex struct. ","excerpt":"Author: @annanay25 Reviewers: @jtlisi, @pstibrany, @cyriltovena, @pracucci Date: April 2020 Status: …","ref":"/docs/proposals/generalize-modules/","title":"Generalize Modules Service to make it extensible"},{"body":"","excerpt":"","ref":"/docs/getting-started/","title":"Getting Started"},{"body":"Gojek launched in 2010 as a call center for booking motorcycle taxi rides in Indonesia. Today, the startup is a decacorn serving millions of users across Southeast Asia with its mobile wallet, GoPay, and 20+ products on its super app. Want to order dinner? Book a massage? Buy movie tickets? You can do all of that with the Gojek app.\nThe company’s mission is to solve everyday challenges with technology innovation. To achieve that across multiple markets the systems team at Gojek focused on building an infrastructure for speed, reliability, and scale. By 2019, the team realized it needed a new monitoring system that could keep up with Gojek’s ever-growing technology organization, which led them to Cortex, the horizontally scalable Prometheus implementation.\n“We were using InfluxDB for metrics storage. Developers configured alerts by committing kapacitor scripts in git repos. To achieve high availability, we had a relay setup with two InfluxDBs. Since we could not horizontally scale Influx unless we paid for an enterprise license, we ended up having many InfluxDB clusters with relay setup,” says Product Engineer Ankit Goel.\nThough the team had introduced automation for setup, managing all those Influx instances became a pain point for operations. Additionally, some of the Gojek engineering teams needed far greater scale. “Some of our teams generate more than a million active time series,” says Goel. Another common requirement from customers was long-term storage of metrics. With InfluxDB, Gojek only had 2 weeks’ retention, and increasing it would mean provisioning bigger instances.\nGojek was in search of a better monitoring solution that would meet the following requirements:\n Kubernetes native. Horizontally scalable. Highly available out of the box. High reliability. Low operations overhead so a small team can manage it. Cortex met all of these requirements, and also had the following features that the Gojek team could leverage:\n Multi-tenancy. Customizable and modifiable, so it could be integrated with Gojek’s existing tooling. Support for remote_write. Because it supports remote_write, Cortex enabled one of Gojek’s key needs: the ability to offer monitoring as a service. “With Thanos, we would have had to deploy a Thanos sidecar on every Prometheus that would have been deployed,” says Goel. “So essentially, there would be a substantial part of infrastructure on the client side that we would need to manage. We preferred Cortex because people could simply push their metrics to us, and we would have all the metrics in a single place.”\nThe implementation started in January 2019. The team developed a few tools: a simple service for token-based authentication, and another for storing team information, such as notification channels and PagerDuty policies. Once all this was done, they leveraged InfluxData Telegraf’s remote_write plugin to write to Cortex. This allowed them to have all the metrics being sent to InfluxDB to be sent to Cortex as well. “So moving from InfluxDB to tenants would not be that complicated. Because Cortex was multi-tenant, we could directly map each of our InfluxDB servers to our tenants,” says Goel. They’ve developed an internal helm chart to deploy and manage Cortex. After the customizations were completed in about two months, “we had our setup up and running, and we onboarded one team on Cortex,” he says.\nIn the initial version, GitOps was the only interface for developers to apply alerts and create dashboards. The team built tools like grafonnet-playground to make it easy for developers to create dashboards. Developers are also allowed to create dashboards using the UI, since Grafana maintains version history for dashboards.\n“We needed metrics like ‘the number of alerts triggered for each team,’ ‘how long did it take to resolve these alerts,’ ‘how many were actionable and how many were ignored,’ etc.,” says Goel. “For measuring these metrics, the team only had to create a simple dashboard, since the ruler component exposes the per-tenant alert metrics. Both business and developers have found these metrics to be very useful.”\nThe team built a CLI tool to improve user experience for applying alerts without having to dig into PromQL. “You can write a command and say lens attach alert, and you tell it what kind of alert you want to attach, such as a CPU alert or Postgres alerts, and then you give it a service name,” says Goel. “There are some challenges to this approach for applying alerts, but we would like to move to such a model in the future.”\nOne of the challenges the team faces is developer education. But “we always knew if we are going to move to either Thanos or Cortex, developers would have to learn PromQL,” Goel says. The monitoring team paired with developers to help them understand PromQL and migrate their graphs and alerts.\nThe monitoring team has faced issues with Cortex from time to time, but “we always reached out to the Cortex community with our issues through the Cortex slack channel,” says Goel, and “active members of the Cortex community have always helped us with our problems.”\nToday, Gojek’s Lens monitoring system has 40+ tenants, for which Cortex handles about 1.2 million samples per second. Adoption is growing organically by word of mouth. Gojek is currently migrating to Kubernetes, and the teams that moved to Kubernetes have found Prometheus to be a better fit than InfluxDB. Seeing that success, other teams on Kubernetes have onboarded themselves to Lens.\nUltimately, Goel says, “where Cortex has really helped us is to integrate the monitoring system with our existing tools. We have a lot of internal tooling, and in certain places, we needed really tight integrations with the monitoring system. So the goal is to make sure that whenever a new service or team is created, they automatically get onboarded to the monitoring platform. After developers deploy, some of their system metrics and all the other standard metrics that are available for a service are automatically sent to the platform.” The team plans to spend the next six months bringing everyone over to Lens.\nLooking ahead, Goel and his team have the long-term vision of growing from a monitoring team to a full-fledged observability team. “We also want to take care of logging and tracing in Gojek,” he says. “Loki would be easy to fit with Cortex, so in the future we want to explore Loki for logging.”\n","excerpt":"Gojek launched in 2010 as a call center for booking motorcycle taxi rides in Indonesia. Today, the …","ref":"/docs/case-studies/gojek/","title":"How Gojek Is Leveraging Cortex to Keep Up with Its Ever-Growing Scale"},{"body":" Author: @jtlisi Reviewers: @pracucci, @pstibrany, @khaines, @gouthamve Date: March 2020 Status: Accepted Overview The purpose of this design document is to propose a set of standards that should be the basis of the Cortex HTTP API. This document will outline the current state of the Cortex http api and describe limitations that result from the current approach. It will also outline a set of paradigms on how http routes should be created within Cortex.\nCurrent Design As things currently stand, the majority of HTTP API calls exist under the /api/prom path prefix. This prefix is configurable. However, since this prefix is shared between all the modules which leads to conflicts if the Alertmanager is attempted to be run as as part of the single binary (#1722).\nProposed Design Module-Based Routing Cortex incorporates three separate APIs: Alertmanager, Prometheus, and Cortex. Each of these APIs should use a separate route prefix that accurately describes the API. Currently, all of the api calls in Cortex reside under the configured http prefix. Instead the following routing tree is proposed:\n/prometheus/* Under this path prefix, Cortex will act as a Prometheus web server. It will host all of the required Prometheus api endpoints. For example to query cortex the endpoint /prometheus/api/v1/query_range will be used.\n/alertmanager/* Under this path prefix, Cortex will act as a Alertmanager web server. In this case, it will forward requests to the alertmanager and support the alertmanager API. This means for a user to access their Alertmanager UI, they will use the /alertmanager path of cortex.\n/api/v1/* \u0026ndash; The cortex API will exist under this path prefix. /push /chunks /rules/* Current Proposed /api/prom/push /api/v1/push /api/prom/chunks /api/v1/chunks /api/prom/rules/* /api/v1/rules/* Service Endpoints A number of endpoints currently exist that are not under the /api/prom prefix that provide basic web interfaces and trigger operations for cortex services. These endpoints will all be placed under a url with their service name as a prefix if it is applicable.\n Current Proposed /status /multitenant-alertmanager/status /config /config /ring /ingester/ring /ruler_ring /ruler/ring /compactor/ring /compactor/ring /store-gateway/ring /store-gateway/ring /ha-tracker /distributor/ha_tracker /all_user_stats /distributor/all_user_stats /user_stats /distributor/user_stats /flush /ingester/flush /shutdown /ingester/shutdown Path Versioning Cortex will utilize path based versioning similar to both Prometheus and Alertmanager. This will allow future versions of the API to be released with changes over time.\nBackwards-Compatibility The new API endpoints and the current http prefix endpoints can be maintained concurrently. The flag to configure these endpoints will be maintained as http.prefix. This will allow us to roll out the new API without disrupting the current routing schema. The original http prefix endpoints can maintained indefinitely or be phased out over time. Deprecation warnings can be added to the current API either when initialized or utilized. This can be accomplished by injecting a middleware that logs a warning whenever a legacy API endpoint is used.\nIn cases where Cortex is run as a single binary, the Alertmanager module will only be accesible using the new API.\nImplementation This will be implemented by adding an API module to the Cortex service. This module will handle setting up all the required HTTP routes with Cortex. It will be designed around a set of interfaces required to fulfill the API. This is similar to how the v1 Prometheus API is implemented.\nStyle All new paths will utilize _ instead of - for their url to conform with Prometheus and its use of the underscore in the query_range endpoint. This applies to all operations endpoints. Component names in the path can still contain dashes. For example: /store-gateway/ring. ","excerpt":"Author: @jtlisi Reviewers: @pracucci, @pstibrany, @khaines, @gouthamve Date: March 2020 Status: …","ref":"/docs/proposals/http-api-design/","title":"HTTP API Design"},{"body":" This document builds on the getting started guide and specifies the steps needed to get Cortex into production. Ensure you have completed all the steps in the getting started guide and read about the Cortex architecture before you start this one.\n1. Pick a storage backend The getting started guide uses local chunk storage. Local chunk storage is experimental and shouldn’t be used in production.\nCortex requires a scalable storage back-end for production systems. It is recommended you use chunk storage with one of the following back-ends:\n DynamoDB/S3 (see Cortex on AWS) BigTable/GCS Cassandra (see Cortex on Cassandra) Commercial cloud options are DynamoDB/S3 and Bigtable/GCS: the advantage is you don\u0026rsquo;t have to know how to manage them, but the downside is they have specific costs.\nAlternatively you can choose Apache Cassandra, which you will have to install and manage. Cassandra support can also be used with commecial Cassandra-compatible services such as Azure Cosmos DB.\nCortex has an alternative to chunk storage: block storage. Block storage is not ready for production usage at this time.\n2. Deploy Query Frontend The Query Frontend is the Cortex component which parallelizes the execution of and caches the results of queries. The Query Frontend is also responsible for retries and multi-tenant QoS.\nFor the multi-tenant QoS algorithms to work, you should not run more than two Query Frontends. The Query Frontend should be deployed behind a load balancer, and should only be sent queries \u0026ndash; writes should go straight to the Distributor component, or to the single-process Cortex.\nThe Querier component (or single-process Cortex) “pulls” queries from the queues in the Query Frontend. Queriers discover the Query Frontend via DNS. The Queriers should not use the load balancer to access the Query Frontend. In Kubernetes, you should use a separate headless service.\nTo configure the Queries to use the Query Frontend, set the following flag:\n-querier.frontend-address string Address of query frontend service. There are other flag you can use to control the behaviour of the frontend - concurrency, retries, etc. See Query Frontend configuration for more information.\nThe Query Frontend can run using an in-process cache, but should be configured with an external Memcached for production workloads. The next section has more details.\n3. Setup Caching Correctly configured caching is important for a production-ready Cortex cluster. Cortex has many opportunities for using caching to accelerate queries and reduce cost.\nFor more information, see the Caching in Cortex documentation.\n4. Monitoring and Alerting Cortex exports metrics in the Prometheus format. We recommend you install and configure Prometheus server to monitor your Cortex cluster.\nWe publish a set of Prometheus alerts and Grafana dashboards as the cortex-mixin. We recommend you use these for any production Cortex cluster.\n5. Authentication \u0026amp; Multitenancy If you want to run Cortex as a multi-tenant system, you need to give each tenant a unique ID - this can be any string. Managing tenants and allocating IDs must be done outside of Cortex. See Authentication and Authorisation for more information.\n6. Handling HA Prometheus Pairs You should use a pair of Prometheus servers to monitor your targets and send metrics to Cortex. This allows your monitoring system to survive the failure of one of these Prometheus instances. Cortex support deduping the samples on ingestion. For more information on how to configure Cortex and Prometheus to HA pairs, see Config for sending HA Pairs data to Cortex.\n","excerpt":"This document builds on the getting started guide and specifies the steps needed to get Cortex into …","ref":"/docs/production/running-in-production/","title":"Running Cortex in Production"},{"body":" Author: Joe Elliott Date: April 2020 Status: Proposed Overview This document aims to describe the role that the Cortex Query Frontend plays in running multitenant Cortex at scale. It also describes the challenges of horizontally scaling the query frontend component and includes several recommendations and options for creating a reliably scalable query-frontend. Finally, we conclude with a discussion of the overall philosophy of the changes and propose an alternative.\nFor the original design behind the query frontend, you should read Cortex Query Optimisations design doc from 2018-07.\nReasoning Query frontend scaling is becoming increasingly important for two primary reasons.\nThe Cortex team is working toward a scalable single binary solution. Recently the query-frontend was added to the Cortex single binary mode and, therefore, needs to seamlessly scale. Technically, nothing immediately breaks when scaling the query-frontend, but there are a number of concerns detailed in Challenges And Proposals.\nAs the query-frontend continues to support additional features it will start to become a bottleneck of the system. Current wisdom is to run very few query-frontends in order to maximize Tenancy Fairness but as more features are added scaling horizontally will become necessary.\nQuery Frontend Role Load Shedding The query frontend maintains a queue per tenant of configurable length (default 100) in which it stores a series of requests from that tenant. If this queue fills up then the frontend will return 429’s thus load shedding the rest of the system.\nThis is particularly effective due to the “pull” based model in which queriers pull requests from query frontends.\nQuery Retries The query frontend is capable of retrying a query on another querier if the first should fail due to OOM or network issues.\nSharding/Parallelization The query frontend shards requests by interval and other factors to concurrently run a single query across multiple queriers.\nQuery Alignment/Caching Queries are aligned to their own step and then stored/retrieved from cache.\nTenancy Fairness By maintaining one queue per tenant, a low demand tenant will have the same opportunity to have a query serviced as a high demand tenant. See Dilutes Tenant Fairness for additional discussion.\nFor clarity, tenancy fairness only comes into play when queries are actually being queued in the query frontend. Currently this rarely occurs, but as query sharding becomes more aggressive this may become the norm.\nChallenges And Proposals Dynamic Querier Concurrency Challenge For every query frontend the querier adds a configurable number of goroutines which are each capable of executing a query. Therefore, scaling the query frontend impacts the amount of work each individual querier is attempting to do at any given time.\nScaling up may cause a querier to attempt more work than they are configured for due to restrictions such as memory and cpu limits. Additionally, the promql engine itself is limited in the number of queries it can do as configured by the -querier.max-concurrent parameter. Attempting more queries concurrently than this value causes the queries to queue up in the querier itself.\nFor similar reasons scaling down the query frontend may cause a querier to not use its allocated memory and cpu effectively. This will lower effective resource utilization. Also, because individual queriers will be doing less work, this may cause increased queueing in the query frontends.\nProposal Currently queriers are configured to have a max parallelism per query frontend. An additional “total max concurrency” flag should be added.\nTotal Max Concurrency would then be evenly divided amongst all available query frontends. This would decouple the amount of work a querier is attempting to do with the number of query frontends that happen to exist at this moment. Consequently this would allow allocated resources (e.g. k8s cpu/memory limits) to remain balanced with the work the querier was attempting as the query frontend is scaled up or down.\nA PR has already been merged to address this.\nOverwhelming PromQL Concurrency Challenge If #frontends \u0026gt; promql concurrency then the queriers are incapable of devoting even a single worker to each query frontend without risking queueing in the querier. Queuing in the querier is a highly undesirable state and one of the primary reasons the query frontend was originally created.\nProposal When #frontends \u0026gt; promql concurrency then each querier will maintain exactly one connection to every frontend. As the query frontend is currently coded it will attempt to use every open GRPC connection to execute a query in the attached queriers. Therefore, in this situation where #frontends \u0026gt; promql concurrency, the querier is exposing itself to more work then it is actually configured to perform.\nTo prevent this we will add “flow control” information to the ProcessResponse message that is used to return query results from the querier to the query frontend. In an active system this message is passed multiple times per second from the queriers to the query frontends and would be a reliable way for the frontends to track the state of queriers and balance load.\nThere are a lot of options for an exact implementation of this idea. An effective solution should be determined and chosen by modeling a set of alternatives. The details of this would be included in another design doc. A simple implementation would look something like the following:\nAdd two new fields to ProcessResponse:\nmessage ProcessResponse { httpgrpc.HTTPResponse httpResponse = 1; currentConcurrency int = 2; desiredConcurrency int = 3;} currentConcurrency - The current number of queries being executed by the querier.\ndesiredConcurrency - The total number of queries that a querier is capable of executing.\nAdd a short backoff to the main frontend processing loop. This would cause the frontend to briefly back off of any querier that was overloaded but continue to send queries to those that were capable of doing work.\nif current \u0026gt; desired { zzz := (current - desired) * backoffDuration zzz *= 1 + rand.Float64() * .1 // jitter time.Sleep(zzz) } Passing flow control information from the querier to the frontend would also open up additional future work for more sophisticated load balancing across queriers. For example by simply comparing and choosing the least congested of two queriers we could dramatically improve how well work is distributed.\nIncreased Time To Failure Challenge Scaling the query frontend also increases the per tenant queue length by creating more queues. This could result in increased latencies where failing fast (429) would have been preferred.\nThe operator could reduce the queue length per query frontend in response to scaling out, but then they would run the risk of unnecessarily failing a request due to unbalanced distribution across query frontends. Also, shorter queues run the risk of failing to properly service heavily sharded queries.\nAnother concern is that a system with more queues will take longer to recover from an production event as it will have queued up more work.\nProposal Currently we are not proposing any changes to alleviate this concern. We believe this is solvable operationally. This can be revisited as more information is gathered.\nQuerier Discovery Lag Challenge Queriers have a configurable parameter that controls how often they refresh their query frontend list. The default value is 10 seconds. After a new query frontend is added the average querier will take 5 seconds (after DNS is updated) to become aware of it and begin requesting queries from it.\nProposal It is recommended to add a readiness/health check to the query frontend to prevent it from receiving queries while it is waiting for queriers to connect. HTTP health checks are supported by envoy, k8s, nginx, and basically any commodity load balancer. The query frontend would not indicate healthy on its health check until at least one querier had connected.\nIn a k8s environment this will require two services. One service for discovery with publishNotReadyAddresses set to true and one service for load balancing which honors the healthcheck/readiness probe. After a new query-frontend instance is created the \u0026ldquo;discovery service\u0026rdquo; would immediately have the ip of the new instance which would allow queriers to discover and attach to it. After queriers had connected it would then raise its readiness probe and appear on the \u0026ldquo;load balancing\u0026rdquo; service and begin receiving traffic.\nDilutes Tenant Fairness Challenge Given f query frontends, n tenants and an average of q queries in the frontend per tenant. The following assumes that queries are perfectly distributed across query frontends. The number of tenants per instance would be:\nThe chance that a query by a tenant with Q queries in the frontend is serviced next is:\nNote that fewer query frontends caps the impact of the number of active queries per tenant. If there is only one query frontend then the equation reduces to:\nand every tenant has an equal chance of being serviced regardless of the number of queued queries.\nAdding more query frontends favors high volume tenants by giving them more slots to be picked up by the next available querier. Fewer query frontends allows for an even playing field regardless of the number of active queries.\nFor clarity, it should be noted that tenant fairness is only impacted if queries are being queued in the frontend. Under normal operations this is currently not occurring although this may change with increased sharding.\nProposal Tenancy fairness is complex and is currently not impacting our system. Therefore we are proposing a very simple improvement to the query frontend. If/when frontend queuing becomes more common this can be revisited as we will understand the problem better.\nCurrently the query frontend picks a random tenant to service when a querier requests a new query. This can increase long tail latency if a tenant gets “unlucky” and is also exacerbated for low volume tenants by scaling the query frontend. Instead the query frontend could use a round robin approach to choose the next tenant to service. Round robin is a commonly used algorithm to increase fairness in scheduling.\nThis would be a very minor improvement, but would give some guarantees to low volume tenants that their queries would be serviced. This has been proposed in this issue.\nPros: Requires local knowledge only. Easier to implement than weighted round robin.\nCons: Improvement is minor.\nAlternatives to Round Robin\nDo Nothing\nAs is noted above tenancy fairness only comes into play when queries start queueing up in the query frontend. Internal Metrics for multi-tenant Cortex at Grafana show that this has only happened 5 times in the past week significantly enough to have been caught by Prometheus.\nRight now doing nothing is a viable option that will, almost always, fairly serve our tenants. There is, however, some concern that as sharding becomes more commonplace queueing will become more common and QOS will suffer due to reasons outlined in Dilutes Tenant Fairness.\nPros: Easy!\nCons: Nothing happens!\nWeighted Round Robin\nThe query frontends could maintain a local record of throughput or work per tenant. Tenants could then be sorted in QOS bands. In its simplest form there would be two QOS bands. The band of low volume tenants would be serviced twice for every one time the band of high volume tenants would be serviced. The full details of this approach would require a separate proposal.\nThis solution would also open up interesting future work. For instance, we could allow operators to manually configure tenants into QOS bands.\nPros: Requires local knowledge only. Can be extended later to allow tenants to be manually sorted into QOS tiers.\nCons: Improvement is better than Round Robin only. Relies on even distribution of queries across frontends. Increased complexity and difficulty in reasoning about edge cases.\nWeighted Round Robin With Gossiped Traffic\nThis approach would be equivalent to Weighted Round Robin proposed above but with tenant traffic volume gossiped between query frontends.\nPros: Benefits of Weighted Round Robin without the requirement of even query distribution. Even though it requires distributed information a failure in gossip means it gracefully degrades to Weighted Round Robin.\nCons: Requires cross instance communication. Increased complexity and difficulty in reasoning about edge cases.\nAlternative The proposals in this document have preferred augmenting existing components to make decisions with local knowledge. The unstated goal of these proposals is to build a distributed queue across a scaled query frontend that reliably and fairly serves our tenants.\nOverall, these proposals will create a robust system that is resistant to network partitions and failures of individual pieces. However, it will also create a complex system that could be difficult to reason about, contain hard to ascertain edge cases and nuanced failure modes.\nThe alternative is, instead of building a distributed queue, to add a new cortex queueing service that sits in between the frontends and the queriers. This queueing service would pull from the frontends and distribute to the queriers. It would decouple the stateful queue from the stateless elements of the query frontend and allow us to easily scale the query frontend while keeping the queue itself a singleton. In a single binary HA mode one (or few) of the replicas would be leader elected to serve this role.\nHaving a singleton queue is attractive because it is simple to reason about and gives us a single place to make fair cross tenant queueing decisions. It does, however, create a single point of failure and add another network hop to the query path.\nConclusion In this document we reviewed the reasons the frontend exists, challenges and proposals to scaling the frontend and an alternative architecture that avoids most problems but comes with its own challenges.\n Challenge Proposal Status Dynamic Querier Concurrency Add Max Total Concurrency in Querier Pull Request Overwhelming PromQL Concurrency Queriers Coordinate Concurrency with Frontends Proposed Increased Time to Failure Operational/Configuration Issue. No Changes Proposed. Querier Discovery Lag Query Frontend HTTP Health Checks Proposed Dilutes Tenant Fairness Round Robin with additional alternatives proposed Issue ","excerpt":"Author: Joe Elliott Date: April 2020 Status: Proposed Overview This document aims to describe the …","ref":"/docs/proposals/scalable-query-frontend/","title":"Scalable Query Frontend"},{"body":" Author: @gotjosh Reviewers: @gouthamve, @pracucci Date: March 2020 Status: Accepted Problem Statement Prometheus holds metric metadata alongside the contents of a scrape. This metadata (HELP, TYPE, UNIT and METRIC_NAME) enables some Prometheus API endpoints to output the metadata for integrations (e.g. Grafana) to consume it.\nAt the moment of writing, Cortex does not support the api/v1/metadata endpoint that Prometheus implements as metadata was never propagated via remote write. Recent work is done in Prometheus enables the propagation of metadata.\nWith this in place, remote write integrations such as Cortex can now receive this data and implement the API endpoint. This results in Cortex users being able to enjoy a tiny bit more insight on their metrics.\nPotential Solutions Before we delve into the solutions, let\u0026rsquo;s set a baseline about how the data is received. This applies almost equally for the two.\nMetadata from Prometheus is sent in the same WriteRequest proto message that the samples use. It is part of a different field (#3 given #2 is already used interally), the data is a set identified by the metric name - that means it is aggregated across targets, and is sent all at once. Implying, Cortex will receive a single WriteRequest containing a set of the metadata for that instance at an specified interval.\n. It is also important to note that this current process is an intermediary step. Eventually, metadata in a request will be sent alongside samples and only for those included. The solutions proposed, take this nuance into account to avoid coupling between the current and future state of Prometheus, and hopefully do something now that also works for the future.\nAs a reference, these are some key numbers regarding the size (and send timings) of the data at hand from our clusters at Grafana Labs:\n On average, metadata (a combination of HELP, TYPE, UNIT and METRIC_NAME) is ~55 bytes uncompressed. at GL, on an instance with about 2.6M active series, we hold ~1241 unique metrics in total. with that, we can assume that on a worst-case scenario the metadata set for that instance is ~68 kilobytes uncompressed. by default, this data is only propagated once every minute (aligning with the default scrape interval), but this can be adjusted. Finally, what this gives us is a baseline worst-case scenario formula for the data to store per tenant: ~68KB * Replication Factor * # of Instances. Keeping in mind that typically, there\u0026rsquo;s a very high overlap of metadata across instances, and we plan to deduplicate in the ingesters. Write Path Store the metadata directly from the distributors into a cache (e.g. Memcached) Since metadata is received all at once, we could directly store into an external cache using the tenant ID as a key, and still, avoid a read-modify-write. However, a very common use case of Cortex is to have multiple Prometheus sending data for the same tenant ID. This complicates things, as it adds a need to have an intermediary merging phase and thus making a read-modify-write inevitable.\n Keep metadata in memory within the ingesters Similarly to what we do with sample data, we can keep the metadata in-memory in the ingesters and apply similar semantics. I propose to use the tenant ID as a hash key, distribute it to the ingesters (taking into account the replication factor), using a hash map to keep a set of the metadata across all instances for a single tenant, and implement a configurable time-based purge process to deal with metadata churn. Given, we need to ensure fair-use we also propose implementing limits for both the number of metadata entries we can receive and the size of a single entry.\nRead Path In my eyes, the read path seems to only have one option. At the moment of writing, Cortex uses a DummyTargetRetriever as a way to signal that these API endpoints are not implemented. We\u0026rsquo;d need to modify the Prometheus interface to support a Context and extract the tenant ID from there. Then, use the tenant ID to query the ingesters for the data, deduplicate it and serve it.\nConclusions I conclude that solution #2 is ideal for this work on the write path. It allows us to use similar semantics to samples, thus reducing operational complexity, and lays a groundwork for when we start receiving metadata alongside samples.\nThere\u0026rsquo;s one last piece to address: Allowing metadata to survive rolling restarts. Option #1 handles this well, given the aim would be to use an external cache such as Memcached. Option #2 lacks this, as it does not include any plans to persist this data. Given Prometheus (by default) sends metadata every minute, and we don\u0026rsquo;t need a high level of consistency. We expect that an eventual consistency of up to 1 minute on the default case is deemed acceptable.\nReferences Prometheus Propagate metadata via Remote Write Design Doc Prometheus Propagate metadata via Remote Write Design Issue ","excerpt":"Author: @gotjosh Reviewers: @gouthamve, @pracucci Date: March 2020 Status: Accepted Problem …","ref":"/docs/proposals/support-metadata-api/","title":"Support metadata API"},{"body":" Cortex consists of multiple horizontally scalable microservices. Each microservice uses the most appropriate technique for horizontal scaling; most are stateless and can handle requests for any users while some (namely the ingesters) are semi-stateful and depend on consistent hashing. This document provides a basic overview of Cortex\u0026rsquo;s architecture.\nThe role of Prometheus Prometheus instances scrape samples from various targets and then push them to Cortex (using Prometheus\u0026rsquo; remote write API). That remote write API emits batched Snappy-compressed Protocol Buffer messages inside the body of an HTTP PUT request.\nCortex requires that each HTTP request bear a header specifying a tenant ID for the request. Request authentication and authorization are handled by an external reverse proxy.\nIncoming samples (writes from Prometheus) are handled by the distributor while incoming reads (PromQL queries) are handled by the querier or optionally by the query frontend.\nStorage Cortex currently supports two storage engines to store and query the time series:\n Chunks (default, stable) Blocks (experimental) The two engines mostly share the same Cortex architecture with few differences outlined in the rest of the document.\nChunks storage (default) The chunks storage stores each single time series into a separate object called Chunk. Each Chunk contains the samples for a given period (defaults to 12 hours). Chunks are then indexed by time range and labels, in order to provide a fast lookup across many (over millions) Chunks.\nFor this reason, the chunks storage consists of:\n An index for the Chunks. This index can be backed by: Amazon DynamoDB Google Bigtable Apache Cassandra An object store for the Chunk data itself, which can be: Amazon DynamoDB Google Bigtable Apache Cassandra Amazon S3 Google Cloud Storage Microsoft Azure Storage Internally, the access to the chunks storage relies on a unified interface called \u0026ldquo;chunks store\u0026rdquo;. Unlike other Cortex components, the chunk store is not a separate service, but rather a library embedded in the services that need to access the long-term storage: ingester, querier and ruler.\nThe chunk and index format are versioned, this allows Cortex operators to upgrade the cluster to take advantage of new features and improvements. This strategy enables changes in the storage format without requiring any downtime or complex procedures to rewrite the stored data. A set of schemas are used to map the version while reading and writing time series belonging to a specific period of time.\nThe current schema recommendation is the v10 schema (v11 is still experimental). For more information about the schema, please check out the Schema documentation.\nBlocks storage (experimental) The blocks storage is based on Prometheus TSDB: it stores each tenant\u0026rsquo;s time series into their own TSDB which write out their series to a on-disk Block (defaults to 2h block range periods). Each Block is composed by few files storing the chunks and the block index.\nThe TSDB chunk files contain the samples for multiple series. The series inside the Chunks are then indexed by a per-block index, which indexes metric names and labels to time series in the chunk files.\nThe blocks storage doesn\u0026rsquo;t require a dedicated storage backend for the index. The only requirement is an object store for the Block files, which can be:\n Amazon S3 Google Cloud Storage Microsoft Azure Storage Local Filesystem (single node only) OpenStack Swift (experimental) For more information, please check out the Blocks storage documentation.\nServices Cortex has a service-based architecture, in which the overall system is split up into a variety of components that perform a specific task. These components run separately and in parallel. Cortex can alternatively run in a single process mode, where all components are executed within a single process. The single process mode is particularly handy for local testing and development.\nCortex is, for the most part, a shared-nothing system. Each layer of the system can run multiple instances of each component and they don\u0026rsquo;t coordinate or communicate with each other within that layer.\nThe Cortex services are:\n Distributor Ingester Querier Query frontend (optional) Ruler (optional) Alertmanager (optional) Configs API (optional) Distributor The distributor service is responsible for handling incoming samples from Prometheus. It\u0026rsquo;s the first stop in the write path for series samples. Once the distributor receives samples from Prometheus, each sample is validated for correctness and to ensure that it is within the configured tenant limits, falling back to default ones in case limits have not been overridden for the specific tenant. Valid samples are then split into batches and sent to multiple ingesters in parallel.\nThe validation done by the distributor includes:\n The metric labels name are formally correct The configured max number of labels per metric is respected The configured max length of a label name and value is respected The timestamp is not older/newer than the configured min/max time range Distributors are stateless and can be scaled up and down as needed.\nHigh Availability Tracker The distributor features a High Availability (HA) Tracker. When enabled, the distributor deduplicates incoming samples from redundant Prometheus servers. This allows you to have multiple HA replicas of the same Prometheus servers, writing the same series to Cortex and then deduplicate these series in the Cortex distributor.\nThe HA Tracker deduplicates incoming samples based on a cluster and replica label. The cluster label uniquely identifies the cluster of redundant Prometheus servers for a given tenant, while the replica label uniquely identifies the replica within the Prometheus cluster. Incoming samples are considered duplicated (and thus dropped) if received by any replica which is not the current primary within a cluster.\nThe HA Tracker requires a key-value (KV) store to coordinate which replica is currently elected. The distributor will only accept samples from the current leader. Samples with one or no labels (of the replica and cluster) are accepted by default and never deduplicated.\nThe supported KV stores for the HA tracker are:\n Consul Etcd For more information, please refer to config for sending HA pairs data to Cortex in the documentation.\nHashing Distributors use consistent hashing, in conjunction with a configurable replication factor, to determine which ingester instance(s) should receive a given series.\nCortex supports two hashing strategies:\n Hash the metric name and tenant ID (default) Hash the metric name, labels and tenant ID (enabled with -distributor.shard-by-all-labels=true) The trade-off associated with the latter is that writes are more balanced across ingesters but each query needs to talk to any ingester since a metric could be spread across multiple ingesters given different label sets.\nThe hash ring A hash ring (stored in a key-value store) is used to achieve consistent hashing for the series sharding and replication across the ingesters. All ingesters register themselves into the hash ring with a set of tokens they own; each token is a random unsigned 32-bit number. Each incoming series is hashed in the distributor and then pushed to the ingester owning the tokens range for the series hash number plus N-1 subsequent ingesters in the ring, where N is the replication factor.\nTo do the hash lookup, distributors find the smallest appropriate token whose value is larger than the hash of the series. When the replication factor is larger than 1, the next subsequent tokens (clockwise in the ring) that belong to different ingesters will also be included in the result.\nThe effect of this hash set up is that each token that an ingester owns is responsible for a range of hashes. If there are three tokens with values 0, 25, and 50, then a hash of 3 would be given to the ingester that owns the token 25; the ingester owning token 25 is responsible for the hash range of 1-25.\nThe supported KV stores for the hash ring are:\n Consul Etcd Gossip memberlist (experimental) Quorum consistency Since all distributors share access to the same hash ring, write requests can be sent to any distributor and you can setup a stateless load balancer in front of it.\nTo ensure consistent query results, Cortex uses Dynamo-style quorum consistency on reads and writes. This means that the distributor will wait for a positive response of at least one half plus one of the ingesters to send the sample to before successfully responding to the Prometheus write request.\nLoad balancing across distributors We recommend randomly load balancing write requests across distributor instances. For example, if you\u0026rsquo;re running Cortex in a Kubernetes cluster, you could run the distributors as a Kubernetes Service.\nIngester The ingester service is responsible for writing incoming series to a long-term storage backend on the write path and returning in-memory series samples for queries on the read path.\nIncoming series are not immediately written to the storage but kept in memory and periodically flushed to the storage (by default, 12 hours for the chunks storage and 2 hours for the experimental blocks storage). For this reason, the queriers may need to fetch samples both from ingesters and long-term storage while executing a query on the read path.\nIngesters contain a lifecycler which manages the lifecycle of an ingester and stores the ingester state in the hash ring. Each ingester could be in one of the following states:\n PENDING is an ingester\u0026rsquo;s state when it just started and is waiting for a hand-over from another ingester that is LEAVING. If no hand-over occurs within the configured timeout period (\u0026ldquo;auto-join timeout\u0026rdquo;, configurable via -ingester.join-after option), the ingester will join the ring with a new set of random tokens (ie. during a scale up). When hand-over process starts, state changes to JOINING.\n JOINING is an ingester\u0026rsquo;s state in two situations. First, ingester will switch to a JOINING state from PENDING state after auto-join timeout. In this case, ingester will generate tokens, store them into the ring, optionally observe the ring for token conflicts and then move to ACTIVE state. Second, ingester will also switch into a JOINING state as a result of another LEAVING ingester initiating a hand-over process with PENDING (which then switches to JOINING state). JOINING ingester then receives series and tokens from LEAVING ingester, and if everything goes well, JOINING ingester switches to ACTIVE state. If hand-over process fails, JOINING ingester will move back to PENDING state and either wait for another hand-over or auto-join timeout.\n ACTIVE is an ingester\u0026rsquo;s state when it is fully initialized. It may receive both write and read requests for tokens it owns.\n LEAVING is an ingester\u0026rsquo;s state when it is shutting down. It cannot receive write requests anymore, while it could still receive read requests for series it has in memory. While in this state, the ingester may look for a PENDING ingester to start a hand-over process with, used to transfer the state from LEAVING ingester to the PENDING one, during a rolling update (PENDING ingester moves to JOINING state during hand-over process). If there is no new ingester to accept hand-over, ingester in LEAVING state will flush data to storage instead.\n UNHEALTHY is an ingester\u0026rsquo;s state when it has failed to heartbeat to the ring\u0026rsquo;s KV Store. While in this state, distributors skip the ingester while building the replication set for incoming series and the ingester does not receive write or read requests.\n For more information about the hand-over process, please check out the Ingester hand-over documentation.\nIngesters are semi-stateful.\nIngesters failure and data loss If an ingester process crashes or exits abruptly, all the in-memory series that have not yet been flushed to the long-term storage will be lost. There are two main ways to mitigate this failure mode:\n Replication Write-ahead log (WAL) The replication is used to hold multiple (typically 3) replicas of each time series in the ingesters. If the Cortex cluster looses an ingester, the in-memory series hold by the lost ingester are also replicated at least to another ingester. In the event of a single ingester failure, no time series samples will be lost while, in the event of multiple ingesters failure, time series may be potentially lost if failure affects all the ingesters holding the replicas of a specific time series.\nThe write-ahead log (WAL) is used to write to a persistent local disk all incoming series samples until they\u0026rsquo;re flushed to the long-term storage. In the event of an ingester failure, a subsequent process restart will replay the WAL and recover the in-memory series samples.\nContrary to the sole replication and given the persistent local disk data is not lost, in the event of multiple ingesters failure each ingester will recover the in-memory series samples from WAL upon subsequent restart. The replication is still recommended in order to ensure no temporary failures on the read path in the event of a single ingester failure.\nThe WAL for the chunks storage is an experimental feature (disabled by default), while it\u0026rsquo;s always enabled for the blocks storage.\nIngesters write de-amplification Ingesters store recently received samples in-memory in order to perform write de-amplification. If the ingesters would immediately write received samples to the long-term storage, the system would be very difficult to scale due to the very high pressure on the storage. For this reason, the ingesters batch and compress samples in-memory and periodically flush them out to the storage.\nWrite de-amplification is the main source of Cortex\u0026rsquo;s low total cost of ownership (TCO).\nQuerier The querier service handles queries using the PromQL query language.\nQueriers fetch series samples both from the ingesters and long-term storage: the ingesters hold the in-memory series which have not yet been flushed to the long-term storage. Because of the replication factor, it is possible that the querier may receive duplicated samples; to resolve this, for a given time series the querier internally deduplicates samples with the same exact timestamp.\nQueriers are stateless and can be scaled up and down as needed.\nQuery frontend The query frontend is an optional service providing the querier\u0026rsquo;s API endpoints and can be used to accelerate the read path. When the query frontend is in place, incoming query requests should be directed to the query frontend instead of the queriers. The querier service will be still required within the cluster, in order to execute the actual queries.\nThe query frontend internally performs some query adjustments and holds queries in an internal queue. In this setup, queriers act as workers which pull jobs from the queue, execute them, and return them to the query-frontend for aggregation. Queriers need to be configured with the query frontend address (via the -querier.frontend-address CLI flag) in order to allow them to connect to the query frontends.\nQuery frontends are stateless. However, due to how the internal queue works, it\u0026rsquo;s recommended to run a few query frontend replicas to reap the benefit of fair scheduling. Two replicas should suffice in most cases.\nQueueing The query frontend queuing mechanism is used to:\n Ensure that large queries, that could cause an out-of-memory (OOM) error in the querier, will be retried on failure. This allows administrators to under-provision memory for queries, or optimistically run more small queries in parallel, which helps to reduce the TCO. Prevent multiple large requests from being convoyed on a single querier by distributing them across all queriers using a first-in/first-out queue (FIFO). Prevent a single tenant from denial-of-service-ing (DOSing) other tenants by fairly scheduling queries between tenants. Splitting The query frontend splits multi-day queries into multiple single-day queries, executing these queries in parallel on downstream queriers and stitching the results back together again. This prevents large (multi-day) queries from causing out of memory issues in a single querier and helps to execute them faster.\nCaching The query frontend supports caching query results and reuses them on subsequent queries. If the cached results are incomplete, the query frontend calculates the required subqueries and executes them in parallel on downstream queriers. The query frontend can optionally align queries with their step parameter to improve the cacheability of the query results. The result cache is compatible with any cortex caching backend (currently memcached, redis, and an in-memory cache).\nRuler The ruler is an optional service executing PromQL queries for recording rules and alerts. The ruler requires a database storing the recording rules and alerts for each tenant.\nRuler is semi-stateful and can be scaled horizontally. Running rules internally have state, as well as the ring the rulers initiate. However, if the rulers all fail and restart, Prometheus alert rules have a feature where an alert is restored and returned to a firing state if it would have been active in its for period. However, there would be gaps in the series generated by the recording rules.\nAlertmanager The alertmanager is an optional service responsible for accepting alert notifications from the ruler, deduplicating and grouping them, and routing them to the correct notification channel, such as email, PagerDuty or OpsGenie.\nThe Cortex alertmanager is built on top of the Prometheus Alertmanager, adding multi-tenancy support. Like the ruler, the alertmanager requires a database storing the per-tenant configuration.\nAlertmanager is semi-stateful. The Alertmanager persists information about silences and active alerts to its disk. If all of the alertmanager nodes failed simultaneously there would be a loss of data.\nConfigs API The configs API is an optional service managing the configuration of Rulers and Alertmanagers. It provides APIs to get/set/update the ruler and alertmanager configurations and store them into backend. Current supported backend are PostgreSQL and in-memory.\nConfigs API is stateless.\n","excerpt":"Cortex consists of multiple horizontally scalable microservices. Each microservice uses the most …","ref":"/docs/architecture/","title":"Cortex Architecture"},{"body":" Cortex can be run as a single binary or as multiple independent microservices. The single-binary mode is easier to deploy and is aimed mainly at users wanting to try out Cortex or develop on it. The microservices mode is intended for production usage, as it allows you to independently scale different services and isolate failures.\nThis document will focus on single-process Cortex with the experimental blocks storage. See the architecture doc for more information about the microservices and blocks operation for more information about the blocks storage.\nSeparately from single process vs microservices decision, Cortex can be configured to use local storage or cloud storage (S3, GCS and Azure). Cortex can also make use of external Memcacheds and Redis for caching but this feature is not (yet) available using blocks storage.\nSingle instance, single process For simplicity and to get started, we\u0026rsquo;ll run it as a single process with no dependencies. You can reconfigure the config to use GCS, Azure storage or local storage as shown in the file\u0026rsquo;s comments.\n$ go build ./cmd/cortex $ ./cortex -config.file=./docs/configuration/single-process-config-blocks.yaml Unless reconfigured this starts a single Cortex node storing blocks to S3 in bucket cortex. It is not intended for production use.\nClone and build prometheus\n$ git clone https://github.com/prometheus/prometheus $ cd prometheus $ go build ./cmd/prometheus Add the following to your Prometheus config (documentation/examples/prometheus.yml in Prometheus repo):\nremote_write:-url:http://localhost:9009/api/prom/push And start Prometheus with that config file:\n$ ./prometheus --config.file=./documentation/examples/prometheus.yml Your Prometheus instance will now start pushing data to Cortex. To query that data, start a Grafana instance:\n$ docker run --rm -d --name=grafana -p 3000:3000 grafana/grafana In the Grafana UI (username/password admin/admin), add a Prometheus datasource for Cortex (http://host.docker.internal:9009/api/prom).\nTo clean up: press CTRL-C in both terminals (for Cortex and Promrtheus).\nHorizontally scale out Next we\u0026rsquo;re going to show how you can run a scale out Cortex cluster using Docker. We\u0026rsquo;ll need:\n A built Cortex image. A Docker network to put these containers on so they can resolve each other by name. A single node Consul instance to coordinate the Cortex cluster.\n$ make ./cmd/cortex/.uptodate $ docker network create cortex $ docker run -d --name=consul --network=cortex -e CONSUL_BIND_INTERFACE=eth0 consul Next we\u0026rsquo;ll run a couple of Cortex instances pointed at that Consul. You\u0026rsquo;ll note the Cortex configuration can be specified in either a config file or overridden on the command line. See the arguments documentation for more information about Cortex configuration options.\n$ docker run -d --name=cortex1 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config-blocks.yaml:/etc/single-process-config-blocks.yaml \\ -p 9001:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config-blocks.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 $ docker run -d --name=cortex2 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config-blocks.yaml:/etc/single-process-config-blocks.yaml \\ -p 9002:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config-blocks.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 If you go to http://localhost:9001/ring (or http://localhost:9002/ring) you should see both Cortex nodes join the ring.\nTo demonstrate the correct operation of Cortex clustering, we\u0026rsquo;ll send samples to one of the instances and queries to another. In production, you\u0026rsquo;d want to load balance both pushes and queries evenly among all the nodes.\nPoint Prometheus at the first:\nremote_write:-url:http://localhost:9001/api/prom/push$ ./prometheus --config.file=./documentation/examples/prometheus.yml And Grafana at the second:\n$ docker run -d --name=grafana --network=cortex -p 3000:3000 grafana/grafana In the Grafana UI (username/password admin/admin), add a Prometheus datasource for Cortex (http://cortex2:9009/api/prom).\nTo clean up: CTRL-C the Prometheus process and run:\n$ docker rm -f cortex1 cortex2 consul grafana $ docker network remove cortex High availability with replication In this last demo we\u0026rsquo;ll show how Cortex can replicate data among three nodes, and demonstrate Cortex can tolerate a node failure without affecting reads and writes.\nFirst, create a network and run a new Consul and Grafana:\n$ docker network create cortex $ docker run -d --name=consul --network=cortex -e CONSUL_BIND_INTERFACE=eth0 consul $ docker run -d --name=grafana --network=cortex -p 3000:3000 grafana/grafana Then, launch 3 Cortex nodes with replication factor 3:\n$ docker run -d --name=cortex1 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config-blocks.yaml:/etc/single-process-config-blocks.yaml \\ -p 9001:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config-blocks.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 \\ -distributor.replication-factor=3 $ docker run -d --name=cortex2 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config-blocks.yaml:/etc/single-process-config-blocks.yaml \\ -p 9002:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config-blocks.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 \\ -distributor.replication-factor=3 $ docker run -d --name=cortex3 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config-blocks.yaml:/etc/single-process-config-blocks.yaml \\ -p 9003:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config-blocks.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 \\ -distributor.replication-factor=3 Configure Prometheus to send data to the first replica:\nremote_write:-url:http://localhost:9001/api/prom/push$ ./prometheus --config.file=./documentation/examples/prometheus.yml In Grafana, add a datasource for the 3rd Cortex replica (http://cortex3:9009/api/prom) and verify the same data appears in both Prometheus and Cortex.\nTo show that Cortex can tolerate a node failure, hard kill one of the Cortex replicas:\n$ docker rm -f cortex2 You should see writes and queries continue to work without error.\nTo clean up: CTRL-C the Prometheus process and run:\n$ docker rm -f cortex1 cortex2 cortex3 consul grafana $ docker network remove cortex ","excerpt":"Cortex can be run as a single binary or as multiple independent microservices. The single-binary …","ref":"/docs/getting-started/getting-started-blocks-storage/","title":"Getting Started with Blocks Storage (experimental)"},{"body":" General Notes Cortex has evolved over several years, and the command-line options sometimes reflect this heritage. In some cases the default value for options is not the recommended value, and in some cases names do not reflect the true meaning. We do intend to clean this up, but it requires a lot of care to avoid breaking existing installations. In the meantime we regret the inconvenience.\nDuration arguments should be specified with a unit like 5s or 3h. Valid time units are \u0026ldquo;ms\u0026rdquo;, \u0026ldquo;s\u0026rdquo;, \u0026ldquo;m\u0026rdquo;, \u0026ldquo;h\u0026rdquo;.\nQuerier -querier.max-concurrent The maximum number of top-level PromQL queries that will execute at the same time, per querier process. If using the query frontend, this should be set to at least (-querier.worker-parallelism * number of query frontend replicas). Otherwise queries may queue in the queriers and not the frontend, which will affect QoS. Alternatively, consider using -querier.worker-match-max-concurrent to force worker parallelism to match -querier.max-concurrent.\n -querier.query-parallelism This refers to database queries against the store (e.g. Bigtable or DynamoDB). This is the max subqueries run in parallel per higher-level query.\n -querier.timeout The timeout for a top-level PromQL query.\n -querier.max-samples Maximum number of samples a single query can load into memory, to avoid blowing up on enormous queries.\nThe next three options only apply when the querier is used together with the Query Frontend:\n -querier.frontend-address Address of query frontend service, used by workers to find the frontend which will give them queries to execute.\n -querier.dns-lookup-period How often the workers will query DNS to re-check where the frontend is.\n -querier.worker-parallelism Number of simultaneous queries to process, per query frontend. See note on -querier.max-concurrent\n -querier.worker-match-max-concurrent Force worker concurrency to match the -querier.max-concurrent option. Overrides -querier.worker-parallelism. See note on -querier.max-concurrent\nQuerier and Ruler The ingester query API was improved over time, but defaults to the old behaviour for backwards-compatibility. For best results both of these next two flags should be set to true:\n -querier.batch-iterators This uses iterators to execute query, as opposed to fully materialising the series in memory, and fetches multiple results per loop.\n -querier.ingester-streaming Use streaming RPCs to query ingester, to reduce memory pressure in the ingester.\n -querier.iterators This is similar to -querier.batch-iterators but less efficient. If both iterators and batch-iterators are true, batch-iterators will take precedence.\n -promql.lookback-delta Time since the last sample after which a time series is considered stale and ignored by expression evaluations.\nQuery Frontend -querier.parallelise-shardable-queries If set to true, will cause the query frontend to mutate incoming queries when possible by turning sum operations into sharded sum operations. This requires a shard-compatible schema (v10+). An abridged example: sum by (foo) (rate(bar{baz=”blip”}[1m])) -\u0026gt;\n sum by (foo) ( sum by (foo) (rate(bar{baz=”blip”,__cortex_shard__=”0of16”}[1m])) or sum by (foo) (rate(bar{baz=”blip”,__cortex_shard__=”1of16”}[1m])) or ... sum by (foo) (rate(bar{baz=”blip”,__cortex_shard__=”15of16”}[1m])) ) When enabled, the query-frontend requires a schema config to determine how/when to shard queries, either from a file or from flags (i.e. by the config-yaml CLI flag). This is the same schema config the queriers consume. It\u0026rsquo;s also advised to increase downstream concurrency controls as well to account for more queries of smaller sizes:\n querier.max-outstanding-requests-per-tenant querier.max-query-parallelism querier.max-concurrent server.grpc-max-concurrent-streams (for both query-frontends and queriers) Furthermore, both querier and query-frontend components require the querier.query-ingesters-within parameter to know when to start sharding requests (ingester queries are not sharded). It\u0026rsquo;s recommended to align this with ingester.max-chunk-age.\nInstrumentation (traces) also scale with the number of sharded queries and it\u0026rsquo;s suggested to account for increased throughput there as well (for instance via JAEGER_REPORTER_MAX_QUEUE_SIZE).\n -querier.align-querier-with-step If set to true, will cause the query frontend to mutate incoming queries and align their start and end parameters to the step parameter of the query. This improves the cacheability of the query results.\n -querier.split-queries-by-day If set to true, will cause the query frontend to split multi-day queries into multiple single-day queries and execute them in parallel.\n -querier.cache-results If set to true, will cause the querier to cache query results. The cache will be used to answer future, overlapping queries. The query frontend calculates extra queries required to fill gaps in the cache.\n -frontend.max-cache-freshness When caching query results, it is desirable to prevent the caching of very recent results that might still be in flux. Use this parameter to configure the age of results that should be excluded.\n -frontend.memcached.{hostname, service, timeout} Use these flags to specify the location and timeout of the memcached cluster used to cache query results.\n -frontend.redis.{endpoint, timeout} Use these flags to specify the location and timeout of the Redis service used to cache query results.\nDistributor -distributor.shard-by-all-labels In the original Cortex design, samples were sharded amongst distributors by the combination of (userid, metric name). Sharding by metric name was designed to reduce the number of ingesters you need to hit on the read path; the downside was that you could hotspot the write path.\nIn hindsight, this seems like the wrong choice: we do many orders of magnitude more writes than reads, and ingester reads are in-memory and cheap. It seems the right thing to do is to use all the labels to shard, improving load balancing and support for very high cardinality metrics.\nSet this flag to true for the new behaviour.\nImportant to note is that when setting this flag to true, it has to be set on both the distributor and the querier. If the flag is only set on the distributor and not on the querier, you will get incomplete query results because not all ingesters are queried.\nUpgrade notes: As this flag also makes all queries always read from all ingesters, the upgrade path is pretty trivial; just enable the flag. When you do enable it, you\u0026rsquo;ll see a spike in the number of active series as the writes are \u0026ldquo;reshuffled\u0026rdquo; amongst the ingesters, but over the next stale period all the old series will be flushed, and you should end up with much better load balancing. With this flag enabled in the queriers, reads will always catch all the data from all ingesters.\n -distributor.extra-query-delay This is used by a component with an embedded distributor (Querier and Ruler) to control how long to wait until sending more than the minimum amount of queries needed for a successful response.\n distributor.ha-tracker.enable-for-all-users Flag to enable, for all users, handling of samples with external labels identifying replicas in an HA Prometheus setup. This defaults to false, and is technically defined in the Distributor limits.\n distributor.ha-tracker.enable Enable the distributors HA tracker so that it can accept samples from Prometheus HA replicas gracefully (requires labels). Global (for distributors), this ensures that the necessary internal data structures for the HA handling are created. The option enable-for-all-users is still needed to enable ingestion of HA samples for all users.\n distributor.drop-label This flag can be used to specify label names that to drop during sample ingestion within the distributor and can be repeated in order to drop multiple labels.\n Ring/HA Tracker Store The KVStore client is used by both the Ring and HA Tracker. - {ring,distributor.ha-tracker}.prefix The prefix for the keys in the store. Should end with a /. For example with a prefix of foo/, the key bar would be stored under foo/bar. - {ring,distributor.ha-tracker}.store Backend storage to use for the ring (consul, etcd, inmemory, memberlist, multi).\nConsul By default these flags are used to configure Consul used for the ring. To configure Consul for the HA tracker, prefix these flags with distributor.ha-tracker.\n consul.hostname Hostname and port of Consul. consul.acl-token ACL token used to interact with Consul. consul.client-timeout HTTP timeout when talking to Consul. consul.consistent-reads Enable consistent reads to Consul. etcd By default these flags are used to configure etcd used for the ring. To configure etcd for the HA tracker, prefix these flags with distributor.ha-tracker.\n etcd.endpoints The etcd endpoints to connect to. etcd.dial-timeout The timeout for the etcd connection. etcd.max-retries The maximum number of retries to do for failed ops. memberlist (EXPERIMENTAL) Flags for configuring KV store based on memberlist library. This feature is experimental, please don\u0026rsquo;t use it yet.\n memberlist.nodename Name of the node in memberlist cluster. Defaults to hostname. memberlist.retransmit-factor Multiplication factor used when sending out messages (factor * log(N+1)). If not set, default value is used. memberlist.join Other cluster members to join. Can be specified multiple times. memberlist.abort-if-join-fails If this node fails to join memberlist cluster, abort. memberlist.left-ingesters-timeout How long to keep LEFT ingesters in the ring. Note: this is only used for gossiping, LEFT ingesters are otherwise invisible. memberlist.leave-timeout Timeout for leaving memberlist cluster. memberlist.gossip-interval How often to gossip with other cluster members. Uses memberlist LAN defaults if 0. memberlist.gossip-nodes How many nodes to gossip with in each gossip interval. Uses memberlist LAN defaults if 0. memberlist.pullpush-interval How often to use pull/push sync. Uses memberlist LAN defaults if 0. memberlist.bind-addr IP address to listen on for gossip messages. Multiple addresses may be specified. Defaults to 0.0.0.0. memberlist.bind-port Port to listen on for gossip messages. Defaults to 7946. memberlist.packet-dial-timeout Timeout used when connecting to other nodes to send packet. memberlist.packet-write-timeout Timeout for writing \u0026lsquo;packet\u0026rsquo; data. memberlist.transport-debug Log debug transport messages. Note: global log.level must be at debug level as well. memberlist.gossip-to-dead-nodes-time How long to keep gossiping to the nodes that seem to be dead. After this time, dead node is removed from list of nodes. If \u0026ldquo;dead\u0026rdquo; node appears again, it will simply join the cluster again, if its name is not reused by other node in the meantime. If the name has been reused, such a reanimated node will be ignored by other members. memberlist.dead-node-reclaim-time How soon can dead\u0026rsquo;s node name be reused by a new node (using different IP). Disabled by default, name reclaim is not allowed until gossip-to-dead-nodes-time expires. This can be useful to set to low numbers when reusing node names, eg. in stateful sets. If memberlist library detects that new node is trying to reuse the name of previous node, it will log message like this: Conflicting address for ingester-6. Mine: 10.44.12.251:7946 Theirs: 10.44.12.54:7946 Old state: 2. Node states are: \u0026ldquo;alive\u0026rdquo; = 0, \u0026ldquo;suspect\u0026rdquo; = 1 (doesn\u0026rsquo;t respond, will be marked as dead if it doesn\u0026rsquo;t respond), \u0026ldquo;dead\u0026rdquo; = 2. Multi KV This is a special key-value implementation that uses two different KV stores (eg. consul, etcd or memberlist). One of them is always marked as primary, and all reads and writes go to primary store. Other one, secondary, is only used for writes. The idea is that operator can use multi KV store to migrate from primary to secondary store in runtime.\nFor example, migration from Consul to Etcd would look like this:\n Set ring.store to use multi store. Set -multi.primary=consul and -multi.secondary=etcd. All consul and etcd settings must still be specified. Start all Cortex microservices. They will still use Consul as primary KV, but they will also write share ring via etcd. Operator can now use \u0026ldquo;runtime config\u0026rdquo; mechanism to switch primary store to etcd. After all Cortex microservices have picked up new primary store, and everything looks correct, operator can now shut down Consul, and modify Cortex configuration to use -ring.store=etcd only. At this point, Consul can be shut down. Multi KV has following parameters:\n multi.primary - name of primary KV store. Same values as in ring.store are supported, except multi. multi.secondary - name of secondary KV store. multi.mirror-enabled - enable mirroring of values to secondary store, defaults to true multi.mirror-timeout - wait max this time to write to secondary store to finish. Default to 2 seconds. Errors writing to secondary store are not reported to caller, but are logged and also reported via cortex_multikv_mirror_write_errors_total metric. Multi KV also reacts on changes done via runtime configuration. It uses this section:\nmulti_kv_config:mirror-enabled:falseprimary:memberlist Note that runtime configuration values take precedence over command line options.\nHA Tracker HA tracking has two of its own flags: - distributor.ha-tracker.cluster Prometheus label to look for in samples to identify a Prometheus HA cluster. (default \u0026ldquo;cluster\u0026rdquo;) - distributor.ha-tracker.replica Prometheus label to look for in samples to identify a Prometheus HA replica. (default \u0026ldquo;__replica__\u0026rdquo;)\nIt\u0026rsquo;s reasonable to assume people probably already have a cluster label, or something similar. If not, they should add one along with __replica__ via external labels in their Prometheus config. If you stick to these default values your Prometheus config could look like this (POD_NAME is an environment variable which must be set by you):\nglobal:external_labels:cluster:clustername__replica__:$POD_NAME HA Tracking looks for the two labels (which can be overwritten per user)\nIt also talks to a KVStore and has it\u0026rsquo;s own copies of the same flags used by the Distributor to connect to for the ring. - distributor.ha-tracker.failover-timeout If we don\u0026rsquo;t receive any samples from the accepted replica for a cluster in this amount of time we will failover to the next replica we receive a sample from. This value must be greater than the update timeout (default 30s) - distributor.ha-tracker.store Backend storage to use for the ring (consul, etcd, inmemory). (default \u0026ldquo;consul\u0026rdquo;) - distributor.ha-tracker.update-timeout Update the timestamp in the KV store for a given cluster/replica only after this amount of time has passed since the current stored timestamp. (default 15s)\nIngester -ingester.max-chunk-age The maximum duration of a timeseries chunk in memory. If a timeseries runs for longer than this the current chunk will be flushed to the store and a new chunk created. (default 12h)\n -ingester.max-chunk-idle If a series doesn\u0026rsquo;t receive a sample for this duration, it is flushed and removed from memory.\n -ingester.max-stale-chunk-idle If a series receives a staleness marker, then we wait for this duration to get another sample before we close and flush this series, removing it from memory. You want it to be at least 2x the scrape interval as you don\u0026rsquo;t want a single failed scrape to cause a chunk flush.\n -ingester.chunk-age-jitter To reduce load on the database exactly 12 hours after starting, the age limit is reduced by a varying amount up to this. Don\u0026rsquo;t enable this along with -ingester.spread-flushes (default 0m)\n -ingester.spread-flushes Makes the ingester flush each timeseries at a specific point in the max-chunk-age cycle. This means multiple replicas of a chunk are very likely to contain the same contents which cuts chunk storage space by up to 66%. Set -ingester.chunk-age-jitter to 0 when using this option. If a chunk cache is configured (via -store.chunks-cache.memcached.hostname) then duplicate chunk writes are skipped which cuts write IOPs.\n -ingester.join-after How long to wait in PENDING state during the hand-over process. (default 0s)\n -ingester.max-transfer-retries How many times a LEAVING ingester tries to find a PENDING ingester during the hand-over process. Each attempt takes a second or so. Negative value or zero disables hand-over process completely. (default 10)\n -ingester.normalise-tokens Deprecated. New ingesters always write \u0026ldquo;normalised\u0026rdquo; tokens to the ring. Normalised tokens consume less memory to encode and decode; as the ring is unmarshalled regularly, this significantly reduces memory usage of anything that watches the ring.\nCortex 0.4.0 is the last version that can write denormalised tokens. Cortex 0.5.0 and above always write normalised tokens.\nCortex 0.6.0 is the last version that can read denormalised tokens. Starting with Cortex 0.7.0 only normalised tokens are supported, and ingesters writing denormalised tokens to the ring (running Cortex 0.4.0 or earlier with -ingester.normalise-tokens=false) are ignored by distributors. Such ingesters should either switch to using normalised tokens, or be upgraded to Cortex 0.5.0 or later.\n -ingester.chunk-encoding Pick one of the encoding formats for timeseries data, which have different performance characteristics. Bigchunk uses the Prometheus V2 code, and expands in memory to arbitrary length. Varbit, Delta and DoubleDelta use Prometheus V1 code, and are fixed at 1K per chunk. Defaults to DoubleDelta, but we recommend Bigchunk.\n -store.bigchunk-size-cap-bytes When using bigchunks, start a new bigchunk and flush the old one if the old one reaches this size. Use this setting to limit memory growth of ingesters with a lot of timeseries that last for days.\n -ingester-client.expected-timeseries When push requests arrive, pre-allocate this many slots to decode them. Tune this setting to reduce memory allocations and garbage. This should match the max_samples_per_send in your queue_config for Prometheus.\n -ingester-client.expected-samples-per-series When push requests arrive, pre-allocate this many slots to decode them. Tune this setting to reduce memory allocations and garbage. Under normal conditions, Prometheus scrapes should arrive with one sample per series.\n -ingester-client.expected-labels When push requests arrive, pre-allocate this many slots to decode them. Tune this setting to reduce memory allocations and garbage. The optimum value will depend on how many labels are sent with your timeseries samples.\n -store.chunk-cache.cache-stubs Where you don\u0026rsquo;t want to cache every chunk written by ingesters, but you do want to take advantage of chunk write deduplication, this option will make ingesters write a placeholder to the cache for each chunk. Make sure you configure ingesters with a different cache to queriers, which need the whole value.\nWAL -ingester.wal-dir Directory where the WAL data should be stored and/or recovered from.\n -ingester.wal-enabled\n Setting this to true enables writing to WAL during ingestion.\n -ingester.checkpoint-duration This is the interval at which checkpoints should be created.\n -ingester.recover-from-wal Set this to true to recover data from an existing WAL. The data is recovered even if WAL is disabled and this is set to true. The WAL dir needs to be set for this.\n Flusher -flusher.wal-dir Directory where the WAL data should be recovered from.\n -flusher.concurrent-flushes Number of concurrent flushes.\n -flusher.flush-op-timeout Duration after which a flush should timeout.\n Runtime Configuration file Cortex has a concept of \u0026ldquo;runtime config\u0026rdquo; file, which is simply a file that is reloaded while Cortex is running. It is used by some Cortex components to allow operator to change some aspects of Cortex configuration without restarting it. File is specified by using -runtime-config.file=\u0026lt;filename\u0026gt; flag and reload period (which defaults to 10 seconds) can be changed by -runtime-config.reload-period=\u0026lt;duration\u0026gt; flag. Previously this mechanism was only used by limits overrides, and flags were called -limits.per-user-override-config=\u0026lt;filename\u0026gt; and -limits.per-user-override-period=10s respectively. These are still used, if -runtime-config.file=\u0026lt;filename\u0026gt; is not specified.\nAt the moment, two components use runtime configuration: limits and multi KV store.\nExample runtime configuration file:\noverrides:tenant1:ingestion_rate:10000max_series_per_metric:100000max_series_per_query:100000tenant2:max_samples_per_query:1000000max_series_per_metric:100000max_series_per_query:100000multi_kv_config:mirror-enabled:falseprimary:memberlist When running Cortex on Kubernetes, store this file in a config map and mount it in each services\u0026rsquo; containers. When changing the values there is no need to restart the services, unless otherwise specified.\nIngester, Distributor \u0026amp; Querier limits. Cortex implements various limits on the requests it can process, in order to prevent a single tenant overwhelming the cluster. There are various default global limits which apply to all tenants which can be set on the command line. These limits can also be overridden on a per-tenant basis by using overrides field of runtime configuration file.\nThe overrides field is a map of tenant ID (same values as passed in the X-Scope-OrgID header) to the various limits. An example could look like:\noverrides:tenant1:ingestion_rate:10000max_series_per_metric:100000max_series_per_query:100000tenant2:max_samples_per_query:1000000max_series_per_metric:100000max_series_per_query:100000 Valid per-tenant limits are (with their corresponding flags for default values):\n ingestion_rate_strategy / -distributor.ingestion-rate-limit-strategy ingestion_rate / -distributor.ingestion-rate-limit ingestion_burst_size / -distributor.ingestion-burst-size The per-tenant rate limit (and burst size), in samples per second. It supports two strategies: local (default) and global.\nThe local strategy enforces the limit on a per distributor basis, actual effective rate limit will be N times higher, where N is the number of distributor replicas.\nThe global strategy enforces the limit globally, configuring a per-distributor local rate limiter as ingestion_rate / N, where N is the number of distributor replicas (it\u0026rsquo;s automatically adjusted if the number of replicas change). The ingestion_burst_size refers to the per-distributor local rate limiter (even in the case of the global strategy) and should be set at least to the maximum number of samples expected in a single push request. For this reason, the global strategy requires that push requests are evenly distributed across the pool of distributors; if you use a load balancer in front of the distributors you should be already covered, while if you have a custom setup (ie. an authentication gateway in front) make sure traffic is evenly balanced across distributors.\nThe global strategy requires the distributors to form their own ring, which is used to keep track of the current number of healthy distributor replicas. The ring is configured by distributor: { ring: {}} / -distributor.ring.*.\n max_label_name_length / -validation.max-length-label-name max_label_value_length / -validation.max-length-label-value max_label_names_per_series / -validation.max-label-names-per-series Also enforced by the distributor, limits on the on length of labels and their values, and the total number of labels allowed per series.\n reject_old_samples / -validation.reject-old-samples reject_old_samples_max_age / -validation.reject-old-samples.max-age creation_grace_period / -validation.create-grace-period Also enforce by the distributor, limits on how far in the past (and future) timestamps that we accept can be.\n max_series_per_user / -ingester.max-series-per-user max_series_per_metric / -ingester.max-series-per-metric Enforced by the ingesters; limits the number of active series a user (or a given metric) can have. When running with -distributor.shard-by-all-labels=false (the default), this limit will enforce the maximum number of series a metric can have \u0026lsquo;globally\u0026rsquo;, as all series for a single metric will be sent to the same replication set of ingesters. This is not the case when running with -distributor.shard-by-all-labels=true, so the actual limit will be N/RF times higher, where N is number of ingester replicas and RF is configured replication factor.\nAn active series is a series to which a sample has been written in the last -ingester.max-chunk-idle duration, which defaults to 5 minutes.\n max_global_series_per_user / -ingester.max-global-series-per-user max_global_series_per_metric / -ingester.max-global-series-per-metric Like max_series_per_user and max_series_per_metric, but the limit is enforced across the cluster. Each ingester is configured with a local limit based on the replication factor, the -distributor.shard-by-all-labels setting and the current number of healthy ingesters, and is kept updated whenever the number of ingesters change.\nRequires -distributor.replication-factor and -distributor.shard-by-all-labels set for the ingesters too.\n max_series_per_query / -ingester.max-series-per-query max_samples_per_query / -ingester.max-samples-per-query Limits on the number of timeseries and samples returns by a single ingester during a query.\nStorage s3.force-path-style Set this to true to force the request to use path-style addressing (http://s3.amazonaws.com/BUCKET/KEY). By default, the S3 client will use virtual hosted bucket addressing when possible (http://BUCKET.s3.amazonaws.com/KEY).\nDNS Service Discovery Some clients in Cortex support service discovery via DNS to find addresses of backend servers to connect to (ie. caching servers). The clients supporting it are:\n Blocks storage\u0026rsquo;s memcached index cache All caching memcached servers Supported discovery modes The DNS service discovery, inspired from Thanos DNS SD, supports different discovery modes. A discovery mode is selected adding a specific prefix to the address. The supported prefixes are:\n dns+\nThe domain name after the prefix is looked up as an A/AAAA query. For example: dns+memcached.local:11211 dnssrv+\nThe domain name after the prefix is looked up as a SRV query, and then each SRV record is resolved as an A/AAAA record. For example: dnssrv+memcached.namespace.svc.cluster.local dnssrvnoa+\nThe domain name after the prefix is looked up as a SRV query, with no A/AAAA lookup made after that. For example: dnssrvnoa+memcached.namespace.svc.cluster.local ","excerpt":"General Notes Cortex has evolved over several years, and the command-line options sometimes reflect …","ref":"/docs/configuration/arguments/","title":"Cortex Arguments"},{"body":" Cortex adopts some design patterns and code conventions that we ask you to follow when contributing to the project. These conventions have been adopted based on the experience gained over the time and aim to enforce good coding practices and keep a consistent UX (ie. config).\nGo coding style Cortex follows the Go Code Review Comments styleguide and the Formatting and style section of Peter Bourgon\u0026rsquo;s Go: Best Practices for Production Environments.\nNo global variables Do not use global variables Prometheus metrics When registering a metric:\n Do not use a global variable for the metric Create and register the metric with promauto.With(reg) In any internal Cortex component, do not register the metric to the default prometheus registerer, but pick the registerer in input (ie. NewComponent(reg prometheus.Registerer)) Testing metrics:\n When writing using tests, test exported metrics using testutil.GatherAndCompare() Config file and CLI flags conventions Naming:\n Config file options should be lowercase with words _ (underscore) separated (ie. memcached_client) CLI flags should be lowercase with words - (dash) separated (ie. memcached-client) When adding a new config option, look if a similar one already exists within the config and keep the same naming (ie. addresses for a list of network endpoints) Documentation:\n A CLI flag mentioned in the documentation or changelog should be always prefixed with a single - (dash) ","excerpt":"Cortex adopts some design patterns and code conventions that we ask you to follow when contributing …","ref":"/docs/contributing/design-patterns-and-code-conventions/","title":"Design patterns and Code conventions"},{"body":" Cortex requires Key-Value (KV) store to store the ring. It can use traditional KV stores like Consul or Etcd, but it can also build its own KV store on top of memberlist library using a gossip algorithm.\nThis short guide shows how to start Cortex in single-binary mode with memberlist-based ring. To reduce number of required dependencies in this guide, it will use blocks storage with no shipping to external stores. Storage engine and external storage configuration are not dependant on the ring configuration.\nSingle-binary, two Cortex instances For simplicity and to get started, we\u0026rsquo;ll run it as a two instances of Cortex on local computer. We will use prepared configuration files (file 1, file 2), with no external dependencies.\nBuild Cortex first:\n$ go build ./cmd/cortex Run two instances of Cortex, each one with its own dedicated config file:\n$ ./cortex -config.file docs/configuration/single-process-config-blocks-gossip-1.yaml $ ./cortex -config.file docs/configuration/single-process-config-blocks-gossip-2.yaml Download Prometheus and configure it to use our first Cortex instance for remote writes.\nremote_write:-url:http://localhost:9109/api/prom/push After starting Prometheus, it will now start pushing data to Cortex. Distributor component in Cortex will distribute incoming samples between the two instances.\nTo query that data, you can configure your Grafana instance to use http://localhost:9109/api/prom (first Cortex) as a Prometheus data source.\nHow it works The two instances we started earlier should be able to find each other via memberlist configuration (already present in the config files):\nmemberlist:# defaults to hostnamenode_name:\u0026#34;Ingester 1\u0026#34;bind_port:7946join_members:-localhost:7947abort_if_cluster_join_fails:false This tells memberlist to listen on port 7946, and connect to localhost:7947, which is the second instance. Port numbers are reversed in the second configuration file. We also need to configure node_name and also ingester ID (ingester.lifecycler.id field), because default to hostname, but we are running both Cortex instances on the same host.\nTo make sure that both ingesters generate unique tokens, we configure join_after and observe_period to 10 seconds. First option tells Cortex to wait 10 seconds before joining the ring. This option is normally used to tell Cortex ingester how long to wait for a potential tokens and data transfer from leaving ingester, but we also use it here to increase the chance of finding other gossip peers. When Cortex joins the ring, it generates tokens and writes them to the ring. If multiple Cortex instances do this at the same time, they can generate conflicting tokens. This can be a problem when using gossiped ring (instances may simply not see each other yet), so we use observe_period to watch the ring for token conflicts. If conflict is detected, new tokens are generated instead of conflicting tokens, and observe period is restarted. If no conflict is detected within the observe period, ingester switches to ACTIVE state.\nWe are able to observe ring state on http://localhost:9109/ring and http://localhost:9209/ring. The two instances may see slightly different views (eg. different timestamps), but should converge to a common state soon, with both instances being ACTIVE and ready to receive samples.\nHow to add another instance? To add another Cortex to the small cluster, copy docs/configuration/single-process-config-blocks-gossip-1.yaml to a new file, and make following modifications. We assume that third Cortex will run on the same machine again, so we change node name and ingester ID as well. Here is annotated diff:\n... server: + # These ports need to be unique. - http_listen_port: 9109 - grpc_listen_port: 9195 + http_listen_port: 9309 + grpc_listen_port: 9395 ... ingester: lifecycler: # Defaults to hostname, but we run both ingesters in this demonstration on the same machine. - id: \u0026#34;Ingester 1\u0026#34; + id: \u0026#34;Ingester 3\u0026#34; ... memberlist: # defaults to hostname - node_name: \u0026#34;Ingester 1\u0026#34; + node_name: \u0026#34;Ingester 3\u0026#34; # bind_port needs to be unique - bind_port: 7946 + bind_port: 7948 ... +# Directory names in `tsdb` config ending with `...1` to end with `...3`. This is to avoid different instances +# writing in-progress data to the same directories. tsdb: - dir: /tmp/cortex/tsdb-ing1 + dir: /tmp/cortex/tsdb-ing3 bucket_store: - sync_dir: /tmp/cortex/tsdb-sync-querier1 + sync_dir: /tmp/cortex/tsdb-sync-querier3 ... We don\u0026rsquo;t need to change or add memberlist.join_members list. This new instance will simply join to the second one (listening on port 7947), and will discover other peers through it. When using kubernetes, suggested setup is to have a headless service pointing to all pods that want to be part of gossip cluster, and then point join_members to this headless service.\nWe also don\u0026rsquo;t need to change /tmp/cortex/storage directory in tsdb.filesystem.dir field. This is directory where all ingesters will \u0026ldquo;upload\u0026rdquo; finished blocks. This can also be an S3 or GCP storage, but for simplicity, we use local filesystem in this example.\nAfter these changes, we can start another Cortex instance using the modified configuration file. This instance will join the ring and will start receiving samples after it enters into ACTIVE state.\n","excerpt":"Cortex requires Key-Value (KV) store to store the ring. It can use traditional KV stores like Consul …","ref":"/docs/getting-started/getting-started-with-gossiped-ring/","title":"Getting Started with Gossiped Ring (experimental)"},{"body":"New maintainers are proposed by an existing maintainer and are elected by majority vote. Once the vote passed, the following steps should be done to add a new member to the maintainers team:\n Submit a PR to add the new member to MAINTAINERS Invite to GitHub organization Invite to cortex-team group Invite to Quay.io repository Invite to Docker Hub organization Invite to CNCF cncf-cortex-maintainers mailing list (via CNCF Service Desk) ","excerpt":"New maintainers are proposed by an existing maintainer and are elected by majority vote. Once the …","ref":"/docs/governance/how-to-add-a-maintainer/","title":"How to add a maintainer"},{"body":" The query auditor is a tool bundled in the Cortex repository, but not included in Docker images \u0026ndash; this must be built from source. It\u0026rsquo;s primarily useful for those developing Cortex, but can be helpful to operators as well during certain scenarios (backend migrations come to mind).\nHow it works The query-audit tool performs a set of queries against two backends that expose the Prometheus read API. This is generally the query-frontend component of two Cortex deployments. It will then compare the differences in the responses to determine the average difference for each query. It does this by:\n Ensuring the resulting label sets match. For each label set, ensuring they contain the same number of samples as their pair from the other backend. For each sample, calculates their difference against it\u0026rsquo;s pair from the other backend/label set. Calculates the average diff per query from the above diffs. Limitations It currently only supports queries with Matrix response types.\nUse cases Correctness testing when working on the read path. Comparing results from different backends. Example Configuration control:host:http://localhost:8080/api/promheaders:\u0026#34;X-Scope-OrgID\u0026#34;:1234test:host:http://localhost:8081/api/promheaders:\u0026#34;X-Scope-OrgID\u0026#34;:1234queries:-query:\u0026#39;sum(rate(container_cpu_usage_seconds_total[5m]))\u0026#39;start:2019-11-25T00:00:00Zend:2019-11-28T00:00:00Zstep_size:15m-query:\u0026#39;sum(rate(container_cpu_usage_seconds_total[5m])) by (container_name)\u0026#39;start:2019-11-25T00:00:00Zend:2019-11-28T00:00:00Zstep_size:15m-query:\u0026#39;sum(rate(container_cpu_usage_seconds_total[5m])) without (container_name)\u0026#39;start:2019-11-25T00:00:00Zend:2019-11-26T00:00:00Zstep_size:15m-query:\u0026#39;histogram_quantile(0.9, sum(rate(cortex_cache_value_size_bytes_bucket[5m])) by (le, job))\u0026#39;start:2019-11-25T00:00:00Zend:2019-11-25T06:00:00Zstep_size:15m# two shardable legs-query:\u0026#39;sum without (instance, job) (rate(cortex_query_frontend_queue_length[5m])) or sum by (job) (rate(cortex_query_frontend_queue_length[5m]))\u0026#39;start:2019-11-25T00:00:00Zend:2019-11-25T06:00:00Zstep_size:15m# one shardable leg-query:\u0026#39;sum without (instance, job) (rate(cortex_cache_request_duration_seconds_count[5m])) or rate(cortex_cache_request_duration_seconds_count[5m])\u0026#39;start:2019-11-25T00:00:00Zend:2019-11-25T06:00:00Zstep_size:15m Example Output Under ideal circumstances, you\u0026rsquo;ll see output like the following:\n$ go run ./tools/query-audit/ -f config.yaml 0.000000% avg diff for: query: sum(rate(container_cpu_usage_seconds_total[5m])) series: 1 samples: 289 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-28 00:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: sum(rate(container_cpu_usage_seconds_total[5m])) by (container_name) series: 95 samples: 25877 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-28 00:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: sum(rate(container_cpu_usage_seconds_total[5m])) without (container_name) series: 4308 samples: 374989 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-26 00:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: histogram_quantile(0.9, sum(rate(cortex_cache_value_size_bytes_bucket[5m])) by (le, job)) series: 13 samples: 325 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-25 06:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: sum without (instance, job) (rate(cortex_query_frontend_queue_length[5m])) or sum by (job) (rate(cortex_query_frontend_queue_length[5m])) series: 21 samples: 525 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-25 06:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: sum without (instance, job) (rate(cortex_cache_request_duration_seconds_count[5m])) or rate(cortex_cache_request_duration_seconds_count[5m]) series: 942 samples: 23550 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-25 06:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: sum by (namespace) (predict_linear(container_cpu_usage_seconds_total[5m], 10)) series: 16 samples: 400 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-25 06:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: sum by (namespace) (avg_over_time((rate(container_cpu_usage_seconds_total[5m]))[10m:]) \u0026gt; 1) series: 4 samples: 52 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-25 01:00:00 +0000 UTC step: 5m0s ","excerpt":"The query auditor is a tool bundled in the Cortex repository, but not included in Docker images …","ref":"/docs/operations/query-auditor/","title":"Query Auditor (tool)"},{"body":" [this is a work in progress]\nSee also the Running in Production document.\nCredentials You can supply credentials to Cortex by setting environment variables AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY (and AWS_SESSION_TOKEN if you use MFA), or use a short-term token solution such as kiam.\nShould I use S3 or DynamoDB ? Note that the choices are: \u0026ldquo;chunks\u0026rdquo; of timeseries data in S3 and index in DynamoDB, or everything in DynamoDB. Using just S3 is not an option.\nBroadly S3 is much more expensive to read and write, while DynamoDB is much more expensive to store over months. S3 charges differently, so the cross-over will depend on the size of your chunks, and how long you keep them. Very roughly: for 3KB chunks if you keep them longer than 8 months then S3 is cheaper.\nDynamoDB capacity provisioning By default, the Cortex Tablemanager will provision tables with 1,000 units of write capacity and 300 read - these numbers are chosen to be high enough that most trial installations won\u0026rsquo;t see a bottleneck on storage, but do note that that AWS will charge you approximately $60 per day for this capacity.\nTo match your costs to requirements, observe the actual capacity utilisation via CloudWatch or Prometheus metrics, then adjust the Tablemanager provision via command-line options -dynamodb.chunk-table.write-throughput, read-throughput and similar with .periodic-table which controls the index table.\nTablemanager can even adjust the capacity dynamically, by watching metrics for DynamoDB throttling and ingester queue length. Here is an example set of command-line parameters from a fairly modest install:\n -target=table-manager -metrics.url=http://prometheus.monitoring.svc.cluster.local./api/prom/ -metrics.target-queue-length=100000 -dynamodb.url=dynamodb://us-east-1/ -schema-config-file=/etc/schema.yaml -dynamodb.periodic-table.write-throughput=1000 -dynamodb.periodic-table.write-throughput.scale.enabled=true -dynamodb.periodic-table.write-throughput.scale.min-capacity=200 -dynamodb.periodic-table.write-throughput.scale.max-capacity=2000 -dynamodb.periodic-table.write-throughput.scale.out-cooldown=300 # 5 minutes between scale ups -dynamodb.periodic-table.inactive-enable-ondemand-throughput-mode=true -dynamodb.periodic-table.read-throughput=300 -dynamodb.chunk-table.write-throughput=800 -dynamodb.chunk-table.write-throughput.scale.enabled=true -dynamodb.chunk-table.write-throughput.scale.min-capacity=200 -dynamodb.chunk-table.write-throughput.scale.max-capacity=1000 -dynamodb.chunk-table.write-throughput.scale.out-cooldown=300 # 5 minutes between scale ups -dynamodb.chunk-table.inactive-enable-ondemand-throughput-mode=true -dynamodb.chunk-table.read-throughput=300 Several things to note here:\n -metrics.url points at a Prometheus server running within the cluster, scraping Cortex. Currently it is not possible to use Cortex itself as the target here. -metrics.target-queue-length: when the ingester queue is below this level, Tablemanager will not scale up. When the queue is growing above this level, Tablemanager will scale up whatever table is being throttled. The plain throughput values are used when the tables are first created. Scale-up to any level up to this value will be very quick, but if you go higher than this initial value, AWS may take tens of minutes to finish scaling. In the config above they are set. ondemand-throughput-mode tells AWS to charge for what you use, as opposed to continuous provisioning. This mode is cost-effective for older data, which is never written and only read sporadically. If you want to add AWS tags to the created DynamoDB tables you can do it by adding a tags map to your schema definition. See schema configuration ","excerpt":"[this is a work in progress]\nSee also the Running in Production document.\nCredentials You can supply …","ref":"/docs/production/aws/","title":"Running Cortex with AWS Services"},{"body":" The Cortex documentation is compiled into a website published at cortexmetrics.io. These instructions explain how to run the website locally, in order to have a quick feedback loop while contributing to the documentation or website styling.\nInitial setup The following initial setup is required only once:\n Install Hugo v0.59.1 Install Node.js v12 or above (alternatively via nvm) Install required Node modules with:\ncd website \u0026amp;\u0026amp; npm install postcss-cli autoprefixer \u0026amp;\u0026amp; cd - Run make BUILD_IN_CONTAINER=false web-build\n Run it Once the initial setup is completed, you can run the website with the following command. The local website will run at http://localhost:1313/\n# Keep this running make web-serve Whenever you change the content of docs/ or markdown files in the repository root / you should run:\nmake BUILD_IN_CONTAINER=false web-pre Whenever you change the config file or CLI flags in the Cortex code, you should rebuild the config file reference documentation:\nmake BUILD_IN_CONTAINER=false doc web-pre","excerpt":"The Cortex documentation is compiled into a website published at cortexmetrics.io. These …","ref":"/docs/contributing/how-to-run-the-website-locally/","title":"How to run the website locally"},{"body":"","excerpt":"","ref":"/docs/production/","title":"Production"},{"body":"You can use the Cortex query frontend with any Prometheus-API compatible service, including Prometheus and Thanos. Use this config file to get the benefits of query parallelisation and caching.\n# Disable the requirement that every request to Cortex has a# X-Scope-OrgID header. `fake` will be substituted in instead.auth_enabled:false# We only want to run the query-frontend module.target:query-frontend# We don\u0026#39;t want the usual /api/prom prefix.http_prefix:server:http_listen_port:9091query_range:split_queries_by_interval:24halign_queries_with_step:truecache_results:trueresults_cache:max_freshness:1mcache:# We\u0026#39;re going to use the in-process \u0026#34;FIFO\u0026#34; cache, but you can enable# memcached below.enable_fifocache:truefifocache:size:1024validity:24h# If you want to use a memcached cluster, you can either configure a# headless service in Kubernetes and Cortex will discover the individual# instances using a SRV DNS query (host) or list comma separated# memcached addresses.# host + service: this is the config you should set when you use the# SRV DNS (this is considered stable)# addresses: this is experimental and supports service discovery# (https://cortexmetrics.io/docs/configuration/arguments/#dns-service-discovery)# so it could either be a list of single addresses, or a SRV record# prefixed with dnssrvnoa+. Cortex will then do client-side hashing to# spread the load evenly.# memcached:# expiration : 24h# memcached_client:# host: memcached.default.svc.cluster.local# service: memcached# addresses: \u0026#34;\u0026#34;# consistent_hash: truefrontend:log_queries_longer_than:1scompress_responses:true# The Prometheus URL to which the query-frontend should connect to.downstream_url:http://prometheus.mydomain.com","excerpt":"You can use the Cortex query frontend with any Prometheus-API compatible service, including …","ref":"/docs/configuration/prometheus-frontend/","title":"Prometheus Frontend"},{"body":" The query-tee is a standalone service which can be used for testing purposes to compare the query performances of 2+ backend systems (ie. Cortex clusters) ingesting the same exact series.\nThis service exposes Prometheus-compatible read API endpoints and, for each received request, performs the request against all backends tracking the response time of each backend and then sends back to the client one of the received responses.\nHow to run it You can run query-tee in two ways:\n Build it from sources\ngo run ./cmd/query-tee -help Run it via the provided Docker image\ndocker run quay.io/cortexproject/query-tee -help The service requires at least 1 backend endpoint (but 2 are required in order to compare performances) configured as comma-separated HTTP(S) URLs via the CLI flag -backend.endpoints. For each incoming request, query-tee will clone the request and send it to each backend, tracking performance metrics for each backend before sending back the response to the client.\nHow it works API endpoints The following Prometheus API endpoints are supported by query-tee:\n /api/v1/query (GET) /api/v1/query_range (GET) /api/v1/labels (GET) /api/v1/label/{name}/values (GET) /api/v1/series (GET) Authentication query-tee supports HTTP basic authentication. It allows either to configure username and password in the backend URL, to forward the request auth to the backend or merge the two.\nThe request sent from the query-tee to the backend includes HTTP basic authentication when one of the following conditions are met:\n If the endpoint URL has username and password, query-tee uses it. If the endpoint URL has username only, query-tee keeps the username and inject the password received in the incoming request (if any). If the endpoint URL has no username and no password, query-tee forwards the incoming request basic authentication (if any). Backend response selection query-tee allows to configure a preferred backend from which picking the response to send back to the client. The preferred backend can be configured via the CLI flag -backend.preferred=\u0026lt;hostname\u0026gt;, setting it to the hostname of the preferred backend.\nWhen a preferred backend is set, query-tee sends back to the client:\n The preferred backend response if the status code is 2xx or 4xx Otherwise, the first received 2xx or 4xx response if at least a backend succeeded Otherwise, the first received response When a preferred backend is not set, query-tee sends back to the client:\n The first received 2xx or 4xx response if at least a backend succeeded Otherwise, the first received response Note: from the query-tee perspective, a backend request is considered successful even if the status code is 4xx because it generally means the error is due to an invalid request and not to a backend issue.\nExported metrics query-tee exposes the following Prometheus metrics on the port configured via the CLI flag -server.metrics-port:\n# HELP cortex_querytee_request_duration_seconds Time (in seconds) spent serving HTTP requests. # TYPE cortex_querytee_request_duration_seconds histogram cortex_querytee_request_duration_seconds_bucket{backend=\u0026#34;\u0026lt;hostname\u0026gt;\u0026#34;,method=\u0026#34;\u0026lt;method\u0026gt;\u0026#34;,route=\u0026#34;\u0026lt;route\u0026gt;\u0026#34;,status_code=\u0026#34;\u0026lt;status\u0026gt;\u0026#34;,le=\u0026#34;\u0026lt;bucket\u0026gt;\u0026#34;} cortex_querytee_request_duration_seconds_sum{backend=\u0026#34;\u0026lt;hostname\u0026gt;\u0026#34;,method=\u0026#34;\u0026lt;method\u0026gt;\u0026#34;,route=\u0026#34;\u0026lt;route\u0026gt;\u0026#34;,status_code=\u0026#34;\u0026lt;status\u0026gt;\u0026#34;} cortex_querytee_request_duration_seconds_count{backend=\u0026#34;\u0026lt;hostname\u0026gt;\u0026#34;,method=\u0026#34;\u0026lt;method\u0026gt;\u0026#34;,route=\u0026#34;\u0026lt;route\u0026gt;\u0026#34;,status_code=\u0026#34;\u0026lt;status\u0026gt;\u0026#34;}","excerpt":"The query-tee is a standalone service which can be used for testing purposes to compare the query …","ref":"/docs/operations/query-tee/","title":"Query Tee (service)"},{"body":" Context One option to scale the ruler is by scaling it horizontally. However, with multiple ruler instances running they will need to coordinate to determine which instance will evaluate which rule. Similar to the ingesters, the rulers establish a hash ring to divide up the responsibilities of evaluating rules.\nConfig In order to enable sharding in the ruler the following flag needs to be set:\n -ruler.enable-sharding=true In addition the ruler requires it\u0026rsquo;s own ring to be configured, for instance:\n -ruler.ring.consul.hostname=consul.dev.svc.cluster.local:8500 The only configuration that is required is to enable sharding and configure a key value store. From there the rulers will shard and handle the division of rules automatically.\nUnlike ingesters, rulers do not hand over responsibility: all rules are re-sharded randomly every time a ruler is added to or removed from the ring.\n","excerpt":"Context One option to scale the ruler is by scaling it horizontally. However, with multiple ruler …","ref":"/docs/guides/ruler-sharding/","title":"Config for horizontally scaling the Ruler"},{"body":"To upgrade the Golang version:\n Upgrade build image version Upgrade Golang version in build-image/Dockerfile Build new image make build-image/.uptodate Publish the new image to quay.io (requires a maintainer) Update the Docker image tag in .circleci/config.yml Upgrade integration tests version Update the Golang version installed in the integration job in .circleci/config.yml If the minimum support Golang version should be upgraded as well:\n Upgrade go version in go.mod ","excerpt":"To upgrade the Golang version:\n Upgrade build image version Upgrade Golang version in …","ref":"/docs/contributing/how-to-upgrade-golang-version/","title":"How to upgrade Golang version"},{"body":" Requests mirroring (or shadowing) is a technique you can use to mirror requests from a primary Cortex cluster to a secondary one.\nFor example, requests mirroring can be used when you need to setup a testing Cortex cluster receiving the same series ingested by a primary one without having control over Prometheus remote write config (if you do, then configuring two remote write entries in Prometheus would be the preferred option).\nMirroring with Envoy proxy Envoy proxy can be used to mirror HTTP requests to a secondary upstream cluster. From a network path perspective, you should run Envoy in front of both clusters distributors, letting Envoy to proxy requests to the primary Cortex cluster and mirror them to a secondary cluster in background. The performances and availability of the secondary cluster have no impact on the requests to the primary one. The response to the client will always be the one from the primary one. In this sense, the requests from Envoy to the secondary cluster are \u0026ldquo;fire and forget\u0026rdquo;.\nExample Envoy config The following Envoy configuration shows an example with two Cortex clusters. Envoy will listen on port 9900 and will proxies all requests to cortex-primary:80, mirroring it to cortex-secondary:80 too.\nadmin:# No access logs.access_log_path:/dev/nulladdress:socket_address:{address:0.0.0.0,port_value:9901}static_resources:listeners:-name:cortex_listeneraddress:socket_address:{address:0.0.0.0,port_value:9900}filter_chains:-filters:-name:envoy.http_connection_managerconfig:stat_prefix:cortex_ingressroute_config:name:all_routesvirtual_hosts:-name:all_hostsdomains:[\u0026#34;*\u0026#34;]routes:-match:{prefix:\u0026#34;/\u0026#34;}route:cluster:cortex_primary# Specifies the upstream timeout. This spans between the point at which the entire downstream# request has been processed and when the upstream response has been completely processed.timeout:15s# Specifies the cluster that requests will be mirrored to. The performances and availability of# the secondary cluster have no impact on the requests to the primary one. The response to the# client will always be the one from the primary one. The requests from Envoy to the secondary# cluster are \u0026#34;fire and forget\u0026#34;.request_mirror_policies:-cluster:cortex_secondaryhttp_filters:-name:envoy.routerclusters:-name:cortex_primarytype:STRICT_DNSconnect_timeout:1shosts:[{socket_address:{address:cortex-primary,port_value:80}}]dns_refresh_rate:5s-name:cortex_secondarytype:STRICT_DNSconnect_timeout:1shosts:[{socket_address:{address:cortex-secondary,port_value:80}}]dns_refresh_rate:5s","excerpt":"Requests mirroring (or shadowing) is a technique you can use to mirror requests from a primary …","ref":"/docs/operations/requests-mirroring-to-secondary-cluster/","title":"Requests mirroring to secondary cluster"},{"body":" This guide covers how to run a single local Cortex instance - with the chunks storage engine - storing time series chunks and index in Cassandra.\nIn this guide we\u0026rsquo;re going to:\n Setup a locally running Cassandra Configure Cortex to store chunks and index on Cassandra Configure Prometheus to send series to Cortex Configure Grafana to visualise metrics Setup a locally running Cassandra Run Cassandra with the following command:\ndocker run -d --name cassandra --rm -p 9042:9042 cassandra:3.11 Use Docker to execute the Cassandra Query Language (CQL) shell in the container:\ndocker exec -it \u0026lt;container_id\u0026gt; cqlsh Create a new Cassandra keyspace for Cortex metrics:\nA keyspace is an object that is used to hold column families, user defined types. A keyspace is like RDBMS database which contains column families, indexes, user defined types.\nCREATE KEYSPACE cortex WITH replication = {'class':'SimpleStrategy', 'replication_factor' : 1}; Configure Cortex to store chunks and index on Cassandra Now, we have to configure Cortex to store the chunks and index in Cassandra. Create a config file called single-process-config.yaml, then add the content below. Make sure to replace the following placeholders: - LOCALHOST: Addresses of your Cassandra instance. This can accept multiple addresses by passing them as comma separated values. - KEYSPACE: The name of the Cassandra keyspace used to store the metrics.\nsingle-process-config.yaml\n# Configuration for running Cortex in single-process mode. # This should not be used in production. It is only for getting started # and development. # Disable the requirement that every request to Cortex has a # X-Scope-OrgID header. `fake` will be substituted in instead. auth_enabled: false server: http_listen_port: 9009 # Configure the server to allow messages up to 100MB. grpc_server_max_recv_msg_size: 104857600 grpc_server_max_send_msg_size: 104857600 grpc_server_max_concurrent_streams: 1000 distributor: shard_by_all_labels: true pool: health_check_ingesters: true ingester_client: grpc_client_config: # Configure the client to allow messages up to 100MB. max_recv_msg_size: 104857600 max_send_msg_size: 104857600 use_gzip_compression: true ingester: lifecycler: # The address to advertise for this ingester. Will be autodiscovered by # looking up address on eth0 or en0; can be specified if this fails. address: 127.0.0.1 # We want to start immediately and flush on shutdown. join_after: 0 final_sleep: 0s num_tokens: 512 # Use an in memory ring store, so we don't need to launch a Consul. ring: kvstore: store: inmemory replication_factor: 1 # Use cassandra as storage -for both index store and chunks store. schema: configs: - from: 2019-07-29 store: cassandra object_store: cassandra schema: v10 index: prefix: index_ period: 168h chunks: prefix: chunk_ period: 168h storage: cassandra: addresses: LOCALHOST # configure cassandra addresses here. keyspace: KEYSPACE # configure desired keyspace here. The latest tag is not published for the Cortex docker image. Visit quay.io/repository/cortexproject/cortex to find the latest stable version tag and use it in the command bellow (currently it is v1.0.0).\nRun Cortex using the latest stable version:\ndocker run -d --name=cortex -v $(pwd)/single-process-config.yaml:/etc/single-process-config.yaml -p 9009:9009 quay.io/cortexproject/cortex:v1.0.0 -config.file=/etc/single-process-config.yaml In case you prefer to run the master version, please follow this documentation on how to build Cortex from source.\nConfigure Prometheus to send series to Cortex Now that Cortex is up, it should be running on http://localhost:9009.\nAdd the following section to your Prometheus configuration file. This will configure the remote write to send metrics to Cortex.\nremote_write: - url: http://localhost:9009/api/prom/push Configure Grafana to visualise metrics Run grafana to visualise metrics from Cortex:\ndocker run -d --name=grafana -p 3000:3000 grafana/grafana Add a data source in Grafana by selecting Prometheus as the data source type and use the Cortex URL to query metrics: http://localhost:9009/api/prom.\nFinally, You can monitor Cortex\u0026rsquo;s reads \u0026amp; writes by creating the dashboard. You can follow this documentation to do so.\n","excerpt":"This guide covers how to run a single local Cortex instance - with the chunks storage engine - …","ref":"/docs/production/cassandra/","title":"Running Cortex with Cassandra"},{"body":" Cortex uses a NoSQL Store to store its index and optionally an Object store to store its chunks. Cortex has overtime evolved its schema to be more optimal and better fit the use cases and query patterns that arose.\nCurrently there are 9 schemas that are used in production but we recommend running with v9 schema when possible. You can move from one schema to another if a new schema fits your purpose better, but you still need to configure Cortex to make sure it can read the old data in the old schemas.\nYou can configure the schemas using a YAML config file, that you can point to using the -schema-config-file flag. It has the following YAML spec:\nconfigs:[]\u0026lt;period_config\u0026gt; Where period_config is\n# In YYYY-MM-DD format, for example: 2020-03-01. from: \u0026lt;string\u0026gt; # The index client to use, valid options: aws-dynamo, bigtable, bigtable-hashed, cassandra, boltdb. store: \u0026lt;string\u0026gt; # The object client to use. If none is specified, `store` is used for storing chunks as well. Valid options: s3, aws-dynamo, bigtable, bigtable-hashed, gcs, cassandra, filesystem. object_store: \u0026lt;string\u0026gt; # The schema version to use. Valid ones are v1, v2, v3,... v6, v9, v10, v11. Recommended for production: v9. schema: \u0026lt;string\u0026gt; index: \u0026lt;periodic_table_config\u0026gt; chunks: \u0026lt;periodic_table_config\u0026gt; Where periodic_table_config is\n# The prefix to use for the tables. prefix: \u0026lt;string\u0026gt; # We typically run Cortex with new tables every week to keep the index size low and to make retention easier. This sets the period at which new tables are created and used. Typically 1w (1week). period: \u0026lt;duration\u0026gt; # The tags that can be set on the dynamo table. tags: \u0026lt;map[string]string\u0026gt; Now an example of this file (also something recommended when starting out) is:\nconfigs: - from: \u0026quot;2020-03-01\u0026quot; # Or typically a week before the Cortex cluster was created. schema: v9 index: period: 1w prefix: cortex_index_ # Chunks section is optional and required only if you're not using a # separate object store. chunks: period: 1w prefix: cortex_chunks store: aws-dynamo/bigtable-hashed/cassandra/boltdb object_store: \u0026lt;above options\u0026gt;/s3/gcs/azure/filesystem An example of an advanced schema file with a lot of changes:\nconfigs: # Starting from 2018-08-23 Cortex should store chunks and indexes # on Google BigTable using weekly periodic tables. The chunks table # names will be prefixed with \u0026quot;dev_chunks_\u0026quot;, while index tables will be # prefixed with \u0026quot;dev_index_\u0026quot;. - from: \u0026quot;2018-08-23\u0026quot; schema: v9 chunks: period: 1w prefix: dev_chunks_ index: period: 1w prefix: dev_index_ store: gcp-columnkey # Starting 2018-02-13 we moved from BigTable to GCS for storing the chunks. - from: \u0026quot;2019-02-13\u0026quot; schema: v9 chunks: period: 1w prefix: dev_chunks_ index: period: 1w prefix: dev_index_ object_store: gcs store: gcp-columnkey # Starting 2019-02-24 we moved our index from bigtable-columnkey to bigtable-hashed # which improves the distribution of keys. - from: \u0026quot;2019-02-24\u0026quot; schema: v9 chunks: period: 1w prefix: dev_chunks_ index: period: 1w prefix: dev_index_ object_store: gcs store: bigtable-hashed # Starting 2019-03-05 we moved from v9 schema to v10 schema. - from: \u0026quot;2019-03-05\u0026quot; schema: v10 chunks: period: 1w prefix: dev_chunks_ index: period: 1w prefix: dev_index_ object_store: gcs store: bigtable-hashed Note how we started out with v9 and just Bigtable, but later migrated to GCS as the object store, finally moving to v10. This is a complex schema file showing several changes changes over the time, while a typical schema config file usually has just one or two schema versions.\nMigrating from flags to schema file Legacy versions of Cortex did support the ability to configure schema via flags. If you are still using flags, you need to migrate your configuration from flags to the config file.\nIf you\u0026rsquo;re using:\n chunk.storage-client: then set the corresponding object_store field correctly in the schema file. dynamodb.daily-buckets-from: then set the corresponding from date with v2 schema. dynamodb.base64-buckets-from: then set the corresponding from date with v3 schema. dynamodb.v{4,5,6,9}-schema-from: then set the corresponding from date with schema v{4,5,6,9} bigtable.column-key-from: then set the corresponding from date and use the store as bigtable-columnkey. dynamodb.use-periodic-tables: then set the right index and chunk fields with corresponding values from dynamodb.periodic-table.{prefix, period, tag} and dynamodb.chunk-table.{prefix, period, tag} flags. Note that the default period is 7 days, so please set the period as 168h in the config file if none is set in the flags. ","excerpt":"Cortex uses a NoSQL Store to store its index and optionally an Object store to store its chunks. …","ref":"/docs/configuration/schema-configuration/","title":"Schema Configuration"},{"body":" Correctly configured caching is important for a production-ready Cortex cluster. Cortex has many opportunities for using caching to accelerate queries and reduce cost. Cortex can use a cache for:\n The results of a whole query And for the chunk storage:\n Individual chunks Index lookups for one label on one day Reducing duplication of writes. This doc aims to describe what each cache does, how to configure them and how to tune them.\nCortex Caching Options Cortex can use various different technologies for caching - Memcached, Redis or an in-process FIFO cache. The recommended caching technology for production workloads is Memcached. Using Memcached in your Cortex install means results from one process can be re-used by another. In-process caching can cut fetch times slightly and reduce the load on Memcached, but can only be used by a single process.\nIf multiple caches are enabled for each caching opportunities, they will be tiered – writes will go to all caches, but reads will first go to the in-memory FIFO cache, then memcached, then redis.\nMemcached For small deployments you can use a single memcached cluster for all the caching opportunities – the keys do not collide.\nFor large deployments we recommend separate memcached deployments for each of the caching opportunities, as this allows more sophisticated sizing, monitoring and configuration of each cache. For help provisioning and monitoring memcached clusters using tanka, see the memcached jsonnet module and the memcached-mixin.\nCortex uses DNS SRV records to find the various memcached servers in a cluster. You should ensure your memcached servers are not behind any kind of load balancer. If deploying Cortex on Kubernetes, Cortex should be pointed at a memcached headless service.\nThe flags used to configure memcached are common for each caching caching opportunity, differentiated by a prefix:\n-\u0026lt;prefix\u0026gt;.cache.write-back-buffer int How many chunks to buffer for background write back. (default 10000) -\u0026lt;prefix\u0026gt;.cache.write-back-goroutines int How many goroutines to use to write back to memcache. (default 10) -\u0026lt;prefix\u0026gt;.memcached.batchsize int How many keys to fetch in each batch. -\u0026lt;prefix\u0026gt;.memcached.consistent-hash Use consistent hashing to distribute to memcache servers. -\u0026lt;prefix\u0026gt;.memcached.expiration duration How long keys stay in the memcache. -\u0026lt;prefix\u0026gt;.memcached.hostname string Hostname for memcached service to use when caching chunks. If empty, no memcached will be used. -\u0026lt;prefix\u0026gt;.memcached.max-idle-conns int Maximum number of idle connections in pool. (default 16) -\u0026lt;prefix\u0026gt;.memcached.parallelism int Maximum active requests to memcache. (default 100) -\u0026lt;prefix\u0026gt;.memcached.service string SRV service used to discover memcache servers. (default \u0026quot;memcached\u0026quot;) -\u0026lt;prefix\u0026gt;.memcached.timeout duration Maximum time to wait before giving up on memcached requests. (default 100ms) -\u0026lt;prefix\u0026gt;.memcached.update-interval duration Period with which to poll DNS for memcache servers. (default 1m0s) See the memcached_config and memcached_client_config documentation if you use a config file with Cortex.\nFIFO Cache (Experimental) The FIFO cache is an in-memory, in-process (non-shared) cache that uses a First-In-First-Out (FIFO) eviction strategy. The FIFO cache is useful for simple scenarios where deploying an additional memcached server is too much work, such as when experimenting with the Query Frontend. The FIFO cache can also be used in front of Memcached to reduce latency for commonly accessed keys. The FIFO cache stores a fixed number of entries, and therefore it’s memory usage depends on the caches value’s size.\nTo enable the FIFO cache, use the following flags:\n-\u0026lt;prefix\u0026gt;.cache.enable-fifocache Enable in-memory cache. -\u0026lt;prefix\u0026gt;.fifocache.duration duration The expiry duration for the cache. -\u0026lt;prefix\u0026gt;.fifocache.max-size-bytes int Maximum memory size of the cache. -\u0026lt;prefix\u0026gt;.fifocache.max-size-items int Maximum number of entries in the cache. See fifo_cache_config documentation if you use a config file with Cortex.\nRedis (Experimental) You can also use Redis for out-of-process caching; this is a relatively new addition to Cortex and is under active development.\n-\u0026lt;prefix\u0026gt;.redis.enable-tls Enables connecting to redis with TLS. -\u0026lt;prefix\u0026gt;.redis.endpoint string Redis service endpoint to use when caching chunks. If empty, no redis will be used. -\u0026lt;prefix\u0026gt;.redis.expiration duration How long keys stay in the redis. -\u0026lt;prefix\u0026gt;.redis.max-active-conns int Maximum number of active connections in pool. -\u0026lt;prefix\u0026gt;.redis.max-idle-conns int Maximum number of idle connections in pool. (default 80) -\u0026lt;prefix\u0026gt;.redis.password value Password to use when connecting to redis. -\u0026lt;prefix\u0026gt;.redis.timeout duration Maximum time to wait before giving up on redis requests. (default 100ms) See redis_config documentation if you use a config file with Cortex.\nCortex Caching Opportunities Chunks Cache The chunk cache stores immutable compressed chunks. The cache is used by queries to reduce load on the chunk store. These are typically a few KB in size, and depend mostly on the duration and encoding of your chunks. The chunk cache is a write-through cache - chunks are written to the cache as they are flushed to the chunk store. This ensures the cache always contains the most recent chunks. Items stay in the cache indefinitely.\nThe chunk cache should be configured on the ingester, querier and ruler using the flags with the prefix -store.chunks-cache.\nIt is best practice to ensure the chunk cache is big enough to accommodate at least 24 hours of chunk data. You can use the following query (from the cortex-mixin) to estimate the required number of memcached replicas:\n// 4 x in-memory series size = 24hrs of data. ( 4 * sum by(cluster, namespace) ( cortex_ingester_memory_series{job=~\u0026#34;.+/ingester\u0026#34;} * cortex_ingester_chunk_size_bytes_sum{job=~\u0026#34;.+/ingester\u0026#34;} / cortex_ingester_chunk_size_bytes_count{job=~\u0026#34;.+/ingester\u0026#34;} ) / 1e9 ) \u0026gt; ( sum by (cluster, namespace) (memcached_limit_bytes{job=~\u0026#34;.+/memcached\u0026#34;}) / 1e9 ) Index Read Cache The index read cache stores entire rows from the inverted label index. The cache is used by queries to reduce load on the index. These are typically only a few KB in size, but can grow up to many MB for very high cardinality metrics. The index read cache is populated when there is a cache miss.\nThe index read cache should be configured on the querier and ruler, using the flags with the -store.index-cache-read prefix.\nQuery Results Cache The query results cache contains protobuf \u0026amp; snappy encoded query results. These query results can potentially be very large, and as such the maximum value size in memcached should be increased beyond the default 1M. The cache is populated when there is a cache miss. Items stay in the cache indefinitely.\nThe query results cache should be configured on the query-frontend using flags with -frontend prefix:\n -frontend.memcached.* flags to use Memcached backend -frontend.redis.* flags to use Redis backend -frontend.fifocache.* and -frontend.cache.enable-fifocache flags to use the per-process in-memory cache (not shared across multiple query-frontend instances) Please keep in mind to also enable -querier.cache-results=true and configure -querier.split-queries-by-interval=24h (24h is a good starting point).\nIndex Write Cache The index write cache is used to avoid re-writing index and chunk data which has already been stored in the back-end database, aka “deduplication”. This can reduce write load on your backend-database by around 12x.\nYou should not use in-process caching for the index write cache - most of the deduplication comes from replication between ingesters.\nThe index write cache contains row and column keys written to the index. If an entry is in the index write cache it will not be written to the index. As such, entries are only written to the index write cache after being successfully written to the index. Data stays in the index indefinitely or until it is evicted by newer entries.\nThe index write cache should be configures on the ingesters using flags with the -store.index-cache-write prefix.\n","excerpt":"Correctly configured caching is important for a production-ready Cortex cluster. Cortex has many …","ref":"/docs/production/caching/","title":"Caching in Cortex"},{"body":" [this is a work in progress]\nRemote API Cortex supports Prometheus\u0026rsquo; remote_read and remote_write APIs.\nThe API for writes accepts a HTTP POST request with a body containing a request encoded with Protocol Buffers and compressed with Snappy. The HTTP path for writes is /api/prom/push. The definition of the protobuf message can be found in the Cortex codebase or in the Prometheus codebase. The HTTP request should contain the header X-Prometheus-Remote-Write-Version set to 0.1.0.\nThe API for reads also accepts HTTP/protobuf/snappy, and the path is /api/prom/read.\nSee the Prometheus documentation for more information on the Prometheus remote write format.\nRuler Prometheus Endpoints Cortex supports the Prometheus\u0026rsquo; alerts and rules api endpoints. This is supported in the Ruler service and can be enabled using the experimental.ruler.enable-api flag.\nGET /api/prom/api/v1/rules - List of alerting and recording rules that are currently loaded\nGET /api/prom/api/v1/alerts - List of all active alerts\nExperimental API The ruler supports operations using a configured object storage client as a backend for the storage and management of user rule groups. In order to use this API the experimental.ruler.enable-api must be set and a valid object storage backend must be configured for the ruler. The ruler API uses the concept of a namespace when creating rule groups. This is a stand in for the name of the rule file in Prometheus and rule groups must be named uniquely within a namespace.\nList Rule Groups Path: /api/v1/rules(/{namespace}) namespace path segment is optional\nMethod: GET\nSuccess Response Code: 200 OK\nData:\n---\u0026lt;namespace1\u0026gt;:-name:\u0026lt;string\u0026gt; interval: \u0026lt;duration;optional\u0026gt;rules:-record:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;-alert:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;for:\u0026lt;duration\u0026gt; annotations:\u0026lt;annotation_name\u0026gt;:\u0026lt;string\u0026gt; labels:\u0026lt;label_name\u0026gt;:\u0026lt;string\u0026gt;-name:\u0026lt;string\u0026gt; interval: \u0026lt;duration;optional\u0026gt;rules:-record:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;-alert:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;for:\u0026lt;duration\u0026gt; annotations:\u0026lt;annotation_name\u0026gt;:\u0026lt;string\u0026gt; labels:\u0026lt;label_name\u0026gt;:\u0026lt;string\u0026gt;\u0026lt;namespace2\u0026gt;:-name:\u0026lt;string\u0026gt; interval: \u0026lt;duration;optional\u0026gt;rules:-record:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;-alert:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;for:\u0026lt;duration\u0026gt; annotations:\u0026lt;annotation_name\u0026gt;:\u0026lt;string\u0026gt; labels:\u0026lt;label_name\u0026gt;:\u0026lt;string\u0026gt; The success response for the list operation returns a yaml dictionary with all of the rule groups for each rule namespace.\nGet Rule Group Path: `/api/v1/rules/{namespace}/{group_name}\nMethod: GET\nSuccess Response Code: 200 OK\nData:\nname:\u0026lt;string\u0026gt;interval:\u0026lt;duration;optional\u0026gt;rules:-record:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;-alert:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;for:\u0026lt;duration\u0026gt; annotations:\u0026lt;annotation_name\u0026gt;:\u0026lt;string\u0026gt; labels:\u0026lt;label_name\u0026gt;:\u0026lt;string\u0026gt; Set Rule Group Path: `/api/v1/rules/{namespace}\nMethod: POST\nContent-Type: application/yaml\nBody:\nname:\u0026lt;string\u0026gt;interval:\u0026lt;duration;optional\u0026gt;rules:-record:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;-alert:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;for:\u0026lt;duration\u0026gt; annotations:\u0026lt;annotation_name\u0026gt;:\u0026lt;string\u0026gt; labels:\u0026lt;label_name\u0026gt;:\u0026lt;string\u0026gt; Success Response Code: 202 ACCEPTED\nBody: None\nDelete Rule Group Path: /api/v1/rules/{namespace}/{group_name}\nMethod: DELETE\nSuccess Response Code: 202 ACCEPTED\nBody: None\nConfigs API The configs service provides an API-driven multi-tenant approach to handling various configuration files for prometheus. The service hosts an API where users can read and write Prometheus rule files, Alertmanager configuration files, and Alertmanager templates to a database.\nEach tenant will have it\u0026rsquo;s own set of rule files, Alertmanager config, and templates. A POST operation will effectively replace the existing copy with the configs provided in the request body.\nConfigs Format At the current time of writing, the API is part-way through a migration from a single Configs service that handled all three sets of data to a split API (Tracking issue). All APIs take and return all sets of data.\nThe following schema is used both when retrieving the current configs from the API and when setting new configs via the API.\nSchema: { \u0026#34;id\u0026#34;: 99, \u0026#34;rule_format_version\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;alertmanager_config\u0026#34;: \u0026#34;\u0026lt;standard alertmanager.yaml config\u0026gt;\u0026#34;, \u0026#34;rules_files\u0026#34;: { \u0026#34;rules.yaml\u0026#34;: \u0026#34;\u0026lt;standard rules.yaml config\u0026gt;\u0026#34;, \u0026#34;rules2.yaml\u0026#34;: \u0026#34;\u0026lt;standard rules.yaml config\u0026gt;\u0026#34; }, \u0026#34;template_files\u0026#34;: { \u0026#34;templates.tmpl\u0026#34;: \u0026#34;\u0026lt;standard template file\u0026gt;\u0026#34;, \u0026#34;templates2.tmpl\u0026#34;: \u0026#34;\u0026lt;standard template file\u0026gt;\u0026#34; } } Formatting id - should be incremented every time data is updated; Cortex will use the config with the highest number.\nrule_format_version - allows compatibility for tenants with config in Prometheus V1 format. Pass \u0026ldquo;1\u0026rdquo; or \u0026ldquo;2\u0026rdquo; according to which Prometheus version you want to match.\nconfig.alertmanager_config - The contents of the alertmanager config file should be as described here, encoded as a single string to fit within the overall JSON payload.\nconfig.rules_files - The contents of a rules file should be as described here, encoded as a single string to fit within the overall JSON payload.\nconfig.template_files - The contents of a template file should be as described here, encoded as a single string to fit within the overall JSON payload.\nEndpoints Manage Alertmanager GET /api/prom/configs/alertmanager - Get current Alertmanager config\n Normal Response Codes: OK(200) Error Response Codes: Unauthorized(401), NotFound(404) POST /api/prom/configs/alertmanager - Replace current Alertmanager config\n Normal Response Codes: NoContent(204) Error Response Codes: Unauthorized(401), BadRequest(400) The POST request body is expected to be like the following example:\n{ \u0026#34;rule_format_version\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;alertmanager_config\u0026#34;: \u0026#34;global:\\n resolve_timeout: 10s\\nroute: \\n receiver: webhook\\nreceivers:\\n - name: webhook\\n webhook_configs: \\n - url: http://example.com\u0026#34;, \u0026#34;rules_files\u0026#34;: { \u0026#34;rules.yaml\u0026#34;: \u0026#34;groups:\\n- name: demo-service-alerts\\n interval: 1s\\n rules:\\n - alert: SomethingIsUp\\n expr: up == 1\\n\u0026#34; } } POST /api/prom/configs/alertmanager/validate - Validate Alertmanager config\nNormal Response: OK(200)\n{ \u0026#34;status\u0026#34;: \u0026#34;success\u0026#34; } Error Response: BadRequest(400)\n{ \u0026#34;status\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;error message\u0026#34; } Manage Rules GET /api/prom/configs/rules - Get current rule files\n Normal Response Codes: OK(200) Error Response Codes: Unauthorized(400), NotFound(404) POST /api/prom/configs/rules - Replace current rule files\n Normal Response Codes: NoContent(204) Error Response Codes: Unauthorized(401), BadRequest(400) Manage Templates GET /api/prom/configs/templates - Get current templates\n Normal Response Codes: OK(200) Error Response Codes: Unauthorized(401), NotFound(404) POST /api/prom/configs/templates - Replace current templates\n Normal Response Codes: NoContent(204) Error Response Codes: Unauthorized(401), BadRequest(400) Deactivate/Restore Configs DELETE /api/prom/configs/deactivate - Disable configs for a tenant\n Normal Response Codes: OK(200) Error Response Codes: Unauthorized(401), NotFound(404) POST /api/prom/configs/restore - Re-enable configs for a tenant\n Normal Response Codes OK(200) Error Response Codes: Unauthorized(401), NotFound(404) These API endpoints will disable/enable the current Rule and Alertmanager configuration for a tenant.\nNote that setting a new config will effectively \u0026ldquo;re-enable\u0026rdquo; the Rules and Alertmanager configuration for a tenant.\nIngester Shutdown POST /shutdown - Shutdown all operations of an ingester. Shutdown operations performed are similar to when an ingester is gracefully shutting down, including flushing of chunks if no other ingester is in PENDING state. Ingester does not terminate after calling this endpoint.\n Normal Response Codes: NoContent(204) Error Response Codes: Unauthorized(401) Testing APIs POST /push - Push samples directly to ingesters. Accepts requests in Prometheus remote write format. Indended for performance testing and debugging.\n","excerpt":"[this is a work in progress]\nRemote API Cortex supports Prometheus\u0026rsquo; remote_read and …","ref":"/docs/apis/","title":"Cortex APIs"},{"body":" Cortex integration tests are written in Go and based on a custom framework running Cortex and its dependencies in Docker containers and using the Go testing package for assertions. Integration tests run in CI for every PR, and can be easily executed locally during development (it just requires Docker).\nHow to run integration tests When integration tests run in CI, we build the Cortex docker image based on the PR code and then run the integration tests against it. When running tests locally you should build the Cortex Docker image first:\nmake ./cmd/cortex/.uptodate This will locally build the quay.io/cortexproject/cortex:latest image used by integration tests. Whenever the Cortex code changes (cmd/, pkg/ or vendors) you should rebuild the Cortex image, while it\u0026rsquo;s not necessary to rebuild it while developing integration tests.\nOnce the Docker image is built, you can run integration tests:\ngo test -v -tags=requires_docker ./integration/... If you want to run a single test you can use a filter. For example, to only run TestChunksStorageAllIndexBackends:\ngo test -v -tags=requires_docker ./integration -run \u0026quot;^TestChunksStorageAllIndexBackends$\u0026quot; Supported environment variables CORTEX_IMAGE\nDocker image used to run Cortex in integration tests (defaults to quay.io/cortexproject/cortex:latest) CORTEX_CHECKOUT_DIR\nThe absolute path of the Cortex repository local checkout (defaults to $GOPATH/src/github.com/cortexproject/cortex) The requires_docker tag Integration tests have requires_docker tag (// +build requires_docker line followed by empty line on top of Go files), to avoid running them unintentionally as they require Docker, e.g. by running go test ./... in main Cortex package.\nIsolation Each integration test runs in isolation. For each integration test, we do create a Docker network, start Cortex and its dependencies containers, push/query series to/from Cortex and run assertions on it. Once the test has done, both the Docker network and containers are terminated and deleted.\n","excerpt":"Cortex integration tests are written in Go and based on a custom framework running Cortex and its …","ref":"/docs/contributing/how-integration-tests-work/","title":"How integration tests work"},{"body":" Currently the ingesters running in the chunks storage mode, store all their data in memory. If there is a crash, there could be loss of data. WAL helps fill this gap in reliability.\nTo use WAL, there are some changes that needs to be made in the deployment.\nThe WAL is currently considered experimental.\nChanges to deployment Since ingesters need to have the same persistent volume across restarts/rollout, all the ingesters should be run on statefulset with fixed volumes.\n Following flags needs to be set\n --ingester.wal-enabled to true which enables writing to WAL during ingestion. --ingester.wal-dir to the directory where the WAL data should be stores and/or recovered from. Note that this should be on the mounted volume. --ingester.checkpoint-duration to the interval at which checkpoints should be created. Default is 30m, and depending on the number of series, it can be brought down to 15m if there are less series per ingester (say 1M). --ingester.recover-from-wal to true to recover data from an existing WAL. The data is recovered even if WAL is disabled and this is set to true. The WAL dir needs to be set for this. If you are going to enable WAL, it is advisable to always set this to true. --ingester.tokens-file-path should be set to the filepath where the tokens should be stored. Note that this should be on the mounted volume. Why this is required is described below. Changes in lifecycle when WAL is enabled Flushing of data to chunk store during rollouts or scale down is disabled. This is because during a rollout of statefulset there are no ingesters that are simultaneously leaving and joining, rather the same ingester is shut down and brought back again with updated config. Hence flushing is skipped and the data is recovered from the WAL.\n As there are no transfers between ingesters, the tokens are stored and recovered from disk between rollout/restarts. This is not a new thing but it is effective when using statefulsets.\n Disk space requirements Based on tests in real world:\n Numbers from an ingester with 1.2M series, ~80k samples/s ingested and ~15s scrape interval. Checkpoint period was 20mins, so we need to scale up the number of WAL files to account for the default of 30mins. There were 87 WAL files (an upper estimate) in 20 mins. At any given point, we have 2 complete checkpoints present on the disk and a 2 sets of WAL files between checkpoints (and now). This peaks at 3 checkpoints and 3 lots of WAL momentarily, as we remove the old checkpoints. Observation Disk utilisation Size of 1 checkpoint for 1.2M series 1410 MiB Avg checkpoint size per series 1.2 KiB No. of WAL files between checkpoints (30m checkpoint) 30 mins x 87 / 20mins = 130 Size per WAL file 32 MiB (reduced from Prometheus) Total size of WAL 4160 MiB Steady state usage 2 x 1410 MiB + 2 x 4160 MiB = ~11 GiB Peak usage 3 x 1410 MiB + 3 x 4160 MiB = ~16.3 GiB For 1M series at 15s scrape interval with checkpoint duration of 30m\n Usage Disk utilisation Steady state usage 11 GiB / 1.2 = ~9.2 GiB Peak usage 17 GiB / 1.2 = ~13.6 GiB You should not target 100% disk utilisation; 70% is a safer margin, hence for a 1M active series ingester, a 20GiB disk should suffice.\nMigrating from stateless deployments The ingester deployment without WAL and statefulset with WAL should be scaled down and up respectively in sync without transfer of data between them to ensure that any ingestion after migration is reliable immediately.\nLet\u0026rsquo;s take an example of 4 ingesters. The migration would look something like this:\n Bring up one stateful ingester ingester-0 and wait till it\u0026rsquo;s ready (accepting read and write requests). Scale down old ingester deployment to 3 and wait till the leaving ingester flushes all the data to chunk store. Once that ingester has disappeared from kc get pods ..., add another stateful ingester and wait till it\u0026rsquo;s ready. This assures not transfer. Now you have ingester-0 ingester-1. Repeat step 2 to reduce remove another ingester from old deployment. Repeat step 3 to add another stateful ingester. Now you have ingester-0 ingester-1 ingester-2. Repeat step 4 and 5, and now you will finally have ingester-0 ingester-1 ingester-2 ingester-3. How to scale up/down Scale up Scaling up is same as what you would do without WAL or statefulsets. Nothing to change here.\nScale down Since Kubernetes doesn\u0026rsquo;t differentiate between rollout and scale down when sending a signal, the flushing of chunks is disabled by default. Hence the only thing to take care during scale down is flushing of chunks.\nThere are 2 ways to do it, with the latter being a fallback option.\nFirst option Consider you have 4 ingesters ingester-0 ingester-1 ingester-2 ingester-3 and you want to scale down to 2 ingesters, the ingesters which will be shutdown according to statefulset rules are ingester-3 and then ingester-2.\nHence before actually scaling down in Kubernetes, port forward those ingesters and hit the /shutdown endpoint. This will flush the chunks and shut down the ingesters (while also removing itself from the ring).\nAfter hitting the endpoint for ingester-2 ingester-3, scale down the ingesters to 2.\nPS: Given you have to scale down 1 ingester at a time, you can pipeline the shutdown and scaledown process instead of hitting shutdown endpoint for all to-be-scaled-down ingesters at the same time.\nFallback option\nThere is a flusher target that can be used to flush the data in the WAL. It\u0026rsquo;s config can be found here. As flusher depends on the chunk store and the http API components, you need to also set all the config related to them similar to ingesters (see api,storage,chunk_store,limits,runtime_config and schema). Pro tip: Re-use the ingester config and set the target as flusher with additional flusher config, the irrelevant config will be ignored.\nYou can run it as a Kubernetes job which will:\n Attach to the volume of the scaled down ingester. Recover from the WAL. And flush all the chunks. This job is to be run for all the PVCs linked to the ingesters that you missed hitting the shutdown endpoint as a first option.\nAdditional notes If you have lots of ingestion with the WAL replay taking a longer time, you can try reducing the checkpoint duration (--ingester.checkpoint-duration) to 15m. This would require slightly higher disk bandwidth for writes (still less in absolute terms), but it will reduce the WAL replay time overall. Non-Kubernetes or baremetal deployments When the ingester restarts for any reason (upgrade, crash, etc), it should be able to attach to the same volume in order to recover back the WAL and tokens. If it fails to attach to the same volume for any reason, use the flusher to flush that data. 2 ingesters should not be working with the same volume/directory for the WAL. It will cause data corruptions. Basing from above point, rollout should include bringing down an ingester completely and then starting the new ingester. Not the other way round, i.e. bringing another ingester live and taking the old one down. ","excerpt":"Currently the ingesters running in the chunks storage mode, store all their data in memory. If there …","ref":"/docs/production/ingesters-with-wal/","title":"Ingesters with WAL"},{"body":"Configuration for running Cortex in single-process mode. This should not be used in production. It is only for getting started and development.\n# Disable the requirement that every request to Cortex has a# X-Scope-OrgID header. `fake` will be substituted in instead.auth_enabled:falseserver:http_listen_port:9009# Configure the server to allow messages up to 100MB.grpc_server_max_recv_msg_size:104857600grpc_server_max_send_msg_size:104857600grpc_server_max_concurrent_streams:1000distributor:shard_by_all_labels:truepool:health_check_ingesters:trueingester_client:grpc_client_config:# Configure the client to allow messages up to 100MB.max_recv_msg_size:104857600max_send_msg_size:104857600use_gzip_compression:trueingester:#chunk_idle_period: 15mlifecycler:# The address to advertise for this ingester. Will be autodiscovered by# looking up address on eth0 or en0; can be specified if this fails.# address: 127.0.0.1# We want to start immediately and flush on shutdown.join_after:0final_sleep:0snum_tokens:512# Use an in memory ring store, so we don\u0026#39;t need to launch a Consul.ring:kvstore:store:inmemoryreplication_factor:1# Use local storage - BoltDB for the index, and the filesystem# for the chunks.schema:configs:-from:2019-07-29store:boltdbobject_store:filesystemschema:v10index:prefix:index_period:1wstorage:boltdb:directory:/tmp/cortex/indexfilesystem:directory:/tmp/cortex/chunks# Configure the frontend worker in the querier to match worker count# to max_concurrent on the queriers.frontend_worker:match_max_concurrent:true","excerpt":"Configuration for running Cortex in single-process mode. This should not be used in production. It …","ref":"/docs/configuration/single-process-config/","title":"Single-process"},{"body":" In a default configuration, time-series written to ingesters are replicated based on the container/pod name of the ingester instances. It is completely possible that all the replicas for the given time-series are held with in the same availability zone, even if the cortex infrastructure spans multiple zones within the region. Storing multiple replicas for a given time-series poses a risk for data loss if there is an outage affecting various nodes within a zone or a total outage.\nConfiguration Cortex can be configured to consider an availability zone value in its replication system. Doing so mitigates risks associated with losing multiple nodes within the same availability zone. The availability zone for an ingester can be defined on the command line of the ingester using the ingester.availability-zone flag or using the yaml configuration:\ningester:lifecycler:availability_zone:\u0026#34;zone-3\u0026#34; Zone Replication Considerations Enabling availability zone awareness helps mitigate risks regarding data loss within a single zone, some items need consideration by an operator if they are thinking of enabling this feature.\nMinimum number of Zones For cortex to function correctly, there must be at least the same number of availability zones as there is replica count. So by default, a cortex cluster should be spread over 3 zones as the default replica count is 3. It is safe to have more zones than the replica count, but it cannot be less. Having fewer availability zones than replica count causes a replica write to be missed, and in some cases, the write fails if the availability zone count is too low.\nCost Depending on the existing cortex infrastructure being used, this may cause an increase in running costs as most cloud providers charge for cross availability zone traffic. The most significant change would be for a cortex cluster currently running in a singular zone.\n","excerpt":"In a default configuration, time-series written to ingesters are replicated based on the …","ref":"/docs/guides/zone-aware-replication/","title":"Zone Aware Replication"},{"body":"All Cortex components take the tenant ID from a header X-Scope-OrgID on each request. They trust this value completely: if you need to protect your Cortex installation from accidental or malicious calls then you must add an additional layer of protection.\nTypically this means you run Cortex behind a reverse proxy, and ensure that all callers, both machines sending data over the remote_write interface and humans sending queries from GUIs, supply credentials which identify them and confirm they are authorised.\nWhen configuring the remote_write API in Prometheus there is no way to add extra headers. The user and password fields of http Basic auth, or Bearer token, can be used to convey tenant ID and/or credentials.\n","excerpt":"All Cortex components take the tenant ID from a header X-Scope-OrgID on each request. They trust …","ref":"/docs/production/auth/","title":"Authentication and Authorisation"},{"body":"","excerpt":"","ref":"/docs/guides/","title":"Guides"},{"body":" For the v1.0 release, we want to provide the following guarantees:\nFlags, Config and minor version upgrades Upgrading cortex from one minor version to the next should \u0026ldquo;just work\u0026rdquo;; that being said, we don\u0026rsquo;t want to bump the major version every time we remove a flag, so we will will keep deprecated flags around for 2 minor release. There is a metric (cortex_deprecated_flags_inuse_total) you can alert on to find out if you\u0026rsquo;re using a deprecated flag.\nSimilarly to flags, minor version upgrades using config files should \u0026ldquo;just work\u0026rdquo;. If we do need to change config, we will keep the old way working for two minor version. There will be a metric you can alert on for this too.\nThese guarantees don\u0026rsquo;t apply for experimental features.\nReading old data The Cortex maintainers commit to ensuring future version of Cortex can read data written by versions up to two years old. In practice we expect to be able to read more, but this is our guarantee.\nAPI Compatibility Cortex strives to be 100% API compatible with Prometheus (under /api/prom/*); any deviation from this is considered a bug, except:\n Requiring the __name__ label on queries. Additional API endpoints for creating, removing and modifying alerts and recording rules. Additional API around pushing metrics (under /api/push). Additional API endpoints for management of Cortex itself, such as the ring. These APIs are not part of the any compatibility guarantees. Experimental features Cortex is an actively developed project and we want to encourage the introduction of new features and capability. As such, not everything in each release of Cortex is considered \u0026ldquo;production-ready\u0026rdquo;. We don\u0026rsquo;t provide any backwards compatibility guarantees on these and the config and flags might break.\nCurrently experimental features are:\n TSDB block storage. Ingester chunk WAL. Cassandra storage engine. Azure blob storage. Zone awareness based replication. Gossip based ring. User subrings. Ruler API (to PUT rules). Memcached client DNS-based service discovery. Delete series APIs. In-memory (FIFO) and Redis cache. Openstack Swift storage. ","excerpt":"For the v1.0 release, we want to provide the following guarantees:\nFlags, Config and minor version …","ref":"/docs/configuration/v1guarantees/","title":"v1.x Guarantees"},{"body":"","excerpt":"","ref":"/docs/configuration/","title":"Configuration"},{"body":"","excerpt":"","ref":"/docs/operations/","title":"Operating Cortex"},{"body":" Context You can have more than a single Prometheus monitoring and ingesting the same metrics for redundancy. Cortex already does replication for redundancy and it doesn\u0026rsquo;t make sense to ingest the same data twice. So in Cortex, we made sure we can dedupe the data we receive from HA Pairs of Prometheus. We do this via the following:\nAssume that there are two teams, each running their own Prometheus, monitoring different services. Let\u0026rsquo;s call the Prometheis T1 and T2. Now, if the teams are running HA pairs, let\u0026rsquo;s call the individual Prometheis, T1.a, T1.b and T2.a and T2.b.\nIn Cortex we make sure we only ingest from one of T1.a and T1.b, and only from one of T2.a and T2.b. We do this by electing a leader replica for each cluster of Prometheus. For example, in the case of T1, let it be T1.a. As long as T1.a is the leader, we drop the samples sent by T1.b. And if Cortex sees no new samples from T1.a for a short period (30s by default), it\u0026rsquo;ll switch the leader to be T1.b.\nThis means if T1.a goes down for a few minutes Cortex\u0026rsquo;s HA sample handling will have switched and elected T1.b as the leader. This failover timeout is what enables us to only accept samples from a single replica at a time, but ensure we don\u0026rsquo;t drop too much data in case of issues. Note that with the default scrape period of 15s, and the default timeouts in Cortex, in most cases you\u0026rsquo;ll only lose a single scrape of data in the case of a leader election failover. For any rate queries the rate window should be at least 4x the scrape period to account for any of these failover scenarios, for example with the default scrape period of 15s then you should calculate rates over at least 1m periods.\nNow we do the same leader election process T2.\nConfig Client Side So for Cortex to achieve this, we need 2 identifiers for each process, one identifier for the cluster (T1 or T2, etc) and one identifier to identify the replica in the cluster (a or b). The easiest way to do with is by setting external labels, ideally cluster and replica (note the default is __replica__). For example:\ncluster: prom-team1 replica: replica1 (or pod-name) and\ncluster: prom-team1 replica: replica2 Note: These are external labels and have nothing to do with remote_write config.\nThese two label names are configurable per-tenant within Cortex, and should be set to something sensible. For example, cluster label is already used by some workloads, and you should set the label to be something else but uniquely identifies the cluster. Good examples for this label-name would be team, cluster, prometheus, etc.\nThe replica label should be set so that the value for each prometheus is unique in that cluster. Note: Cortex drops this label when ingesting data, but preserves the cluster label. This way, your timeseries won\u0026rsquo;t change when replicas change.\nServer Side To enable handling of samples, see the distributor flags having ha-tracker in them.\n","excerpt":"Context You can have more than a single Prometheus monitoring and ingesting the same metrics for …","ref":"/docs/production/ha-pair-handling/","title":"Config for sending HA Pairs data to Cortex"},{"body":" Welcome! We\u0026rsquo;re excited that you\u0026rsquo;re interested in contributing. Below are some basic guidelines.\nWorkflow Cortex follows a standard GitHub pull request workflow. If you\u0026rsquo;re unfamiliar with this workflow, read the very helpful Understanding the GitHub flow guide from GitHub.\nYou are welcome to create draft PRs at any stage of readiness - this can be helpful to ask for assistance or to develop an idea. But before a piece of work is finished it should:\n Be organised into one or more commits, each of which has a commit message that describes all changes made in that commit (\u0026lsquo;why\u0026rsquo; more than \u0026lsquo;what\u0026rsquo; - we can read the diffs to see the code that changed). Each commit should build towards the whole - don\u0026rsquo;t leave in back-tracks and mistakes that you later corrected. Have unit and/or integration tests for new functionality or tests that would have caught the bug being fixed. Include a CHANGELOG message if users of Cortex need to hear about what you did. If you have made any changes to flags or config, run make doc and commit the changed files to update the config file documentation. Formatting Cortex projects uses goimports tool (go get golang.org/x/tools/cmd/goimports to install) to format the Go files, and sort imports. We use goimports with -local github.com/cortexproject/cortex parameter, to put Cortex internal imports into a separate group. We try to keep imports sorted into three groups: imports from standard library, imports of 3rd party packages and internal Cortex imports. Goimports will fix the order, but will keep existing newlines between imports in the groups. We try to avoid extra newlines like that.\nYou\u0026rsquo;re using an IDE you may find useful the following settings for the Cortex project:\n VSCode Developer Certificates of Origin (DCOs) Before submitting your work in a pull request, make sure that all commits are signed off with a Developer Certificate of Origin (DCO). Here\u0026rsquo;s an example:\ngit commit -s -m \u0026#34;Here is my signed commit\u0026#34; You can find further instructions here.\nBuilding Cortex To build:\nmake (By default, the build runs in a Docker container, using an image built with all the tools required. The source code is mounted from where you run make into the build container as a Docker volume.)\nTo run the unit tests suite:\ngo test ./... To run the integration tests suite please see \u0026ldquo;How integration tests work\u0026rdquo;.\nDependency management We uses Go modules to manage dependencies on external packages. This requires a working Go environment with version 1.11 or greater, git and bzr installed.\nTo add or update a new dependency, use the go get command:\n# Pick the latest tagged release. go get example.com/some/module/pkg # Pick a specific version. go get example.com/some/module/pkg@vX.Y.Z Tidy up the go.mod and go.sum files:\ngo mod tidy go mod vendor git add go.mod go.sum vendor git commit You have to commit the changes to go.mod and go.sum before submitting the pull request.\nDesign patterns and Code conventions Please see the dedicated \u0026ldquo;Design patterns and Code conventions\u0026rdquo; page.\nDocumentation The Cortex documentation is compiled into a website published at cortexmetrics.io. Please see \u0026ldquo;How to run the website locally\u0026rdquo; for instructions.\nNote: if you attempt to view pages on Github, it\u0026rsquo;s likely that you might find broken links or pages. That is expected and should not be addressed unless it is causing issues with the site that occur as part of the build.\n","excerpt":"Welcome! We\u0026rsquo;re excited that you\u0026rsquo;re interested in contributing. Below are some basic …","ref":"/docs/contributing/","title":"Contributing"},{"body":"","excerpt":"","ref":"/docs/case-studies/","title":"Case Studies"},{"body":" This document defines project governance for the project.\nVoting The Cortex project employs voting to ensure no single member can dominate the project. Any maintainer may cast a vote. To avoid having a single company dominate the project, at most two votes from maintainers working for the same company will count.\nFor formal votes, a specific statement of what is being voted on should be added to the relevant github issue or PR, and a link to that issue or PR added to the maintainers meeting agenda document. Maintainers should indicate their yes/no vote on that issue or PR, and after a suitable period of time, the votes will be tallied and the outcome noted.\nChanges in Maintainership New maintainers are proposed by an existing maintainer and are elected by a 2\u0026frasl;3 majority vote.\nMaintainers can be removed by a 2\u0026frasl;3 majority vote.\nApproving PRs PRs may be merged after receiving at least two positive votes. If the PR author is a maintainer, this counts as a vote.\nGithub Project Administration Maintainers will be added to the collaborators list of the Cortex repository with \u0026ldquo;Write\u0026rdquo; access.\nAfter 6 months a maintainer will be given \u0026ldquo;Admin\u0026rdquo; access to the Cortex repository.\nChanges in Governance All changes in Governance require a 2\u0026frasl;3 majority vote.\nOther Changes Unless specified above, all other changes to the project require a 2\u0026frasl;3 majority vote. Additionally, any maintainer may request that any change require a 2\u0026frasl;3 majority vote.\n","excerpt":"This document defines project governance for the project.\nVoting The Cortex project employs voting …","ref":"/docs/governance/","title":"Governance"},{"body":" master / unreleased [CHANGE] Added v1 API routes documented in #2327. #2372 Added -http.alertmanager-http-prefix flag which allows the configuration of the path where the Alertmanager API and UI can be reached. The default is set to /alertmanager. Added -http.prometheus-http-prefix flag which allows the configuration of the path where the Prometheus API and UI can be reached. The default is set to /prometheus. Updated the index hosted at the root prefix to point to the updated routes. Legacy routes hardcoded with the /api/prom prefix now respect the -http.prefix flag. [CHANGE] The metrics cortex_distributor_ingester_appends_total and distributor_ingester_append_failures_total now includes a type label to differentiate between samples and metadata. #2336 [CHANGE] The metrics for number of chunks and bytes flushed to the chunk store are renamed from: #2463 cortex_ingester_chunks_stored_total \u0026gt; cortex_chunk_store_stored_chunks_total cortex_ingester_chunk_stored_bytes_total \u0026gt; cortex_chunk_store_stored_chunk_bytes_total [CHANGE] Experimental TSDB: renamed blocks meta fetcher metrics: #2375 cortex_querier_bucket_store_blocks_meta_syncs_total \u0026gt; cortex_querier_blocks_meta_syncs_total cortex_querier_bucket_store_blocks_meta_sync_failures_total \u0026gt; cortex_querier_blocks_meta_sync_failures_total cortex_querier_bucket_store_blocks_meta_sync_duration_seconds \u0026gt; cortex_querier_blocks_meta_sync_duration_seconds cortex_querier_bucket_store_blocks_meta_sync_consistency_delay_seconds \u0026gt; cortex_querier_blocks_meta_sync_consistency_delay_seconds [CHANGE] Experimental TSDB: Modified default values for compactor.deletion-delay option from 48h to 12h and -experimental.tsdb.bucket-store.ignore-deletion-marks-delay from 24h to 6h. #2414 [CHANGE] Experimental WAL: Default value of -ingester.checkpoint-enabled changed to true. #2416 [CHANGE] trace_id field in log files has been renamed to traceID. #2518 [CHANGE] Slow query log has a different output now. Previously used url field has been replaced with host and path, and query parameters are logged as individual log fields with qs_ prefix. #2520 [CHANGE] Experimental WAL: WAL and checkpoint compression is now disabled. #2436 [CHANGE] Update in dependency go-kit/kit from v0.9.0 to v0.10.0. HTML escaping disabled in JSON Logger. #2535 [CHANGE] Experimental TSDB: Removed cortex_\u0026lt;service\u0026gt;_ prefix from Thanos objstore metrics and added component label to distinguish which Cortex component is doing API calls to the object storage when running in single-binary mode: #2568 cortex_\u0026lt;service\u0026gt;_thanos_objstore_bucket_operations_total renamed to thanos_objstore_bucket_operations_total{component=\u0026quot;\u0026lt;name\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_thanos_objstore_bucket_operation_failures_total renamed to thanos_objstore_bucket_operation_failures_total{component=\u0026quot;\u0026lt;name\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_thanos_objstore_bucket_operation_duration_seconds renamed to thanos_objstore_bucket_operation_duration_seconds{component=\u0026quot;\u0026lt;name\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_thanos_objstore_bucket_last_successful_upload_time renamed to thanos_objstore_bucket_last_successful_upload_time{component=\u0026quot;\u0026lt;name\u0026gt;\u0026quot;} [FEATURE] Ruler: The -ruler.evaluation-delay flag was added to allow users to configure a default evaluation delay for all rules in cortex. The default value is 0 which is the current behavior. #2423 [FEATURE] Experimental: Added a new object storage client for OpenStack Swift. #2440 [FEATURE] Update in dependency weaveworks/common. TLS config options added to the Server. #2535 [FEATURE] Experimental: Added support for /api/v1/metadata Prometheus-based endpoint. #2549 [FEATURE] Add ability to limit concurrent queries to Cassandra with -cassandra.query-concurrency flag. #2562 [ENHANCEMENT] Experimental TSDB: sample ingestion errors are now reported via existing cortex_discarded_samples_total metric. #2370 [ENHANCEMENT] Failures on samples at distributors and ingesters return the first validation error as opposed to the last. #2383 [ENHANCEMENT] Experimental TSDB: Added cortex_querier_blocks_meta_synced, which reflects current state of synced blocks over all tenants. #2392 [ENHANCEMENT] Added cortex_distributor_latest_seen_sample_timestamp_seconds metric to see how far behind Prometheus servers are in sending data. #2371 [ENHANCEMENT] FIFO cache to support eviction based on memory usage. The -\u0026lt;prefix\u0026gt;.fifocache.size CLI flag has been renamed to -\u0026lt;prefix\u0026gt;.fifocache.max-size-items as well as its YAML config option size renamed to max_size_items. Added -\u0026lt;prefix\u0026gt;.fifocache.max-size-bytes CLI flag and YAML config option max_size_bytes to specify memory limit of the cache. #2319, #2527 [ENHANCEMENT] Added -querier.worker-match-max-concurrent. Force worker concurrency to match the -querier.max-concurrent option. Overrides -querier.worker-parallelism. #2456 [ENHANCEMENT] Added the following metrics for monitoring delete requests: #2445 cortex_purger_delete_requests_received_total: Number of delete requests received per user. cortex_purger_delete_requests_processed_total: Number of delete requests processed per user. cortex_purger_delete_requests_chunks_selected_total: Number of chunks selected while building delete plans per user. cortex_purger_delete_requests_processing_failures_total: Number of delete requests processing failures per user. [ENHANCEMENT] Single Binary: Added query-frontend to the single binary. Single binary users will now benefit from various query-frontend features. Primarily: sharding, parallelization, load shedding, additional caching (if configured), and query retries. #2437 [ENHANCEMENT] Allow 1w (where w denotes week) and 1y (where y denotes year) when setting -store.cache-lookups-older-than and -store.max-look-back-period. #2454 [ENHANCEMENT] Optimize index queries for matchers using \u0026ldquo;a|b|c\u0026rdquo;-type regex. #2446 #2475 [ENHANCEMENT] Added per tenant metrics for queries and chunks and bytes read from chunk store: #2463 [ENHANCEMENT] Experimental WAL: New metrics cortex_ingester_wal_logged_bytes_total and cortex_ingester_checkpoint_logged_bytes_total added to track total bytes logged to disk for WAL and checkpoints. #2497 cortex_chunk_store_fetched_chunks_total and cortex_chunk_store_fetched_chunk_bytes_total cortex_query_frontend_queries_total (per tenant queries counted by the frontend) [ENHANCEMENT] Add de-duplicated chunks counter cortex_chunk_store_deduped_chunks_total which counts every chunk not sent to the store because it was already sent by another replica. #2485 [ENHANCEMENT] query-frontend now also logs the POST data of long queries. #2481 [ENHANCEMENT] Experimental WAL: Ingester WAL records now have type header and the custom WAL records have been replaced by Prometheus TSDB\u0026rsquo;s WAL records. Old records will not be supported from 1.3 onwards. Note: once this is deployed, you cannot downgrade without data loss. #2436 [ENHANCEMENT] Redis Cache: Added idle_timeout, wait_on_pool_exhaustion and max_conn_lifetime options to redis cache configuration. #2550 [BUGFIX] Ruler: Ensure temporary rule files with special characters are properly mapped and cleaned up. #2506 [BUGFIX] Fixes #2411, Ensure requests are properly routed to the prometheus api embedded in the query if -server.path-prefix is set. #2372 [BUGFIX] Experimental TSDB: fixed chunk data corruption when querying back series using the experimental blocks storage. #2400 [BUGFIX] Cassandra Storage: Fix endpoint TLS host verification. #2109 [BUGFIX] Experimental TSDB: fixed response status code from 422 to 500 when an error occurs while iterating chunks with the experimental blocks storage. #2402 [BUGFIX] Ring: Fixed a situation where upgrading from pre-1.0 cortex with a rolling strategy caused new 1.0 ingesters to lose their zone value in the ring until manually forced to re-register. #2404 [BUGFIX] Distributor: /all_user_stats now show API and Rule Ingest Rate correctly. #2457 [BUGFIX] Fixed version, revision and branch labels exported by the cortex_build_info metric. #2468 [BUGFIX] QueryFrontend: fixed a situation where HTTP error is ignored and an incorrect status code is set. #2483 [BUGFIX] QueryFrontend: fixed a situation where span context missed when downstream_url is used. #2539 [BUGFIX] Querier: Fixed a situation where querier would crash because of an unresponsive frontend instance. #2569 1.0.0 / 2020-04-02 This is the first major release of Cortex. We made a lot of breaking changes in this release which have been detailed below. Please also see the stability guarantees we provide as part of a major release: https://cortexmetrics.io/docs/configuration/v1guarantees/\n [CHANGE] Remove the following deprecated flags: #2339 -metrics.error-rate-query (use -metrics.write-throttle-query instead). -store.cardinality-cache-size (use -store.index-cache-read.enable-fifocache and -store.index-cache-read.fifocache.size instead). -store.cardinality-cache-validity (use -store.index-cache-read.enable-fifocache and -store.index-cache-read.fifocache.duration instead). -distributor.limiter-reload-period (flag unused) -ingester.claim-on-rollout (flag unused) -ingester.normalise-tokens (flag unused) [CHANGE] Renamed YAML file options to be more consistent. See full config file changes below. #2273 [CHANGE] AWS based autoscaling has been removed. You can only use metrics based autoscaling now. -applicationautoscaling.url has been removed. See https://cortexmetrics.io/docs/guides/aws/#dynamodb-capacity-provisioning on how to migrate. #2328 [CHANGE] Renamed the memcache.write-back-goroutines and memcache.write-back-buffer flags to background.write-back-concurrency and background.write-back-buffer. This affects the following flags: #2241\n -frontend.memcache.write-back-buffer \u0026ndash;\u0026gt; -frontend.background.write-back-buffer -frontend.memcache.write-back-goroutines \u0026ndash;\u0026gt; -frontend.background.write-back-concurrency -store.index-cache-read.memcache.write-back-buffer \u0026ndash;\u0026gt; -store.index-cache-read.background.write-back-buffer -store.index-cache-read.memcache.write-back-goroutines \u0026ndash;\u0026gt; -store.index-cache-read.background.write-back-concurrency -store.index-cache-write.memcache.write-back-buffer \u0026ndash;\u0026gt; -store.index-cache-write.background.write-back-buffer -store.index-cache-write.memcache.write-back-goroutines \u0026ndash;\u0026gt; -store.index-cache-write.background.write-back-concurrency -memcache.write-back-buffer \u0026ndash;\u0026gt; -store.chunks-cache.background.write-back-buffer. Note the next change log for the difference. -memcache.write-back-goroutines \u0026ndash;\u0026gt; -store.chunks-cache.background.write-back-concurrency. Note the next change log for the difference. [CHANGE] Renamed the chunk cache flags to have store.chunks-cache. as prefix. This means the following flags have been changed: #2241\n -cache.enable-fifocache \u0026ndash;\u0026gt; -store.chunks-cache.cache.enable-fifocache -default-validity \u0026ndash;\u0026gt; -store.chunks-cache.default-validity -fifocache.duration \u0026ndash;\u0026gt; -store.chunks-cache.fifocache.duration -fifocache.size \u0026ndash;\u0026gt; -store.chunks-cache.fifocache.size -memcache.write-back-buffer \u0026ndash;\u0026gt; -store.chunks-cache.background.write-back-buffer. Note the previous change log for the difference. -memcache.write-back-goroutines \u0026ndash;\u0026gt; -store.chunks-cache.background.write-back-concurrency. Note the previous change log for the difference. -memcached.batchsize \u0026ndash;\u0026gt; -store.chunks-cache.memcached.batchsize -memcached.consistent-hash \u0026ndash;\u0026gt; -store.chunks-cache.memcached.consistent-hash -memcached.expiration \u0026ndash;\u0026gt; -store.chunks-cache.memcached.expiration -memcached.hostname \u0026ndash;\u0026gt; -store.chunks-cache.memcached.hostname -memcached.max-idle-conns \u0026ndash;\u0026gt; -store.chunks-cache.memcached.max-idle-conns -memcached.parallelism \u0026ndash;\u0026gt; -store.chunks-cache.memcached.parallelism -memcached.service \u0026ndash;\u0026gt; -store.chunks-cache.memcached.service -memcached.timeout \u0026ndash;\u0026gt; -store.chunks-cache.memcached.timeout -memcached.update-interval \u0026ndash;\u0026gt; -store.chunks-cache.memcached.update-interval -redis.enable-tls \u0026ndash;\u0026gt; -store.chunks-cache.redis.enable-tls -redis.endpoint \u0026ndash;\u0026gt; -store.chunks-cache.redis.endpoint -redis.expiration \u0026ndash;\u0026gt; -store.chunks-cache.redis.expiration -redis.max-active-conns \u0026ndash;\u0026gt; -store.chunks-cache.redis.max-active-conns -redis.max-idle-conns \u0026ndash;\u0026gt; -store.chunks-cache.redis.max-idle-conns -redis.password \u0026ndash;\u0026gt; -store.chunks-cache.redis.password -redis.timeout \u0026ndash;\u0026gt; -store.chunks-cache.redis.timeout [CHANGE] Rename the -store.chunk-cache-stubs to -store.chunks-cache.cache-stubs to be more inline with above. #2241\n [CHANGE] Change prefix of flags -dynamodb.periodic-table.* to -table-manager.index-table.*. #2359\n [CHANGE] Change prefix of flags -dynamodb.chunk-table.* to -table-manager.chunk-table.*. #2359\n [CHANGE] Change the following flags: #2359\n -dynamodb.poll-interval \u0026ndash;\u0026gt; -table-manager.poll-interval -dynamodb.periodic-table.grace-period \u0026ndash;\u0026gt; -table-manager.periodic-table.grace-period [CHANGE] Renamed the following flags: #2273\n -dynamodb.chunk.gang.size \u0026ndash;\u0026gt; -dynamodb.chunk-gang-size -dynamodb.chunk.get.max.parallelism \u0026ndash;\u0026gt; -dynamodb.chunk-get-max-parallelism [CHANGE] Don\u0026rsquo;t support mixed time units anymore for duration. For example, 168h5m0s doesn\u0026rsquo;t work anymore, please use just one unit (s|m|h|d|w|y). #2252\n [CHANGE] Utilize separate protos for rule state and storage. Experimental ruler API will not be functional until the rollout is complete. #2226\n [CHANGE] Frontend worker in querier now starts after all Querier module dependencies are started. This fixes issue where frontend worker started to send queries to querier before it was ready to serve them (mostly visible when using experimental blocks storage). #2246\n [CHANGE] Lifecycler component now enters Failed state on errors, and doesn\u0026rsquo;t exit the process. (Important if you\u0026rsquo;re vendoring Cortex and use Lifecycler) #2251\n [CHANGE] /ready handler now returns 200 instead of 204. #2330\n [CHANGE] Better defaults for the following options: #2344\n -\u0026lt;prefix\u0026gt;.consul.consistent-reads: Old default: true, new default: false. This reduces the load on Consul. -\u0026lt;prefix\u0026gt;.consul.watch-rate-limit: Old default: 0, new default: 1. This rate limits the reads to 1 per second. Which is good enough for ring watches. -distributor.health-check-ingesters: Old default: false, new default: true. -ingester.max-stale-chunk-idle: Old default: 0, new default: 2m. This lets us expire series that we know are stale early. -ingester.spread-flushes: Old default: false, new default: true. This allows to better de-duplicate data and use less space. -ingester.chunk-age-jitter: Old default: 20mins, new default: 0. This is to enable the -ingester.spread-flushes to true. -\u0026lt;prefix\u0026gt;.memcached.batchsize: Old default: 0, new default: 1024. This allows batching of requests and keeps the concurrent requests low. -\u0026lt;prefix\u0026gt;.memcached.consistent-hash: Old default: false, new default: true. This allows for better cache hits when the memcaches are scaled up and down. -querier.batch-iterators: Old default: false, new default: true. -querier.ingester-streaming: Old default: false, new default: true. [CHANGE] Experimental TSDB: Added -experimental.tsdb.bucket-store.postings-cache-compression-enabled to enable postings compression when storing to cache. #2335\n [CHANGE] Experimental TSDB: Added -compactor.deletion-delay, which is time before a block marked for deletion is deleted from bucket. If not 0, blocks will be marked for deletion and compactor component will delete blocks marked for deletion from the bucket. If delete-delay is 0, blocks will be deleted straight away. Note that deleting blocks immediately can cause query failures, if store gateway / querier still has the block loaded, or compactor is ignoring the deletion because it\u0026rsquo;s compacting the block at the same time. Default value is 48h. #2335\n [CHANGE] Experimental TSDB: Added -experimental.tsdb.bucket-store.index-cache.postings-compression-enabled, to set duration after which the blocks marked for deletion will be filtered out while fetching blocks used for querying. This option allows querier to ignore blocks that are marked for deletion with some delay. This ensures store can still serve blocks that are meant to be deleted but do not have a replacement yet. Default is 24h, half of the default value for -compactor.deletion-delay. #2335\n [CHANGE] Experimental TSDB: Added -experimental.tsdb.bucket-store.index-cache.memcached.max-item-size to control maximum size of item that is stored to memcached. Defaults to 1 MiB. #2335\n [FEATURE] Added experimental storage API to the ruler service that is enabled when the -experimental.ruler.enable-api is set to true #2269\n -ruler.storage.type flag now allows s3,gcs, and azure values -ruler.storage.(s3|gcs|azure) flags exist to allow the configuration of object clients set for rule storage [CHANGE] Renamed table manager metrics. #2307 #2359\n cortex_dynamo_sync_tables_seconds -\u0026gt; cortex_table_manager_sync_duration_seconds cortex_dynamo_table_capacity_units -\u0026gt; cortex_table_capacity_units [FEATURE] Flusher target to flush the WAL. #2075\n -flusher.wal-dir for the WAL directory to recover from. -flusher.concurrent-flushes for number of concurrent flushes. -flusher.flush-op-timeout is duration after which a flush should timeout. [FEATURE] Ingesters can now have an optional availability zone set, to ensure metric replication is distributed across zones. This is set via the -ingester.availability-zone flag or the availability_zone field in the config file. #2317\n [ENHANCEMENT] Better re-use of connections to DynamoDB and S3. #2268\n [ENHANCEMENT] Reduce number of goroutines used while executing a single index query. #2280\n [ENHANCEMENT] Experimental TSDB: Add support for local filesystem backend. #2245\n [ENHANCEMENT] Experimental TSDB: Added memcached support for the TSDB index cache. #2290\n [ENHANCEMENT] Experimental TSDB: Removed gRPC server to communicate between querier and BucketStore. #2324\n [ENHANCEMENT] Allow 1w (where w denotes week) and 1y (where y denotes year) when setting table period and retention. #2252\n [ENHANCEMENT] Added FIFO cache metrics for current number of entries and memory usage. #2270\n [ENHANCEMENT] Output all config fields to /config API, including those with empty value. #2209\n [ENHANCEMENT] Add \u0026ldquo;missing_metric_name\u0026rdquo; and \u0026ldquo;metric_name_invalid\u0026rdquo; reasons to cortex_discarded_samples_total metric. #2346\n [ENHANCEMENT] Experimental TSDB: sample ingestion errors are now reported via existing cortex_discarded_samples_total metric. #2370\n [BUGFIX] Ensure user state metrics are updated if a transfer fails. #2338\n [BUGFIX] Fixed etcd client keepalive settings. #2278\n [BUGFIX] Register the metrics of the WAL. #2295\n [BUXFIX] Experimental TSDB: fixed error handling when ingesting out of bound samples. #2342\n [BUGFIX] Fix gaps when querying ingesters with replication factor = 3 and 2 ingesters in the cluster. #2503\n Known issues This experimental blocks storage in Cortex 1.0.0 has a bug which may lead to the error cannot iterate chunk for series when running queries. This bug has been fixed in #2400. If you\u0026rsquo;re running the experimental blocks storage, please build Cortex from master. Config file breaking changes In this section you can find a config file diff showing the breaking changes introduced in Cortex. You can also find the full configuration file reference doc in the website.\n### ingester_config # Period with which to attempt to flush chunks. # CLI flag: -ingester.flush-period -[flushcheckperiod: \u0026lt;duration\u0026gt; | default = 1m0s] +[flush_period: \u0026lt;duration\u0026gt; | default = 1m0s] # Period chunks will remain in memory after flushing. # CLI flag: -ingester.retain-period -[retainperiod: \u0026lt;duration\u0026gt; | default = 5m0s] +[retain_period: \u0026lt;duration\u0026gt; | default = 5m0s] # Maximum chunk idle time before flushing. # CLI flag: -ingester.max-chunk-idle -[maxchunkidle: \u0026lt;duration\u0026gt; | default = 5m0s] +[max_chunk_idle_time: \u0026lt;duration\u0026gt; | default = 5m0s] # Maximum chunk idle time for chunks terminating in stale markers before # flushing. 0 disables it and a stale series is not flushed until the # max-chunk-idle timeout is reached. # CLI flag: -ingester.max-stale-chunk-idle -[maxstalechunkidle: \u0026lt;duration\u0026gt; | default = 0s] +[max_stale_chunk_idle_time: \u0026lt;duration\u0026gt; | default = 2m0s] # Timeout for individual flush operations. # CLI flag: -ingester.flush-op-timeout -[flushoptimeout: \u0026lt;duration\u0026gt; | default = 1m0s] +[flush_op_timeout: \u0026lt;duration\u0026gt; | default = 1m0s] # Maximum chunk age before flushing. # CLI flag: -ingester.max-chunk-age -[maxchunkage: \u0026lt;duration\u0026gt; | default = 12h0m0s] +[max_chunk_age: \u0026lt;duration\u0026gt; | default = 12h0m0s] -# Range of time to subtract from MaxChunkAge to spread out flushes +# Range of time to subtract from -ingester.max-chunk-age to spread out flushes # CLI flag: -ingester.chunk-age-jitter -[chunkagejitter: \u0026lt;duration\u0026gt; | default = 20m0s] +[chunk_age_jitter: \u0026lt;duration\u0026gt; | default = 0] # Number of concurrent goroutines flushing to dynamodb. # CLI flag: -ingester.concurrent-flushes -[concurrentflushes: \u0026lt;int\u0026gt; | default = 50] +[concurrent_flushes: \u0026lt;int\u0026gt; | default = 50] -# If true, spread series flushes across the whole period of MaxChunkAge +# If true, spread series flushes across the whole period of +# -ingester.max-chunk-age. # CLI flag: -ingester.spread-flushes -[spreadflushes: \u0026lt;boolean\u0026gt; | default = false] +[spread_flushes: \u0026lt;boolean\u0026gt; | default = true] # Period with which to update the per-user ingestion rates. # CLI flag: -ingester.rate-update-period -[rateupdateperiod: \u0026lt;duration\u0026gt; | default = 15s] +[rate_update_period: \u0026lt;duration\u0026gt; | default = 15s] ### querier_config # The maximum number of concurrent queries. # CLI flag: -querier.max-concurrent -[maxconcurrent: \u0026lt;int\u0026gt; | default = 20] +[max_concurrent: \u0026lt;int\u0026gt; | default = 20] # Use batch iterators to execute query, as opposed to fully materialising the # series in memory. Takes precedent over the -querier.iterators flag. # CLI flag: -querier.batch-iterators -[batchiterators: \u0026lt;boolean\u0026gt; | default = false] +[batch_iterators: \u0026lt;boolean\u0026gt; | default = true] # Use streaming RPCs to query ingester. # CLI flag: -querier.ingester-streaming -[ingesterstreaming: \u0026lt;boolean\u0026gt; | default = false] +[ingester_streaming: \u0026lt;boolean\u0026gt; | default = true] # Maximum number of samples a single query can load into memory. # CLI flag: -querier.max-samples -[maxsamples: \u0026lt;int\u0026gt; | default = 50000000] +[max_samples: \u0026lt;int\u0026gt; | default = 50000000] # The default evaluation interval or step size for subqueries. # CLI flag: -querier.default-evaluation-interval -[defaultevaluationinterval: \u0026lt;duration\u0026gt; | default = 1m0s] +[default_evaluation_interval: \u0026lt;duration\u0026gt; | default = 1m0s] ### query_frontend_config # URL of downstream Prometheus. # CLI flag: -frontend.downstream-url -[downstream: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +[downstream_url: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] ### ruler_config # URL of alerts return path. # CLI flag: -ruler.external.url -[externalurl: \u0026lt;url\u0026gt; | default = ] +[external_url: \u0026lt;url\u0026gt; | default = ] # How frequently to evaluate rules # CLI flag: -ruler.evaluation-interval -[evaluationinterval: \u0026lt;duration\u0026gt; | default = 1m0s] +[evaluation_interval: \u0026lt;duration\u0026gt; | default = 1m0s] # How frequently to poll for rule changes # CLI flag: -ruler.poll-interval -[pollinterval: \u0026lt;duration\u0026gt; | default = 1m0s] +[poll_interval: \u0026lt;duration\u0026gt; | default = 1m0s] -storeconfig: +storage: # file path to store temporary rule files for the prometheus rule managers # CLI flag: -ruler.rule-path -[rulepath: \u0026lt;string\u0026gt; | default = \u0026#34;/rules\u0026#34;] +[rule_path: \u0026lt;string\u0026gt; | default = \u0026#34;/rules\u0026#34;] # URL of the Alertmanager to send notifications to. # CLI flag: -ruler.alertmanager-url -[alertmanagerurl: \u0026lt;url\u0026gt; | default = ] +[alertmanager_url: \u0026lt;url\u0026gt; | default = ] # Use DNS SRV records to discover alertmanager hosts. # CLI flag: -ruler.alertmanager-discovery -[alertmanagerdiscovery: \u0026lt;boolean\u0026gt; | default = false] +[enable_alertmanager_discovery: \u0026lt;boolean\u0026gt; | default = false] # How long to wait between refreshing alertmanager hosts. # CLI flag: -ruler.alertmanager-refresh-interval -[alertmanagerrefreshinterval: \u0026lt;duration\u0026gt; | default = 1m0s] +[alertmanager_refresh_interval: \u0026lt;duration\u0026gt; | default = 1m0s] # If enabled requests to alertmanager will utilize the V2 API. # CLI flag: -ruler.alertmanager-use-v2 -[alertmanangerenablev2api: \u0026lt;boolean\u0026gt; | default = false] +[enable_alertmanager_v2: \u0026lt;boolean\u0026gt; | default = false] # Capacity of the queue for notifications to be sent to the Alertmanager. # CLI flag: -ruler.notification-queue-capacity -[notificationqueuecapacity: \u0026lt;int\u0026gt; | default = 10000] +[notification_queue_capacity: \u0026lt;int\u0026gt; | default = 10000] # HTTP timeout duration when sending notifications to the Alertmanager. # CLI flag: -ruler.notification-timeout -[notificationtimeout: \u0026lt;duration\u0026gt; | default = 10s] +[notification_timeout: \u0026lt;duration\u0026gt; | default = 10s] # Distribute rule evaluation using ring backend # CLI flag: -ruler.enable-sharding -[enablesharding: \u0026lt;boolean\u0026gt; | default = false] +[enable_sharding: \u0026lt;boolean\u0026gt; | default = false] # Time to spend searching for a pending ruler when shutting down. # CLI flag: -ruler.search-pending-for -[searchpendingfor: \u0026lt;duration\u0026gt; | default = 5m0s] +[search_pending_for: \u0026lt;duration\u0026gt; | default = 5m0s] # Period with which to attempt to flush rule groups. # CLI flag: -ruler.flush-period -[flushcheckperiod: \u0026lt;duration\u0026gt; | default = 1m0s] +[flush_period: \u0026lt;duration\u0026gt; | default = 1m0s] ### alertmanager_config # Base path for data storage. # CLI flag: -alertmanager.storage.path -[datadir: \u0026lt;string\u0026gt; | default = \u0026#34;data/\u0026#34;] +[data_dir: \u0026lt;string\u0026gt; | default = \u0026#34;data/\u0026#34;] # will be used to prefix all HTTP endpoints served by Alertmanager. If omitted, # relevant URL components will be derived automatically. # CLI flag: -alertmanager.web.external-url -[externalurl: \u0026lt;url\u0026gt; | default = ] +[external_url: \u0026lt;url\u0026gt; | default = ] # How frequently to poll Cortex configs # CLI flag: -alertmanager.configs.poll-interval -[pollinterval: \u0026lt;duration\u0026gt; | default = 15s] +[poll_interval: \u0026lt;duration\u0026gt; | default = 15s] # Listen address for cluster. # CLI flag: -cluster.listen-address -[clusterbindaddr: \u0026lt;string\u0026gt; | default = \u0026#34;0.0.0.0:9094\u0026#34;] +[cluster_bind_address: \u0026lt;string\u0026gt; | default = \u0026#34;0.0.0.0:9094\u0026#34;] # Explicit address to advertise in cluster. # CLI flag: -cluster.advertise-address -[clusteradvertiseaddr: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +[cluster_advertise_address: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] # Time to wait between peers to send notifications. # CLI flag: -cluster.peer-timeout -[peertimeout: \u0026lt;duration\u0026gt; | default = 15s] +[peer_timeout: \u0026lt;duration\u0026gt; | default = 15s] # Filename of fallback config to use if none specified for instance. # CLI flag: -alertmanager.configs.fallback -[fallbackconfigfile: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +[fallback_config_file: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] # Root of URL to generate if config is http://internal.monitor # CLI flag: -alertmanager.configs.auto-webhook-root -[autowebhookroot: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +[auto_webhook_root: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] ### table_manager_config -store: +storage: -# How frequently to poll DynamoDB to learn our capacity. -# CLI flag: -dynamodb.poll-interval -[dynamodb_poll_interval: \u0026lt;duration\u0026gt; | default = 2m0s] +# How frequently to poll backend to learn our capacity. +# CLI flag: -table-manager.poll-interval +[poll_interval: \u0026lt;duration\u0026gt; | default = 2m0s] -# DynamoDB periodic tables grace period (duration which table will be -# created/deleted before/after it\u0026#39;s needed). -# CLI flag: -dynamodb.periodic-table.grace-period +# Periodic tables grace period (duration which table will be created/deleted +# before/after it\u0026#39;s needed). +# CLI flag: -table-manager.periodic-table.grace-period [creation_grace_period: \u0026lt;duration\u0026gt; | default = 10m0s] index_tables_provisioning: # Enables on demand throughput provisioning for the storage provider (if - # supported). Applies only to tables which are not autoscaled - # CLI flag: -dynamodb.periodic-table.enable-ondemand-throughput-mode - [provisioned_throughput_on_demand_mode: \u0026lt;boolean\u0026gt; | default = false] + # supported). Applies only to tables which are not autoscaled. Supported by + # DynamoDB + # CLI flag: -table-manager.index-table.enable-ondemand-throughput-mode + [enable_ondemand_throughput_mode: \u0026lt;boolean\u0026gt; | default = false] # Enables on demand throughput provisioning for the storage provider (if - # supported). Applies only to tables which are not autoscaled - # CLI flag: -dynamodb.periodic-table.inactive-enable-ondemand-throughput-mode - [inactive_throughput_on_demand_mode: \u0026lt;boolean\u0026gt; | default = false] + # supported). Applies only to tables which are not autoscaled. Supported by + # DynamoDB + # CLI flag: -table-manager.index-table.inactive-enable-ondemand-throughput-mode + [enable_inactive_throughput_on_demand_mode: \u0026lt;boolean\u0026gt; | default = false] chunk_tables_provisioning: # Enables on demand throughput provisioning for the storage provider (if - # supported). Applies only to tables which are not autoscaled - # CLI flag: -dynamodb.chunk-table.enable-ondemand-throughput-mode - [provisioned_throughput_on_demand_mode: \u0026lt;boolean\u0026gt; | default = false] + # supported). Applies only to tables which are not autoscaled. Supported by + # DynamoDB + # CLI flag: -table-manager.chunk-table.enable-ondemand-throughput-mode + [enable_ondemand_throughput_mode: \u0026lt;boolean\u0026gt; | default = false] ### storage_config aws: - dynamodbconfig: + dynamodb: # DynamoDB endpoint URL with escaped Key and Secret encoded. If only region # is specified as a host, proper endpoint will be deduced. Use # inmemory:///\u0026lt;table-name\u0026gt; to use a mock in-memory implementation. # CLI flag: -dynamodb.url - [dynamodb: \u0026lt;url\u0026gt; | default = ] + [dynamodb_url: \u0026lt;url\u0026gt; | default = ] # DynamoDB table management requests per second limit. # CLI flag: -dynamodb.api-limit - [apilimit: \u0026lt;float\u0026gt; | default = 2] + [api_limit: \u0026lt;float\u0026gt; | default = 2] # DynamoDB rate cap to back off when throttled. # CLI flag: -dynamodb.throttle-limit - [throttlelimit: \u0026lt;float\u0026gt; | default = 10] + [throttle_limit: \u0026lt;float\u0026gt; | default = 10] - - # ApplicationAutoscaling endpoint URL with escaped Key and Secret encoded. - # CLI flag: -applicationautoscaling.url - [applicationautoscaling: \u0026lt;url\u0026gt; | default = ] # Queue length above which we will scale up capacity # CLI flag: -metrics.target-queue-length - [targetqueuelen: \u0026lt;int\u0026gt; | default = 100000] + [target_queue_length: \u0026lt;int\u0026gt; | default = 100000] # Scale up capacity by this multiple # CLI flag: -metrics.scale-up-factor - [scaleupfactor: \u0026lt;float\u0026gt; | default = 1.3] + [scale_up_factor: \u0026lt;float\u0026gt; | default = 1.3] # Ignore throttling below this level (rate per second) # CLI flag: -metrics.ignore-throttle-below - [minthrottling: \u0026lt;float\u0026gt; | default = 1] + [ignore_throttle_below: \u0026lt;float\u0026gt; | default = 1] # query to fetch ingester queue length # CLI flag: -metrics.queue-length-query - [queuelengthquery: \u0026lt;string\u0026gt; | default = \u0026#34;sum(avg_over_time(cortex_ingester_flush_queue_length{job=\\\u0026#34;cortex/ingester\\\u0026#34;}[2m]))\u0026#34;] + [queue_length_query: \u0026lt;string\u0026gt; | default = \u0026#34;sum(avg_over_time(cortex_ingester_flush_queue_length{job=\\\u0026#34;cortex/ingester\\\u0026#34;}[2m]))\u0026#34;] # query to fetch throttle rates per table # CLI flag: -metrics.write-throttle-query - [throttlequery: \u0026lt;string\u0026gt; | default = \u0026#34;sum(rate(cortex_dynamo_throttled_total{operation=\\\u0026#34;DynamoDB.BatchWriteItem\\\u0026#34;}[1m])) by (table) \u0026gt; 0\u0026#34;] + [write_throttle_query: \u0026lt;string\u0026gt; | default = \u0026#34;sum(rate(cortex_dynamo_throttled_total{operation=\\\u0026#34;DynamoDB.BatchWriteItem\\\u0026#34;}[1m])) by (table) \u0026gt; 0\u0026#34;] # query to fetch write capacity usage per table # CLI flag: -metrics.usage-query - [usagequery: \u0026lt;string\u0026gt; | default = \u0026#34;sum(rate(cortex_dynamo_consumed_capacity_total{operation=\\\u0026#34;DynamoDB.BatchWriteItem\\\u0026#34;}[15m])) by (table) \u0026gt; 0\u0026#34;] + [write_usage_query: \u0026lt;string\u0026gt; | default = \u0026#34;sum(rate(cortex_dynamo_consumed_capacity_total{operation=\\\u0026#34;DynamoDB.BatchWriteItem\\\u0026#34;}[15m])) by (table) \u0026gt; 0\u0026#34;] # query to fetch read capacity usage per table # CLI flag: -metrics.read-usage-query - [readusagequery: \u0026lt;string\u0026gt; | default = \u0026#34;sum(rate(cortex_dynamo_consumed_capacity_total{operation=\\\u0026#34;DynamoDB.QueryPages\\\u0026#34;}[1h])) by (table) \u0026gt; 0\u0026#34;] + [read_usage_query: \u0026lt;string\u0026gt; | default = \u0026#34;sum(rate(cortex_dynamo_consumed_capacity_total{operation=\\\u0026#34;DynamoDB.QueryPages\\\u0026#34;}[1h])) by (table) \u0026gt; 0\u0026#34;] # query to fetch read errors per table # CLI flag: -metrics.read-error-query - [readerrorquery: \u0026lt;string\u0026gt; | default = \u0026#34;sum(increase(cortex_dynamo_failures_total{operation=\\\u0026#34;DynamoDB.QueryPages\\\u0026#34;,error=\\\u0026#34;ProvisionedThroughputExceededException\\\u0026#34;}[1m])) by (table) \u0026gt; 0\u0026#34;] + [read_error_query: \u0026lt;string\u0026gt; | default = \u0026#34;sum(increase(cortex_dynamo_failures_total{operation=\\\u0026#34;DynamoDB.QueryPages\\\u0026#34;,error=\\\u0026#34;ProvisionedThroughputExceededException\\\u0026#34;}[1m])) by (table) \u0026gt; 0\u0026#34;] # Number of chunks to group together to parallelise fetches (zero to # disable) - # CLI flag: -dynamodb.chunk.gang.size - [chunkgangsize: \u0026lt;int\u0026gt; | default = 10] + # CLI flag: -dynamodb.chunk-gang-size + [chunk_gang_size: \u0026lt;int\u0026gt; | default = 10] # Max number of chunk-get operations to start in parallel - # CLI flag: -dynamodb.chunk.get.max.parallelism - [chunkgetmaxparallelism: \u0026lt;int\u0026gt; | default = 32] + # CLI flag: -dynamodb.chunk.get-max-parallelism + [chunk_get_max_parallelism: \u0026lt;int\u0026gt; | default = 32] backoff_config: # Minimum delay when backing off. # CLI flag: -bigtable.backoff-min-period - [minbackoff: \u0026lt;duration\u0026gt; | default = 100ms] + [min_period: \u0026lt;duration\u0026gt; | default = 100ms] # Maximum delay when backing off. # CLI flag: -bigtable.backoff-max-period - [maxbackoff: \u0026lt;duration\u0026gt; | default = 10s] + [max_period: \u0026lt;duration\u0026gt; | default = 10s] # Number of times to backoff and retry before failing. # CLI flag: -bigtable.backoff-retries - [maxretries: \u0026lt;int\u0026gt; | default = 10] + [max_retries: \u0026lt;int\u0026gt; | default = 10] # If enabled, once a tables info is fetched, it is cached. # CLI flag: -bigtable.table-cache.enabled - [tablecacheenabled: \u0026lt;boolean\u0026gt; | default = true] + [table_cache_enabled: \u0026lt;boolean\u0026gt; | default = true] # Duration to cache tables before checking again. # CLI flag: -bigtable.table-cache.expiration - [tablecacheexpiration: \u0026lt;duration\u0026gt; | default = 30m0s] + [table_cache_expiration: \u0026lt;duration\u0026gt; | default = 30m0s] # Cache validity for active index entries. Should be no higher than # -ingester.max-chunk-idle. # CLI flag: -store.index-cache-validity -[indexcachevalidity: \u0026lt;duration\u0026gt; | default = 5m0s] +[index_cache_validity: \u0026lt;duration\u0026gt; | default = 5m0s] ### ingester_client_config grpc_client_config: backoff_config: # Minimum delay when backing off. # CLI flag: -ingester.client.backoff-min-period - [minbackoff: \u0026lt;duration\u0026gt; | default = 100ms] + [min_period: \u0026lt;duration\u0026gt; | default = 100ms] # Maximum delay when backing off. # CLI flag: -ingester.client.backoff-max-period - [maxbackoff: \u0026lt;duration\u0026gt; | default = 10s] + [max_period: \u0026lt;duration\u0026gt; | default = 10s] # Number of times to backoff and retry before failing. # CLI flag: -ingester.client.backoff-retries - [maxretries: \u0026lt;int\u0026gt; | default = 10] + [max_retries: \u0026lt;int\u0026gt; | default = 10] ### frontend_worker_config -# Address of query frontend service. +# Address of query frontend service, in host:port format. # CLI flag: -querier.frontend-address -[address: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +[frontend_address: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] # How often to query DNS. # CLI flag: -querier.dns-lookup-period -[dnslookupduration: \u0026lt;duration\u0026gt; | default = 10s] +[dns_lookup_duration: \u0026lt;duration\u0026gt; | default = 10s] grpc_client_config: backoff_config: # Minimum delay when backing off. # CLI flag: -querier.frontend-client.backoff-min-period - [minbackoff: \u0026lt;duration\u0026gt; | default = 100ms] + [min_period: \u0026lt;duration\u0026gt; | default = 100ms] # Maximum delay when backing off. # CLI flag: -querier.frontend-client.backoff-max-period - [maxbackoff: \u0026lt;duration\u0026gt; | default = 10s] + [max_period: \u0026lt;duration\u0026gt; | default = 10s] # Number of times to backoff and retry before failing. # CLI flag: -querier.frontend-client.backoff-retries - [maxretries: \u0026lt;int\u0026gt; | default = 10] + [max_retries: \u0026lt;int\u0026gt; | default = 10] ### consul_config # ACL Token used to interact with Consul. -# CLI flag: -\u0026lt;prefix\u0026gt;.consul.acltoken -[acltoken: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +# CLI flag: -\u0026lt;prefix\u0026gt;.consul.acl-token +[acl_token: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] # HTTP timeout when talking to Consul # CLI flag: -\u0026lt;prefix\u0026gt;.consul.client-timeout -[httpclienttimeout: \u0026lt;duration\u0026gt; | default = 20s] +[http_client_timeout: \u0026lt;duration\u0026gt; | default = 20s] # Enable consistent reads to Consul. # CLI flag: -\u0026lt;prefix\u0026gt;.consul.consistent-reads -[consistentreads: \u0026lt;boolean\u0026gt; | default = true] +[consistent_reads: \u0026lt;boolean\u0026gt; | default = false] # Rate limit when watching key or prefix in Consul, in requests per second. 0 # disables the rate limit. # CLI flag: -\u0026lt;prefix\u0026gt;.consul.watch-rate-limit -[watchkeyratelimit: \u0026lt;float\u0026gt; | default = 0] +[watch_rate_limit: \u0026lt;float\u0026gt; | default = 1] # Burst size used in rate limit. Values less than 1 are treated as 1. # CLI flag: -\u0026lt;prefix\u0026gt;.consul.watch-burst-size -[watchkeyburstsize: \u0026lt;int\u0026gt; | default = 1] +[watch_burst_size: \u0026lt;int\u0026gt; | default = 1] ### configstore_config # URL of configs API server. # CLI flag: -\u0026lt;prefix\u0026gt;.configs.url -[configsapiurl: \u0026lt;url\u0026gt; | default = ] +[configs_api_url: \u0026lt;url\u0026gt; | default = ] # Timeout for requests to Weave Cloud configs service. # CLI flag: -\u0026lt;prefix\u0026gt;.configs.client-timeout -[clienttimeout: \u0026lt;duration\u0026gt; | default = 5s] +[client_timeout: \u0026lt;duration\u0026gt; | default = 5s] 0.7.0 / 2020-03-16 Cortex 0.7.0 is a major step forward the upcoming 1.0 release. In this release, we\u0026rsquo;ve got 164 contributions from 26 authors. Thanks to all contributors! ❤️\nPlease be aware that Cortex 0.7.0 introduces some breaking changes. You\u0026rsquo;re encouraged to read all the [CHANGE] entries below before upgrading your Cortex cluster. In particular:\n Cleaned up some configuration options in preparation for the Cortex 1.0.0 release (see also the annotated config file breaking changes below): Removed CLI flags support to configure the schema (see how to migrate from flags to schema file) Renamed CLI flag -config-yaml to -schema-config-file Removed CLI flag -store.min-chunk-age in favor of -querier.query-store-after. The corresponding YAML config option ingestermaxquerylookback has been renamed to query_ingesters_within Deprecated CLI flag -frontend.cache-split-interval in favor of -querier.split-queries-by-interval Renamed the YAML config option defaul_validity to default_validity Removed the YAML config option config_store (in the alertmanager YAML config) in favor of store Removed the YAML config root block configdb in favor of configs. This change is also reflected in the following CLI flags renaming: -database.* -\u0026gt; -configs.database.* -database.migrations -\u0026gt; -configs.database.migrations-dir Removed the fluentd-based billing infrastructure including the CLI flags: -distributor.enable-billing -billing.max-buffered-events -billing.retry-delay -billing.ingester Removed support for using denormalised tokens in the ring. Before upgrading, make sure your Cortex cluster is already running v0.6.0 or an earlier version with -ingester.normalise-tokens=true Full changelog [CHANGE] Removed support for flags to configure schema. Further, the flag for specifying the config file (-config-yaml) has been deprecated. Please use -schema-config-file. See the Schema Configuration documentation for more details on how to configure the schema using the YAML file. #2221 [CHANGE] In the config file, the root level config_store config option has been moved to alertmanager \u0026gt; store \u0026gt; configdb. #2125 [CHANGE] Removed unnecessary frontend.cache-split-interval in favor of querier.split-queries-by-interval both to reduce configuration complexity and guarantee alignment of these two configs. Starting from now, -querier.cache-results may only be enabled in conjunction with -querier.split-queries-by-interval (previously the cache interval default was 24h so if you want to preserve the same behaviour you should set -querier.split-queries-by-interval=24h). #2040 [CHANGE] Renamed Configs configuration options. #2187 configuration options -database.* -\u0026gt; -configs.database.* -database.migrations -\u0026gt; -configs.database.migrations-dir config file configdb.uri: -\u0026gt; configs.database.uri: configdb.migrationsdir: -\u0026gt; configs.database.migrations_dir: configdb.passwordfile: -\u0026gt; configs.database.password_file: [CHANGE] Moved -store.min-chunk-age to the Querier config as -querier.query-store-after, allowing the store to be skipped during query time if the metrics wouldn\u0026rsquo;t be found. The YAML config option ingestermaxquerylookback has been renamed to query_ingesters_within to match its CLI flag. #1893 [CHANGE] Renamed the cache configuration setting defaul_validity to default_validity. #2140 [CHANGE] Remove fluentd-based billing infrastructure and flags such as -distributor.enable-billing. #1491 [CHANGE] Removed remaining support for using denormalised tokens in the ring. If you\u0026rsquo;re still running ingesters with denormalised tokens (Cortex 0.4 or earlier, with -ingester.normalise-tokens=false), such ingesters will now be completely invisible to distributors and need to be either switched to Cortex 0.6.0 or later, or be configured to use normalised tokens. #2034 [CHANGE] The frontend http server will now send 502 in case of deadline exceeded and 499 if the user requested cancellation. #2156 [CHANGE] We now enforce queries to be up to -querier.max-query-into-future into the future (defaults to 10m). #1929 -store.min-chunk-age has been removed -querier.query-store-after has been added in it\u0026rsquo;s place. [CHANGE] Removed unused /validate_expr endpoint. #2152 [CHANGE] Updated Prometheus dependency to v2.16.0. This Prometheus version uses Active Query Tracker to limit concurrent queries. In order to keep -querier.max-concurrent working, Active Query Tracker is enabled by default, and is configured to store its data to active-query-tracker directory (relative to current directory when Cortex started). This can be changed by using -querier.active-query-tracker-dir option. Purpose of Active Query Tracker is to log queries that were running when Cortex crashes. This logging happens on next Cortex start. #2088 [CHANGE] Default to BigChunk encoding; may result in slightly higher disk usage if many timeseries have a constant value, but should generally result in fewer, bigger chunks. #2207 [CHANGE] WAL replays are now done while the rest of Cortex is starting, and more specifically, when HTTP server is running. This makes it possible to scrape metrics during WAL replays. Applies to both chunks and experimental blocks storage. #2222 [CHANGE] Cortex now has /ready probe for all services, not just ingester and querier as before. In single-binary mode, /ready reports 204 only if all components are running properly. #2166 [CHANGE] If you are vendoring Cortex and use its components in your project, be aware that many Cortex components no longer start automatically when they are created. You may want to review PR and attached document. #2166 [CHANGE] Experimental TSDB: the querier in-memory index cache used by the experimental blocks storage shifted from per-tenant to per-querier. The -experimental.tsdb.bucket-store.index-cache-size-bytes now configures the per-querier index cache max size instead of a per-tenant cache and its default has been increased to 1GB. #2189 [CHANGE] Experimental TSDB: TSDB head compaction interval and concurrency is now configurable (defaults to 1 min interval and 5 concurrent head compactions). New options: -experimental.tsdb.head-compaction-interval and -experimental.tsdb.head-compaction-concurrency. #2172 [CHANGE] Experimental TSDB: switched the blocks storage index header to the binary format. This change is expected to have no visible impact, except lower startup times and memory usage in the queriers. It\u0026rsquo;s possible to switch back to the old JSON format via the flag -experimental.tsdb.bucket-store.binary-index-header-enabled=false. #2223 [CHANGE] Experimental Memberlist KV store can now be used in single-binary Cortex. Attempts to use it previously would fail with panic. This change also breaks existing binary protocol used to exchange gossip messages, so this version will not be able to understand gossiped Ring when used in combination with the previous version of Cortex. Easiest way to upgrade is to shutdown old Cortex installation, and restart it with new version. Incremental rollout works too, but with reduced functionality until all components run the same version. #2016 [FEATURE] Added a read-only local alertmanager config store using files named corresponding to their tenant id. #2125 [FEATURE] Added flag -experimental.ruler.enable-api to enable the ruler api which implements the Prometheus API /api/v1/rules and /api/v1/alerts endpoints under the configured -http.prefix. #1999 [FEATURE] Added sharding support to compactor when using the experimental TSDB blocks storage. #2113 [FEATURE] Added ability to override YAML config file settings using environment variables. #2147 -config.expand-env [FEATURE] Added flags to disable Alertmanager notifications methods. #2187 -configs.notifications.disable-email -configs.notifications.disable-webhook [FEATURE] Add /config HTTP endpoint which exposes the current Cortex configuration as YAML. #2165 [FEATURE] Allow Prometheus remote write directly to ingesters. #1491 [FEATURE] Introduced new standalone service query-tee that can be used for testing purposes to send the same Prometheus query to multiple backends (ie. two Cortex clusters ingesting the same metrics) and compare the performances. #2203 [FEATURE] Fan out parallelizable queries to backend queriers concurrently. #1878 querier.parallelise-shardable-queries (bool) Requires a shard-compatible schema (v10+) This causes the number of traces to increase accordingly. The query-frontend now requires a schema config to determine how/when to shard queries, either from a file or from flags (i.e. by the config-yaml CLI flag). This is the same schema config the queriers consume. The schema is only required to use this option. It\u0026rsquo;s also advised to increase downstream concurrency controls as well: querier.max-outstanding-requests-per-tenant querier.max-query-parallelism querier.max-concurrent server.grpc-max-concurrent-streams (for both query-frontends and queriers) [FEATURE] Added user sub rings to distribute users to a subset of ingesters. #1947 -experimental.distributor.user-subring-size [FEATURE] Add flag -experimental.tsdb.stripe-size to expose TSDB stripe size option. #2185 [FEATURE] Experimental Delete Series: Added support for Deleting Series with Prometheus style API. Needs to be enabled first by setting -purger.enable to true. Deletion only supported when using boltdb and filesystem as index and object store respectively. Support for other stores to follow in separate PRs #2103 [ENHANCEMENT] Alertmanager: Expose Per-tenant alertmanager metrics #2124 [ENHANCEMENT] Add status label to cortex_alertmanager_configs metric to gauge the number of valid and invalid configs. #2125 [ENHANCEMENT] Cassandra Authentication: added the custom_authenticators config option that allows users to authenticate with cassandra clusters using password authenticators that are not approved by default in gocql #2093 [ENHANCEMENT] Cassandra Storage: added max_retries, retry_min_backoff and retry_max_backoff configuration options to enable retrying recoverable errors. #2054 [ENHANCEMENT] Allow to configure HTTP and gRPC server listen address, maximum number of simultaneous connections and connection keepalive settings. -server.http-listen-address -server.http-conn-limit -server.grpc-listen-address -server.grpc-conn-limit -server.grpc.keepalive.max-connection-idle -server.grpc.keepalive.max-connection-age -server.grpc.keepalive.max-connection-age-grace -server.grpc.keepalive.time -server.grpc.keepalive.timeout [ENHANCEMENT] PostgreSQL: Bump up github.com/lib/pq from v1.0.0 to v1.3.0 to support PostgreSQL SCRAM-SHA-256 authentication. #2097 [ENHANCEMENT] Cassandra Storage: User no longer need CREATE privilege on \u0026lt;all keyspaces\u0026gt; if given keyspace exists. #2032 [ENHANCEMENT] Cassandra Storage: added password_file configuration options to enable reading Cassandra password from file. #2096 [ENHANCEMENT] Configs API: Allow GET/POST configs in YAML format. #2181 [ENHANCEMENT] Background cache writes are batched to improve parallelism and observability. #2135 [ENHANCEMENT] Add automatic repair for checkpoint and WAL. #2105 [ENHANCEMENT] Support lastEvaluation and evaluationTime in /api/v1/rules endpoints and make order of groups stable. #2196 [ENHANCEMENT] Skip expired requests in query-frontend scheduling. #2082 [ENHANCEMENT] Add ability to configure gRPC keepalive settings. #2066 [ENHANCEMENT] Experimental TSDB: Export TSDB Syncer metrics from Compactor component, they are prefixed with cortex_compactor_. #2023 [ENHANCEMENT] Experimental TSDB: Added dedicated flag -experimental.tsdb.bucket-store.tenant-sync-concurrency to configure the maximum number of concurrent tenants for which blocks are synched. #2026 [ENHANCEMENT] Experimental TSDB: Expose metrics for objstore operations (prefixed with cortex_\u0026lt;component\u0026gt;_thanos_objstore_, component being one of ingester, querier and compactor). #2027 [ENHANCEMENT] Experimental TSDB: Added support for Azure Storage to be used for block storage, in addition to S3 and GCS. #2083 [ENHANCEMENT] Experimental TSDB: Reduced memory allocations in the ingesters when using the experimental blocks storage. #2057 [ENHANCEMENT] Experimental Memberlist KV: expose -memberlist.gossip-to-dead-nodes-time and -memberlist.dead-node-reclaim-time options to control how memberlist library handles dead nodes and name reuse. #2131 [BUGFIX] Alertmanager: fixed panic upon applying a new config, caused by duplicate metrics registration in the NewPipelineBuilder function. #211 [BUGFIX] Azure Blob ChunkStore: Fixed issue causing invalid chunk checksum errors. #2074 [BUGFIX] The gauge cortex_overrides_last_reload_successful is now only exported by components that use a RuntimeConfigManager. Previously, for components that do not initialize a RuntimeConfigManager (such as the compactor) the gauge was initialized with 0 (indicating error state) and then never updated, resulting in a false-negative permanent error state. #2092 [BUGFIX] Fixed WAL metric names, added the cortex_ prefix. [BUGFIX] Restored histogram cortex_configs_request_duration_seconds #2138 [BUGFIX] Fix wrong syntax for url in config-file-reference. #2148 [BUGFIX] Fixed some 5xx status code returned by the query-frontend when they should actually be 4xx. #2122 [BUGFIX] Fixed leaked goroutines in the querier. #2070 [BUGFIX] Experimental TSDB: fixed /all_user_stats and /api/prom/user_stats endpoints when using the experimental TSDB blocks storage. #2042 [BUGFIX] Experimental TSDB: fixed ruler to correctly work with the experimental TSDB blocks storage. #2101 Changes to denormalised tokens in the ring Cortex 0.4.0 is the last version that can write denormalised tokens. Cortex 0.5.0 and above always write normalised tokens.\nCortex 0.6.0 is the last version that can read denormalised tokens. Starting with Cortex 0.7.0 only normalised tokens are supported, and ingesters writing denormalised tokens to the ring (running Cortex 0.4.0 or earlier with -ingester.normalise-tokens=false) are ignored by distributors. Such ingesters should either switch to using normalised tokens, or be upgraded to Cortex 0.5.0 or later.\nKnown issues The gRPC streaming for ingesters doesn\u0026rsquo;t work when using the experimental TSDB blocks storage. Please do not enable -querier.ingester-streaming if you\u0026rsquo;re using the TSDB blocks storage. If you want to enable it, you can build Cortex from master given the issue has been fixed after Cortex 0.7 branch has been cut and the fix wasn\u0026rsquo;t included in the 0.7 because related to an experimental feature. Annotated config file breaking changes In this section you can find a config file diff showing the breaking changes introduced in Cortex 0.7. You can also find the full configuration file reference doc in the website.\n### Root level config # \u0026#34;configdb\u0026#34; has been moved to \u0026#34;alertmanager \u0026gt; store \u0026gt; configdb\u0026#34;. -[configdb: \u0026lt;configdb_config\u0026gt;] # \u0026#34;config_store\u0026#34; has been renamed to \u0026#34;configs\u0026#34;. -[config_store: \u0026lt;configstore_config\u0026gt;] +[configs: \u0026lt;configs_config\u0026gt;] ### `distributor_config` # The support to hook an external billing system has been removed. -[enable_billing: \u0026lt;boolean\u0026gt; | default = false] -billing: - [maxbufferedevents: \u0026lt;int\u0026gt; | default = 1024] - [retrydelay: \u0026lt;duration\u0026gt; | default = 500ms] - [ingesterhostport: \u0026lt;string\u0026gt; | default = \u0026#34;localhost:24225\u0026#34;] ### `querier_config` # \u0026#34;ingestermaxquerylookback\u0026#34; has been renamed to \u0026#34;query_ingesters_within\u0026#34;. -[ingestermaxquerylookback: \u0026lt;duration\u0026gt; | default = 0s] +[query_ingesters_within: \u0026lt;duration\u0026gt; | default = 0s] ### `queryrange_config` results_cache: cache: # \u0026#34;defaul_validity\u0026#34; has been renamed to \u0026#34;default_validity\u0026#34;. - [defaul_validity: \u0026lt;duration\u0026gt; | default = 0s] + [default_validity: \u0026lt;duration\u0026gt; | default = 0s] # \u0026#34;cache_split_interval\u0026#34; has been deprecated in favor of \u0026#34;split_queries_by_interval\u0026#34;. - [cache_split_interval: \u0026lt;duration\u0026gt; | default = 24h0m0s] ### `alertmanager_config` # The \u0026#34;store\u0026#34; config block has been added. This includes \u0026#34;configdb\u0026#34; which previously # was the \u0026#34;configdb\u0026#34; root level config block. +store: + [type: \u0026lt;string\u0026gt; | default = \u0026#34;configdb\u0026#34;] + [configdb: \u0026lt;configstore_config\u0026gt;] + local: + [path: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] ### `storage_config` index_queries_cache_config: # \u0026#34;defaul_validity\u0026#34; has been renamed to \u0026#34;default_validity\u0026#34;. - [defaul_validity: \u0026lt;duration\u0026gt; | default = 0s] + [default_validity: \u0026lt;duration\u0026gt; | default = 0s] ### `chunk_store_config` chunk_cache_config: # \u0026#34;defaul_validity\u0026#34; has been renamed to \u0026#34;default_validity\u0026#34;. - [defaul_validity: \u0026lt;duration\u0026gt; | default = 0s] + [default_validity: \u0026lt;duration\u0026gt; | default = 0s] write_dedupe_cache_config: # \u0026#34;defaul_validity\u0026#34; has been renamed to \u0026#34;default_validity\u0026#34;. - [defaul_validity: \u0026lt;duration\u0026gt; | default = 0s] + [default_validity: \u0026lt;duration\u0026gt; | default = 0s] # \u0026#34;min_chunk_age\u0026#34; has been removed in favor of \u0026#34;querier \u0026gt; query_store_after\u0026#34;. -[min_chunk_age: \u0026lt;duration\u0026gt; | default = 0s] ### `configs_config` -# \u0026#34;uri\u0026#34; has been moved to \u0026#34;database \u0026gt; uri\u0026#34;. -[uri: \u0026lt;string\u0026gt; | default = \u0026#34;postgres://postgres@configs-db.weave.local/configs?sslmode=disable\u0026#34;] -# \u0026#34;migrationsdir\u0026#34; has been moved to \u0026#34;database \u0026gt; migrations_dir\u0026#34;. -[migrationsdir: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] -# \u0026#34;passwordfile\u0026#34; has been moved to \u0026#34;database \u0026gt; password_file\u0026#34;. -[passwordfile: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +database: + [uri: \u0026lt;string\u0026gt; | default = \u0026#34;postgres://postgres@configs-db.weave.local/configs?sslmode=disable\u0026#34;] + [migrations_dir: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] + [password_file: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] 0.6.1 / 2020-02-05 [BUGFIX] Fixed parsing of the WAL configuration when specified in the YAML config file. #2071 0.6.0 / 2020-01-28 Note that the ruler flags need to be changed in this upgrade. You\u0026rsquo;re moving from a single node ruler to something that might need to be sharded. Further, if you\u0026rsquo;re using the configs service, we\u0026rsquo;ve upgraded the migration library and this requires some manual intervention. See full instructions below to upgrade your PostgreSQL.\n [CHANGE] The frontend component now does not cache results if it finds a Cache-Control header and if one of its values is no-store. #1974 [CHANGE] Flags changed with transition to upstream Prometheus rules manager: -ruler.client-timeout is now ruler.configs.client-timeout in order to match ruler.configs.url. -ruler.group-timeouthas been removed. -ruler.num-workers has been removed. -ruler.rule-path has been added to specify where the prometheus rule manager will sync rule files. -ruler.storage.type has beem added to specify the rule store backend type, currently only the configdb. -ruler.poll-interval has been added to specify the interval in which to poll new rule groups. -ruler.evaluation-interval default value has changed from 15s to 1m to match the default evaluation interval in Prometheus. Ruler sharding requires a ring which can be configured via the ring flags prefixed by ruler.ring.. #1987 [CHANGE] Use relative links from /ring page to make it work when used behind reverse proxy. #1896 [CHANGE] Deprecated -distributor.limiter-reload-period flag. #1766 [CHANGE] Ingesters now write only normalised tokens to the ring, although they can still read denormalised tokens used by other ingesters. -ingester.normalise-tokens is now deprecated, and ignored. If you want to switch back to using denormalised tokens, you need to downgrade to Cortex 0.4.0. Previous versions don\u0026rsquo;t handle claiming tokens from normalised ingesters correctly. #1809 [CHANGE] Overrides mechanism has been renamed to \u0026ldquo;runtime config\u0026rdquo;, and is now separate from limits. Runtime config is simply a file that is reloaded by Cortex every couple of seconds. Limits and now also multi KV use this mechanism.\nNew arguments were introduced: -runtime-config.file (defaults to empty) and -runtime-config.reload-period (defaults to 10 seconds), which replace previously used -limits.per-user-override-config and -limits.per-user-override-period options. Old options are still used if -runtime-config.file is not specified. This change is also reflected in YAML configuration, where old limits.per_tenant_override_config and limits.per_tenant_override_period fields are replaced with runtime_config.file and runtime_config.period respectively. #1749 [CHANGE] Cortex now rejects data with duplicate labels. Previously, such data was accepted, with duplicate labels removed with only one value left. #1964 [CHANGE] Changed the default value for -distributor.ha-tracker.prefix from collectors/ to ha-tracker/ in order to not clash with other keys (ie. ring) stored in the same key-value store. #1940 [FEATURE] Experimental: Write-Ahead-Log added in ingesters for more data reliability against ingester crashes. #1103 --ingester.wal-enabled: Setting this to true enables writing to WAL during ingestion. --ingester.wal-dir: Directory where the WAL data should be stored and/or recovered from. --ingester.checkpoint-enabled: Set this to true to enable checkpointing of in-memory chunks to disk. --ingester.checkpoint-duration: This is the interval at which checkpoints should be created. --ingester.recover-from-wal: Set this to true to recover data from an existing WAL. For more information, please checkout the \u0026ldquo;Ingesters with WAL\u0026rdquo; guide. [FEATURE] The distributor can now drop labels from samples (similar to the removal of the replica label for HA ingestion) per user via the distributor.drop-label flag. #1726 [FEATURE] Added flag debug.mutex-profile-fraction to enable mutex profiling #1969 [FEATURE] Added global ingestion rate limiter strategy. Deprecated -distributor.limiter-reload-period flag. #1766 [FEATURE] Added support for Microsoft Azure blob storage to be used for storing chunk data. #1913 [FEATURE] Added readiness probe endpoint/ready to queriers. #1934 [FEATURE] Added \u0026ldquo;multi\u0026rdquo; KV store that can interact with two other KV stores, primary one for all reads and writes, and secondary one, which only receives writes. Primary/secondary store can be modified in runtime via runtime-config mechanism (previously \u0026ldquo;overrides\u0026rdquo;). #1749 [FEATURE] Added support to store ring tokens to a file and read it back on startup, instead of generating/fetching the tokens to/from the ring. This feature can be enabled with the flag -ingester.tokens-file-path. #1750 [FEATURE] Experimental TSDB: Added /series API endpoint support with TSDB blocks storage. #1830 [FEATURE] Experimental TSDB: Added TSDB blocks compactor component, which iterates over users blocks stored in the bucket and compact them according to the configured block ranges. #1942 [ENHANCEMENT] metric cortex_ingester_flush_reasons gets a new reason value: Spread, when -ingester.spread-flushes option is enabled. #1978 [ENHANCEMENT] Added password and enable_tls options to redis cache configuration. Enables usage of Microsoft Azure Cache for Redis service. #1923 [ENHANCEMENT] Upgraded Kubernetes API version for deployments from extensions/v1beta1 to apps/v1. #1941 [ENHANCEMENT] Experimental TSDB: Open existing TSDB on startup to prevent ingester from becoming ready before it can accept writes. The max concurrency is set via --experimental.tsdb.max-tsdb-opening-concurrency-on-startup. #1917 [ENHANCEMENT] Experimental TSDB: Querier now exports aggregate metrics from Thanos bucket store and in memory index cache (many metrics to list, but all have cortex_querier_bucket_store_ or cortex_querier_blocks_index_cache_ prefix). #1996 [ENHANCEMENT] Experimental TSDB: Improved multi-tenant bucket store. #1991 Allowed to configure the blocks sync interval via -experimental.tsdb.bucket-store.sync-interval (0 disables the sync) Limited the number of tenants concurrently synched by -experimental.tsdb.bucket-store.block-sync-concurrency Renamed cortex_querier_sync_seconds metric to cortex_querier_blocks_sync_seconds Track cortex_querier_blocks_sync_seconds metric for the initial sync too [BUGFIX] Fixed unnecessary CAS operations done by the HA tracker when the jitter is enabled. #1861 [BUGFIX] Fixed ingesters getting stuck in a LEAVING state after coming up from an ungraceful exit. #1921 [BUGFIX] Reduce memory usage when ingester Push() errors. #1922 [BUGFIX] Table Manager: Fixed calculation of expected tables and creation of tables from next active schema considering grace period. #1976 [BUGFIX] Experimental TSDB: Fixed ingesters consistency during hand-over when using experimental TSDB blocks storage. #1854 #1818 [BUGFIX] Experimental TSDB: Fixed metrics when using experimental TSDB blocks storage. #1981 #1982 #1990 #1983 [BUGFIX] Experimental memberlist: Use the advertised address when sending packets to other peers of the Gossip memberlist. #1857 Upgrading PostgreSQL (if you\u0026rsquo;re using configs service) Reference: https://github.com/golang-migrate/migrate/tree/master/database/postgres#upgrading-from-v1\n Install the migrate package cli tool: https://github.com/golang-migrate/migrate/tree/master/cmd/migrate#installation Drop the schema_migrations table: DROP TABLE schema_migrations;. Run the migrate command:\nmigrate -path \u0026lt;absolute_path_to_cortex\u0026gt;/cmd/cortex/migrations -database postgres://localhost:5432/database force 2 Known issues The cortex_prometheus_rule_group_last_evaluation_timestamp_seconds metric, tracked by the ruler, is not unregistered for rule groups not being used anymore. This issue will be fixed in the next Cortex release (see 2033).\n Write-Ahead-Log (WAL) does not have automatic repair of corrupt checkpoint or WAL segments, which is possible if ingester crashes abruptly or the underlying disk corrupts. Currently the only way to resolve this is to manually delete the affected checkpoint and/or WAL segments. Automatic repair will be added in the future releases.\n 0.4.0 / 2019-12-02 [CHANGE] The frontend component has been refactored to be easier to re-use. When upgrading the frontend, cache entries will be discarded and re-created with the new protobuf schema. #1734 [CHANGE] Removed direct DB/API access from the ruler. -ruler.configs.url has been now deprecated. #1579 [CHANGE] Removed Delta encoding. Any old chunks with Delta encoding cannot be read anymore. If ingester.chunk-encoding is set to Delta the ingester will fail to start. #1706 [CHANGE] Setting -ingester.max-transfer-retries to 0 now disables hand-over when ingester is shutting down. Previously, zero meant infinite number of attempts. #1771 [CHANGE] dynamo has been removed as a valid storage name to make it consistent for all components. aws and aws-dynamo remain as valid storage names. [CHANGE/FEATURE] The frontend split and cache intervals can now be configured using the respective flag --querier.split-queries-by-interval and --frontend.cache-split-interval. If --querier.split-queries-by-interval is not provided request splitting is disabled by default. --querier.split-queries-by-day is still accepted for backward compatibility but has been deprecated. You should now use --querier.split-queries-by-interval. We recommend a to use a multiple of 24 hours. [FEATURE] Global limit on the max series per user and metric #1760 -ingester.max-global-series-per-user -ingester.max-global-series-per-metric Requires -distributor.replication-factor and -distributor.shard-by-all-labels set for the ingesters too [FEATURE] Flush chunks with stale markers early with ingester.max-stale-chunk-idle. #1759 [FEATURE] EXPERIMENTAL: Added new KV Store backend based on memberlist library. Components can gossip about tokens and ingester states, instead of using Consul or Etcd. #1721 [FEATURE] EXPERIMENTAL: Use TSDB in the ingesters \u0026amp; flush blocks to S3/GCS ala Thanos. This will let us use an Object Store more efficiently and reduce costs. #1695 [FEATURE] Allow Query Frontend to log slow queries with frontend.log-queries-longer-than. #1744 [FEATURE] Add HTTP handler to trigger ingester flush \u0026amp; shutdown - used when running as a stateful set with the WAL enabled. #1746 [FEATURE] EXPERIMENTAL: Added GCS support to TSDB blocks storage. #1772 [ENHANCEMENT] Reduce memory allocations in the write path. #1706 [ENHANCEMENT] Consul client now follows recommended practices for blocking queries wrt returned Index value. #1708 [ENHANCEMENT] Consul client can optionally rate-limit itself during Watch (used e.g. by ring watchers) and WatchPrefix (used by HA feature) operations. Rate limiting is disabled by default. New flags added: --consul.watch-rate-limit, and --consul.watch-burst-size. #1708 [ENHANCEMENT] Added jitter to HA deduping heartbeats, configure using distributor.ha-tracker.update-timeout-jitter-max #1534 [ENHANCEMENT] Add ability to flush chunks with stale markers early. #1759 [BUGFIX] Stop reporting successful actions as 500 errors in KV store metrics. #1798 [BUGFIX] Fix bug where duplicate labels can be returned through metadata APIs. #1790 [BUGFIX] Fix reading of old, v3 chunk data. #1779 [BUGFIX] Now support IAM roles in service accounts in AWS EKS. #1803 [BUGFIX] Fixed duplicated series returned when querying both ingesters and store with the experimental TSDB blocks storage. #1778 In this release we updated the following dependencies:\n gRPC v1.25.0 (resulted in a drop of 30% CPU usage when compression is on) jaeger-client v2.20.0 aws-sdk-go to v1.25.22 0.3.0 / 2019-10-11 This release adds support for Redis as an alternative to Memcached, and also includes many optimisations which reduce CPU and memory usage.\n [CHANGE] Gauge metrics were renamed to drop the _total suffix. #1685 In Alertmanager, alertmanager_configs_total is now alertmanager_configs In Ruler, scheduler_configs_total is now scheduler_configs scheduler_groups_total is now scheduler_groups. [CHANGE] --alertmanager.configs.auto-slack-root flag was dropped as auto Slack root is not supported anymore. #1597 [CHANGE] In table-manager, default DynamoDB capacity was reduced from 3,000 units to 1,000 units. We recommend you do not run with the defaults: find out what figures are needed for your environment and set that via -dynamodb.periodic-table.write-throughput and -dynamodb.chunk-table.write-throughput. [FEATURE] Add Redis support for caching #1612 [FEATURE] Allow spreading chunk writes across multiple S3 buckets #1625 [FEATURE] Added /shutdown endpoint for ingester to shutdown all operations of the ingester. #1746 [ENHANCEMENT] Upgraded Prometheus to 2.12.0 and Alertmanager to 0.19.0. #1597 [ENHANCEMENT] Cortex is now built with Go 1.13 #1675, #1676, #1679 [ENHANCEMENT] Many optimisations, mostly impacting ingester and querier: #1574, #1624, #1638, #1644, #1649, #1654, #1702 Full list of changes: https://github.com/cortexproject/cortex/compare/v0.2.0...v0.3.0\n0.2.0 / 2019-09-05 This release has several exciting features, the most notable of them being setting -ingester.spread-flushes to potentially reduce your storage space by upto 50%.\n [CHANGE] Flags changed due to changes upstream in Prometheus Alertmanager #929: alertmanager.mesh.listen-address is now cluster.listen-address alertmanager.mesh.peer.host and alertmanager.mesh.peer.service can be replaced by cluster.peer alertmanager.mesh.hardware-address, alertmanager.mesh.nickname, alertmanager.mesh.password, and alertmanager.mesh.peer.refresh-interval all disappear. [CHANGE] \u0026ndash;claim-on-rollout flag deprecated; feature is now always on #1566 [CHANGE] Retention period must now be a multiple of periodic table duration #1564 [CHANGE] The value for the name label for the chunks memcache in all cortex_cache_ metrics is now chunksmemcache (before it was memcache) #1569 [FEATURE] Makes the ingester flush each timeseries at a specific point in the max-chunk-age cycle with -ingester.spread-flushes. This means multiple replicas of a chunk are very likely to contain the same contents which cuts chunk storage space by up to 66%. #1578 [FEATURE] Make minimum number of chunk samples configurable per user #1620 [FEATURE] Honor HTTPS for custom S3 URLs #1603 [FEATURE] You can now point the query-frontend at a normal Prometheus for parallelisation and caching #1441 [FEATURE] You can now specify http_config on alert receivers #929 [FEATURE] Add option to use jump hashing to load balance requests to memcached #1554 [FEATURE] Add status page for HA tracker to distributors #1546 [FEATURE] The distributor ring page is now easier to read with alternate rows grayed out #1621 0.1.0 / 2019-08-07 [CHANGE] HA Tracker flags were renamed to provide more clarity #1465 distributor.accept-ha-labels is now distributor.ha-tracker.enable distributor.accept-ha-samples is now distributor.ha-tracker.enable-for-all-users ha-tracker.replica is now distributor.ha-tracker.replica ha-tracker.cluster is now distributor.ha-tracker.cluster [FEATURE] You can specify \u0026ldquo;heap ballast\u0026rdquo; to reduce Go GC Churn #1489 [BUGFIX] HA Tracker no longer always makes a request to Consul/Etcd when a request is not from the active replica #1516 [BUGFIX] Queries are now correctly cancelled by the query-frontend #1508 ","excerpt":"master / unreleased [CHANGE] Added v1 API routes documented in #2327. #2372 Added …","ref":"/docs/changelog/","title":"Changelog"},{"body":"","excerpt":"","ref":"/docs/proposals/","title":"Proposals"},{"body":"Cortex follows the CNCF Code of Conduct.\n","excerpt":"Cortex follows the CNCF Code of Conduct.","ref":"/docs/code-of-conduct/","title":"Code of Conduct"},{"body":" Because Cortex is designed to run multiple instances of each component (ingester, querier, etc.), you probably want to automate the placement and shepherding of these instances. Most users choose Kubernetes to do this, but this is not mandatory.\nConfiguration Resource requests If using Kubernetes, each container should specify resource requests so that the scheduler can place them on a node with sufficient capacity.\nFor example an ingester might request:\n resources: requests: cpu: 4 memory: 10Gi The specific values here should be adjusted based on your own experiences running Cortex - they are very dependent on rate of data arriving and other factors such as series churn.\nTake extra care with ingesters Ingesters hold hours of timeseries data in memory; you can configure Cortex to replicate the data but you should take steps to avoid losing all replicas at once:\n Don\u0026rsquo;t run multiple ingesters on the same node. Don\u0026rsquo;t run ingesters on preemptible/spot nodes. Spread out ingesters across racks / availability zones / whatever applies in your datacenters. You can ask Kubernetes to avoid running on the same node like this:\n affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: name operator: In values: - ingester topologyKey: \u0026quot;kubernetes.io/hostname\u0026quot; Give plenty of time for an ingester to hand over or flush data to store when shutting down; for Kubernetes this looks like:\n terminationGracePeriodSeconds: 2400 Ask Kubernetes to limit rolling updates to one ingester at a time, and signal the old one to stop before the new one is ready:\n strategy: rollingUpdate: maxSurge: 0 maxUnavailable: 1 Ingesters provide an HTTP hook to signal readiness when all is well; this is valuable because it stops a rolling update at the first problem:\n readinessProbe: httpGet: path: /ready port: 80 We do not recommend configuring a liveness probe on ingesters - killing them is a last resort and should not be left to a machine.\n","excerpt":"Because Cortex is designed to run multiple instances of each component (ingester, querier, etc.), …","ref":"/docs/guides/kubernetes/","title":"Running Cortex on Kubernetes"},{"body":" Cortex uses Jaeger to implement distributed tracing. We have found Jaeger invaluable for troubleshooting the behavior of Cortex in production.\nDependencies In order to send traces you will need to set up a Jaeger deployment. A deployment includes either the jaeger all-in-one binary, or else a distributed system of agents, collectors, and queriers. If running on Kubernetes, Jaeger Kubernetes is an excellent resource.\nConfiguration In order to configure Cortex to send traces you must do two things: 1. Set the JAEGER_AGENT_HOST environment variable in all components to point to your Jaeger agent. This defaults to localhost. 1. Enable sampling in the appropriate components: * The Ingester and Ruler self-initiate traces and should have sampling explicitly enabled. * Sampling for the Distributor and Query Frontend can be enabled in Cortex or in an upstream service such as your frontdoor.\nTo enable sampling in Cortex components you can specify either JAEGER_SAMPLER_MANAGER_HOST_PORT for remote sampling, or JAEGER_SAMPLER_TYPE and JAEGER_SAMPLER_PARAM to manually set sampling configuration. See the Jaeger Client Go documentation for the full list of environment variables you can configure.\nNote that you must specify one of JAEGER_AGENT_HOST or JAEGER_SAMPLER_MANAGER_HOST_PORT in each component for Jaeger to be enabled, even if you plan to use the default values.\n","excerpt":"Cortex uses Jaeger to implement distributed tracing. We have found Jaeger invaluable for …","ref":"/docs/guides/tracing/","title":"Tracing"},{"body":"The ingester holds several hours of sample data in memory. When we want to shut down an ingester, either for software version update or to drain a node for maintenance, this data must not be discarded.\nEach ingester goes through different states in its lifecycle. When working normally, the state is ACTIVE.\nOn start-up, an ingester first goes into state PENDING. After a short time, if nothing happens, it adds itself to the ring and goes into state ACTIVE.\nA running ingester is notified to shut down by Unix signal SIGINT. On receipt of this signal it goes into state LEAVING and looks for an ingester in state PENDING. If it finds one, that ingester goes into state JOINING and the leaver transfers all its in-memory data over to the joiner. On successful transfer the leaver removes itself from the ring and exits and the joiner changes to ACTIVE, taking over ownership of the leaver\u0026rsquo;s ring tokens.\nIf a leaving ingester does not find a pending ingester after several attempts, it will flush all of its chunks to the backing database, then remove itself from the ring and exit. This may take tens of minutes to complete.\nDuring hand-over, neither the leaving nor joining ingesters will accept new samples. Distributors are aware of this, and \u0026ldquo;spill\u0026rdquo; the samples to the next ingester in the ring. This creates a set of extra \u0026ldquo;spilled\u0026rdquo; chunks which will idle out and flush after hand-over is complete. The sudden increase in flush queue can be alarming!\nThe following metrics can be used to observe this process:\n cortex_member_ring_tokens_owned - how many tokens each ingester thinks it owns cortex_ring_tokens_owned - how many tokens each ingester is seen to own by other components cortex_ring_member_ownership_percent same as cortex_ring_tokens_owned but expressed as a percentage cortex_ring_members - how many ingesters can be seen in each state, by other components cortex_ingester_sent_chunks - number of chunks sent by leaving ingester cortex_ingester_received_chunks - number of chunks received by joining ingester You can see the current state of the ring via http browser request to /ring on a distributor.\n","excerpt":"The ingester holds several hours of sample data in memory. When we want to shut down an ingester, …","ref":"/docs/guides/ingester-handover/","title":"Ingester Hand-over"},{"body":"You will want to estimate how many nodes are required, how many of each component to run, and how much storage space will be required. In practice, these will vary greatly depending on the metrics being sent to Cortex.\nSome key parameters are:\n The number of active series. If you have Prometheus already you can query prometheus_tsdb_head_series to see this number. Sampling rate, e.g. a new sample for each series every minute (the default Prometheus scrape_interval). Multiply this by the number of active series to get the total rate at which samples will arrive at Cortex. The rate at which series are added and removed. This can be very high if you monitor objects that come and go - for example if you run thousands of batch jobs lasting a minute or so and capture metrics with a unique ID for each one. Read how to analyse this on Prometheus. How compressible the time-series data are. If a metric stays at the same value constantly, then Cortex can compress it very well, so 12 hours of data sampled every 15 seconds would be around 2KB. On the other hand if the value jumps around a lot it might take 10KB. There are not currently any tools available to analyse this. How long you want to retain data for, e.g. 1 month or 2 years. Other parameters which can become important if you have particularly high values:\n Number of different series under one metric name. Number of labels per series. Rate and complexity of queries. Now, some rules of thumb:\n Each million series in an ingester takes 15GB of RAM. Total number of series in ingesters is number of active series times the replication factor. This is with the default of 12-hour chunks - RAM required will reduce if you set -ingester.max-chunk-age lower (trading off more back-end database IO) Each million series (including churn) consumes 15GB of chunk storage and 4GB of index, per day (so multiply by the retention period). Each 100,000 samples/sec arriving takes 1 CPU in distributors. Distributors don\u0026rsquo;t need much RAM. If you turn on compression between distributors and ingesters (for example to save on inter-zone bandwidth charges at AWS/GCP) they will use significantly more CPU (approx 100% more for distributor and 50% more for ingester).\n","excerpt":"You will want to estimate how many nodes are required, how many of each component to run, and how …","ref":"/docs/guides/capacity-planning/","title":"Capacity Planning"},{"body":"","excerpt":"","ref":"/index.json","title":""},{"body":" Horizontally scalable, highly available, multi-tenant, long term Prometheus. Learn More Releases Companies using Cortex\n Long term storage Durably store data for longer than the lifetime of any single machine, and use this data for long term capacity planning. Blazin\u0026rsquo; fast PromQL Cortex makes your PromQL queries blazin' fast through aggressive parallelization and caching. A global view of data Cortex gives you a global view of Prometheus time series data that includes data in long-term storage, greatly expanding the usefulness of PromQL for analytical purposes. Horizontally scalable Cortex runs across multiple machines in a cluster, exceeding the throughput and storage of a single machine. This enables you to send the metrics from multiple Prometheus servers to a single Cortex cluster. We are a Cloud Native Computing Foundation Sandbox project.\n Join the community ! Join users and companies that are using Cortex in production.\n Slack Issues Twitter ","excerpt":"Horizontally scalable, highly available, multi-tenant, long term Prometheus. Learn More Releases …","ref":"/","title":"Cortex"},{"body":"","excerpt":"","ref":"/search/","title":"Search Results"}]